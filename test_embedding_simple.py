"""
ç®€åŒ–ç‰ˆæµ‹è¯• - åªæµ‹è¯•æ ¸å¿ƒåŠŸèƒ½
è·³è¿‡å¤šè¯­è¨€æ¨¡å‹ä»¥é¿å…ä¸‹è½½è¶…æ—¶
"""

import sys
import os

# æ·»åŠ backendè·¯å¾„
sys.path.insert(0, os.path.join(os.path.dirname(__file__), 'backend'))

def _run_core_functionality():
    """æµ‹è¯•æ ¸å¿ƒåŠŸèƒ½ï¼Œè¿”å›æ˜¯å¦å…¨éƒ¨é€šè¿‡ï¼ˆä¾› pytest æ–­è¨€å’Œ __main__ ä½¿ç”¨ï¼‰"""
    print("=" * 70)
    print("ChatPDF - å‘é‡æ£€ç´¢å’ŒåµŒå…¥æ¨¡å‹æ ¸å¿ƒåŠŸèƒ½æµ‹è¯•")
    print("=" * 70)
    
    all_passed = True
    
    # æµ‹è¯•1: æœ¬åœ°åµŒå…¥æ¨¡å‹
    print("\n[æµ‹è¯• 1/3] æµ‹è¯•æœ¬åœ°å…è´¹åµŒå…¥æ¨¡å‹ (all-MiniLM-L6-v2)")
    print("-" * 70)
    try:
        from sentence_transformers import SentenceTransformer
        
        model_name = "all-MiniLM-L6-v2"
        print(f"æ­£åœ¨åŠ è½½æ¨¡å‹: {model_name}")
        print("æ³¨æ„: é¦–æ¬¡è¿è¡Œä¼šè‡ªåŠ¨ä¸‹è½½æ¨¡å‹ (~80MB)...\n")
        
        model = SentenceTransformer(model_name)
        print("âœ“ æ¨¡å‹åŠ è½½æˆåŠŸ!")
        
        # æµ‹è¯•åµŒå…¥ç”Ÿæˆ
        test_texts = [
            "æœºå™¨å­¦ä¹ æ˜¯äººå·¥æ™ºèƒ½çš„æ ¸å¿ƒæŠ€æœ¯",
            "æ·±åº¦å­¦ä¹ ä½¿ç”¨ç¥ç»ç½‘ç»œ",
            "è‡ªç„¶è¯­è¨€å¤„ç†å¸®åŠ©ç†è§£æ–‡æœ¬"
        ]
        
        embeddings = model.encode(test_texts)
        print(f"âœ“ åµŒå…¥å‘é‡ç”ŸæˆæˆåŠŸ!")
        print(f"  - æ–‡æœ¬æ•°é‡: {len(test_texts)}")
        print(f"  - åµŒå…¥ç»´åº¦: {embeddings.shape[1]}")
        print(f"  - å‘é‡å½¢çŠ¶: {embeddings.shape}")
        
    except Exception as e:
        print(f"âœ— å¤±è´¥: {e}")
        all_passed = False
    
    # æµ‹è¯•2: FAISSå‘é‡æ£€ç´¢
    print("\n[æµ‹è¯• 2/3] æµ‹è¯•FAISSå‘é‡æ£€ç´¢åŠŸèƒ½")
    print("-" * 70)
    try:
        import numpy as np
        import faiss
        from sentence_transformers import SentenceTransformer
        
        # å‡†å¤‡æµ‹è¯•æ–‡æ¡£
        documents = [
            "æœºå™¨å­¦ä¹ æ˜¯äººå·¥æ™ºèƒ½çš„ä¸€ä¸ªåˆ†æ”¯",
            "æ·±åº¦å­¦ä¹ ä½¿ç”¨ç¥ç»ç½‘ç»œè¿›è¡Œè®­ç»ƒ",
            "è‡ªç„¶è¯­è¨€å¤„ç†ç”¨äºç†è§£å’Œç”Ÿæˆäººç±»è¯­è¨€",
            "è®¡ç®—æœºè§†è§‰å¸®åŠ©æœºå™¨ç†è§£å›¾åƒ",
            "ä»Šå¤©å¤©æ°”å¾ˆå¥½,é€‚åˆå‡ºå»æ•£æ­¥"
        ]
        
        print(f"å‡†å¤‡äº† {len(documents)} ä¸ªæµ‹è¯•æ–‡æ¡£")
        
        # åŠ è½½æ¨¡å‹å¹¶ç”ŸæˆåµŒå…¥
        model = SentenceTransformer("all-MiniLM-L6-v2")
        doc_embeddings = model.encode(documents)
        print(f"âœ“ æ–‡æ¡£åµŒå…¥ç”Ÿæˆå®Œæˆ (ç»´åº¦: {doc_embeddings.shape[1]})")
        
        # åˆ›å»ºFAISSç´¢å¼•
        dimension = doc_embeddings.shape[1]
        index = faiss.IndexFlatL2(dimension)
        index.add(doc_embeddings.astype('float32'))
        print(f"âœ“ FAISSç´¢å¼•åˆ›å»ºæˆåŠŸ (åŒ…å« {index.ntotal} ä¸ªå‘é‡)")
        
        # æµ‹è¯•æ£€ç´¢
        query = "ä»€ä¹ˆæ˜¯æ·±åº¦å­¦ä¹ ?"
        print(f"\næŸ¥è¯¢: '{query}'")
        
        query_embedding = model.encode([query])
        distances, indices = index.search(query_embedding.astype('float32'), 3)
        
        print(f"âœ“ æ£€ç´¢åˆ°æœ€ç›¸å…³çš„3ä¸ªæ–‡æ¡£:")
        for i, (idx, dist) in enumerate(zip(indices[0], distances[0])):
            print(f"  {i+1}. [ç›¸ä¼¼åº¦è·ç¦»: {dist:.4f}] {documents[idx]}")
        
    except Exception as e:
        print(f"âœ— å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        all_passed = False
    
    # æµ‹è¯•3: åº”ç”¨çš„å®Œæ•´æµç¨‹
    print("\n[æµ‹è¯• 3/3] æµ‹è¯•åº”ç”¨çš„å®Œæ•´ç´¢å¼•å’Œæ£€ç´¢æµç¨‹")
    print("-" * 70)
    try:
        from services.embedding_service import build_vector_index, get_relevant_context
        from models.model_registry import EMBEDDING_MODELS
        import tempfile
        import shutil
        
        # æ˜¾ç¤ºå¯ç”¨æ¨¡å‹
        print("å¯ç”¨çš„åµŒå…¥æ¨¡å‹:")
        for model_id, config in EMBEDDING_MODELS.items():
            provider_icon = "ğŸ’»" if config['provider'] == 'local' else "â˜ï¸"
            print(f"  {provider_icon} {model_id}: {config['name']}")
            print(f"     ç»´åº¦: {config['dimension']}, ä»·æ ¼: {config['price']}")
        
        # åˆ›å»ºä¸´æ—¶ç›®å½•
        test_dir = tempfile.mkdtemp(prefix="chatpdf_test_")
        
        # ä¸´æ—¶ä¿®æ”¹å…¨å±€è·¯å¾„
        import app
        original_vector_dir = app.VECTOR_STORE_DIR
        app.VECTOR_STORE_DIR = test_dir
        
        try:
            # å‡†å¤‡æµ‹è¯•æ–‡æ¡£
            test_doc_id = "test_doc_001"
            test_text = """
            äººå·¥æ™ºèƒ½(AI)æ˜¯è®¡ç®—æœºç§‘å­¦çš„ä¸€ä¸ªé‡è¦åˆ†æ”¯ã€‚æœºå™¨å­¦ä¹ æ˜¯å®ç°äººå·¥æ™ºèƒ½çš„æ ¸å¿ƒæ–¹æ³•ã€‚
            æ·±åº¦å­¦ä¹ æ˜¯æœºå™¨å­¦ä¹ çš„ä¸€ä¸ªå­é¢†åŸŸ,å®ƒä½¿ç”¨å¤šå±‚ç¥ç»ç½‘ç»œæ¥å­¦ä¹ æ•°æ®çš„å¤æ‚è¡¨ç¤ºã€‚
            è‡ªç„¶è¯­è¨€å¤„ç†(NLP)ä½¿è®¡ç®—æœºèƒ½å¤Ÿç†è§£ã€è§£é‡Šå’Œç”Ÿæˆäººç±»è¯­è¨€ã€‚
            è®¡ç®—æœºè§†è§‰è®©æœºå™¨èƒ½å¤Ÿä»å›¾åƒå’Œè§†é¢‘ä¸­æå–ã€åˆ†æå’Œç†è§£ä¿¡æ¯ã€‚
            å¼ºåŒ–å­¦ä¹ è®©æ™ºèƒ½ä½“é€šè¿‡ä¸ç¯å¢ƒçš„äº¤äº’æ¥å­¦ä¹ æœ€ä¼˜å†³ç­–ç­–ç•¥ã€‚
            è¿ç§»å­¦ä¹ å¯ä»¥å°†åœ¨ä¸€ä¸ªä»»åŠ¡ä¸Šå­¦åˆ°çš„çŸ¥è¯†åº”ç”¨åˆ°å¦ä¸€ä¸ªç›¸å…³ä»»åŠ¡ä¸Šã€‚
            """
            
            print(f"\næ­£åœ¨ä¸ºæµ‹è¯•æ–‡æ¡£æ„å»ºå‘é‡ç´¢å¼•...")
            build_vector_index(test_doc_id, test_text, vector_store_dir=test_dir, embedding_model_id="local-minilm")
            
            # éªŒè¯æ–‡ä»¶
            index_path = os.path.join(test_dir, f"{test_doc_id}.index")
            chunks_path = os.path.join(test_dir, f"{test_doc_id}.pkl")
            
            if os.path.exists(index_path) and os.path.exists(chunks_path):
                print(f"âœ“ ç´¢å¼•æ–‡ä»¶åˆ›å»ºæˆåŠŸ")
            else:
                raise Exception("ç´¢å¼•æ–‡ä»¶æœªåˆ›å»º")
            
            # æµ‹è¯•æ£€ç´¢
            queries = [
                "ä»€ä¹ˆæ˜¯æ·±åº¦å­¦ä¹ ?",
                "NLPçš„ä½œç”¨æ˜¯ä»€ä¹ˆ?",
            ]
            
            print(f"\næµ‹è¯•å‘é‡æ£€ç´¢:")
            for query in queries:
                print(f"\n  æŸ¥è¯¢: '{query}'")
                context = get_relevant_context(
                    test_doc_id,
                    query,
                    vector_store_dir=test_dir,
                    pages=[],
                    top_k=2
                )
                
                if context:
                    # åªæ˜¾ç¤ºå‰150ä¸ªå­—ç¬¦
                    preview = context.replace('\n', ' ')[:150] + "..."
                    print(f"  âœ“ æ£€ç´¢ç»“æœ: {preview}")
                else:
                    raise Exception(f"æœªèƒ½æ£€ç´¢åˆ°å†…å®¹")
            
            print(f"\nâœ“ å®Œæ•´æµç¨‹æµ‹è¯•æˆåŠŸ!")
            
        finally:
            # æ¸…ç†
            app.VECTOR_STORE_DIR = original_vector_dir
            shutil.rmtree(test_dir, ignore_errors=True)
        
    except Exception as e:
        print(f"âœ— å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        all_passed = False
    
    # æ€»ç»“
    print("\n" + "=" * 70)
    if all_passed:
        print("ğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡!")
        print("=" * 70)
        print("\nâœ“ æœ¬åœ°å…è´¹åµŒå…¥æ¨¡å‹å·¥ä½œæ­£å¸¸")
        print("âœ“ FAISSå‘é‡æ£€ç´¢åŠŸèƒ½æ­£å¸¸")
        print("âœ“ åº”ç”¨çš„ç´¢å¼•æ„å»ºå’Œæ£€ç´¢æµç¨‹æ­£å¸¸")
        print("\næ‚¨å¯ä»¥åœ¨ChatPDFä¸­ä½¿ç”¨å‘é‡æ£€ç´¢åŠŸèƒ½æ¥æé«˜é—®ç­”çš„å‡†ç¡®æ€§!")
        print("åœ¨è®¾ç½®ä¸­å¯ç”¨'å‘é‡æ£€ç´¢'é€‰é¡¹å³å¯ä½¿ç”¨ã€‚")
    else:
        print("âš  éƒ¨åˆ†æµ‹è¯•å¤±è´¥")
        print("=" * 70)
    
    return all_passed


def test_core_functionality():
    assert _run_core_functionality() is True


if __name__ == "__main__":
    try:
        success = _run_core_functionality()
        sys.exit(0 if success else 1)
    except KeyboardInterrupt:
        print("\n\næµ‹è¯•è¢«ç”¨æˆ·ä¸­æ–­")
        sys.exit(1)
    except Exception as e:
        print(f"\n\nå‘ç”Ÿé”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)
