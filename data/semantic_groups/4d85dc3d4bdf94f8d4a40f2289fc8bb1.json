{
  "schema_version": 1,
  "doc_id": "4d85dc3d4bdf94f8d4a40f2289fc8bb1",
  "doc_hash": "",
  "created_at": "2026-02-07T09:01:37.117583+00:00",
  "config": {
    "target_chars": 5000,
    "min_chars": 2500,
    "max_chars": 6000
  },
  "groups": [
    {
      "group_id": "group-0",
      "chunk_indices": [
        0,
        1
      ],
      "char_count": 1620,
      "summary": "第三十三届人工智能大会(AAAI-19)：基于对抗学习的多模型集成方法 MEAL 沈志强，贺占魁，薛向阳 1复旦大学计算机科学技术学院上海市智能信息处理重点 实",
      "digest": "第三十三届人工智能大会(AAAI-19)：基于对抗学习的多模型集成方法 MEAL 沈志强，贺占魁，薛向阳 1复旦大学计算机科学技术学院上海市智能信息处理重点 实验室，中国上海 2美国伊利诺伊大学厄巴纳-香槟分校贝克曼研究所 中国上海复旦大学数据科学学院3 zhiqiangshen0214@gmail.com, {zkhe15, xyxue}@fudan.edu.cn 摘要 推理时的浮点运算次数 6 倍 通常性能最佳的深度神经网络模型是由多个基础网络 快照集成 组成的集成模型。然而，存储这些网络所需的空间以 （黄等人）我们的测试 2017 5 倍 及在测试时运行它们所需的时间，使得它们无法应用 时计算量 于测试集规模较大的场景（例如）。本文提 浮点运算次数 ImageNet 4 倍 出了一种将大型复杂训练集成模型压缩为单一网络的 方法，通过知识蒸馏将多种训练好的深度神经网络 （）知识迁移至单个中。为了从不同训练好 3 倍 DNN DNN 的（教师）模型中提取多样化知识，我们提出采用基 2 倍于对抗学习的策略：通过定义分块训练损失函数来引 导和优化预定义的学生网络，使其恢复教师模型中的 1 倍知识，同时促使判别器网络能够区分教师与学生模型 的特征。我们提出的通过对抗学习迁移蒸馏知识的集 成方法（）展现出三大优势：（）借助判别器 0× MEAL 1 1 2 3 4 5 学习蒸馏知识的学生网络比原始模型优化得更好； 集成数量 （）仅需单次前向传播即可实现快速推理，其性能甚2 至优于传统多原始模型集成方法；（）学生网络能从 图：推理阶段计算量对比。黄等人3 1 (Huang et al.\n任意结构的教师模型中学习蒸馏知识。在 CIFAR- 利用不同局部极小值处的模型进行集成，虽2017a) 10/100、SVHN 和 ImageNet 数据集上的大量实验验证然无需额外训练成本，但测试时的计算量会随集成 了 MEAL 方法的有效性。基于 ResNet-50 的 MEAL 在 规模线性增长。相比之下，我们的方法在推理阶段 ImageNet 上实现了 21.79%/5.99%的 top-1/5 验证错误 始终使用单一模型，因此测试成本与集成数量无 率，较原始模型分别提升 2.06%/1.14%。\n关。\n关。\n利用不同网络架构（处理相同或不同增强输入）的 输出结果。我们的测试过程仍基",
      "full_text": "第三十三届人工智能大会(AAAI-19)：基于对抗学习的多模型集成方法 MEAL 沈志强，贺占魁，薛向阳 1复旦大学计算机科学技术学院上海市智能信息处理重点 实验室，中国上海 2美国伊利诺伊大学厄巴纳-香槟分校贝克曼研究所 中国上海复旦大学数据科学学院3 zhiqiangshen0214@gmail.com, {zkhe15, xyxue}@fudan.edu.cn 摘要 推理时的浮点运算次数 6 倍 通常性能最佳的深度神经网络模型是由多个基础网络 快照集成 组成的集成模型。然而，存储这些网络所需的空间以 （黄等人）我们的测试 2017 5 倍 及在测试时运行它们所需的时间，使得它们无法应用 时计算量 于测试集规模较大的场景（例如）。本文提 浮点运算次数 ImageNet 4 倍 出了一种将大型复杂训练集成模型压缩为单一网络的 方法，通过知识蒸馏将多种训练好的深度神经网络 （）知识迁移至单个中。为了从不同训练好 3 倍 DNN DNN 的（教师）模型中提取多样化知识，我们提出采用基 2 倍于对抗学习的策略：通过定义分块训练损失函数来引 导和优化预定义的学生网络，使其恢复教师模型中的 1 倍知识，同时促使判别器网络能够区分教师与学生模型 的特征。我们提出的通过对抗学习迁移蒸馏知识的集 成方法（）展现出三大优势：（）借助判别器 0× MEAL 1 1 2 3 4 5 学习蒸馏知识的学生网络比原始模型优化得更好； 集成数量 （）仅需单次前向传播即可实现快速推理，其性能甚2 至优于传统多原始模型集成方法；（）学生网络能从 图：推理阶段计算量对比。黄等人3 1 (Huang et al.\n任意结构的教师模型中学习蒸馏知识。在 CIFAR- 利用不同局部极小值处的模型进行集成，虽2017a) 10/100、SVHN 和 ImageNet 数据集上的大量实验验证然无需额外训练成本，但测试时的计算量会随集成 了 MEAL 方法的有效性。基于 ResNet-50 的 MEAL 在 规模线性增长。相比之下，我们的方法在推理阶段 ImageNet 上实现了 21.79%/5.99%的 top-1/5 验证错误 始终使用单一模型，因此测试成本与集成数量无 率，较原始模型分别提升 2.06%/1.14%。\n关。\n关。\n利用不同网络架构（处理相同或不同增强输入）的 输出结果。我们的测试过程仍基于单一网络运行， 但基于不同预训练网络生成的监督标签，实际上对 应着多个参考网络的集成预测效果。\n传统集成方法（或称真实集成）存在一些常被忽视 的缺陷：1) 冗余性：训练完成的神经网络所包含的 引言1. 信息或知识往往存在冗余且相互重叠。直接组合预 集成方法是通过在测试阶段对多个神经网络的预测测结果通常需要额外计算成本，但性能提升有限； 规模臃肿且速度缓慢：集成方法比单一网络需要结果进行加权平均或投票来综合决策的框架。长期 2) 实践证明，多模型集成通常比单一网络具有更强的更多计算操作，这使其无法应用于内存/存储空间/ 算力受限的场景（如台式机、移动设备乃至嵌入式鲁棒性和更高的准确性。这种优势也间接体现在通 过 （等人，）、 设备），也无法满足需要实时预测的应用需求。\nDropoutSrivastava 2014 Dropconnect （Wan 等人，2013）、随机深度（Huang 等人，针对上述缺陷，本文提出采用基于学习的集成方）、 （、 和，）法，旨在通过学习实现多神经网络的集成2016 Swapout Singh Hoiem Forsyth 2016 等技术训练单一网络的过程中。我们通过训练阶段 构建集成预测的方式扩展了这一理念， 同等贡献。本研究成果由何占魁在伊利诺伊大学厄巴纳 香∗ - 槟分校担任研究实习生期间完成。版权所有，人工©2019 智能促进协会(www.aaai.org)，保留所有权利。 4886",
      "keywords": [],
      "page_range": [
        1,
        1
      ],
      "summary_status": "failed",
      "llm_meta": {
        "model": "gpt-4o-mini",
        "temperature": 0.3,
        "prompt_version": "v1",
        "created_at": "2026-02-07T09:01:37.115585+00:00"
      }
    },
    {
      "group_id": "group-1",
      "chunk_indices": [
        2,
        3,
        4,
        5
      ],
      "char_count": 3112,
      "summary": "证明单个网络的泛化能力。最近提出的快照集成 烟草店 图书馆 （等人）旨在解决训练集成模型的成Huang 2017a 书店 玩具店本问题。与快照集成不同，本文主要",
      "digest": "证明单个网络的泛化能力。最近提出的快照集成 烟草店 图书馆 （等人）旨在解决训练集成模型的成Huang 2017a 书店 玩具店本问题。与快照集成不同，本文主要关注测试集成 模型的成本。我们的方法基于近期提出的知识蒸馏 糖果店 （Hinton、Vinyals 和 Dean 2015；Papernot 等人杂货店； 等人； 等人）和对抗学习2017 Li 2017 Yim 2017 （Goodfellow 等人 2014），因此我们将回顾与本研 究最直接相关的工作。隐式集成。本质上，我们\" \" 图 2：左侧是 ImageNet 中\"烟草店\"类别的训练样本示 的方法是一种\"隐式\"集成，通常在训练和测试阶段 例，右侧展示不同训练架构生成的软分布。软标签都具有高效性。典型的隐式集成方法包括：\" \" 蕴含更丰富的信息，能为视觉关联场景提供更全面 Dropout（Srivastava 等人 2014）、DropConnection 的覆盖。 （等人）、随机深度（等人Wan 2013 Huang 2016）、Swapout（Singh、Hoiem 和 Forsyth 2016） 等。这些方法通常在训练过程中创建大量共享权重 在不增加任何测试成本的前提下，我们通过整合不 的网络，在测试时隐式地集成它们。相比之下，我 同神经网络的多样化输出作为监督信号来指导目标 们的方法专注于相同输入下标签的细微差异。与 网络训练。参考网络被称为教师网络，目标网络则 我们工作最为相似的可能是近期提出的标签精炼方 称为学生网络。我们摒弃传统的独热向量标签，转 法（等人，），该方法专注于利Bagherinezhad 2018 而采用能更好覆盖共现对象和视觉关联场景的软标 用先前训练好的神经网络生成的软化标签进行单模 签。我们认为标签应当针对特定图像提供信息量 型优化，并通过迭代学习构建更精确的新网络。我 换言之，相同类别的不同图像不应使用完全相—— 们的方法与之不同之处在于引入了对抗模块，迫使 同的标签。具体而言，如图 2 所示，外观类似\"图 模型学习教师模型与学生模型之间的差异，这能提 书馆的烟草店图像，其标签分布应当有别于更\" \" \" 升模型泛化能力，并可与任何其他隐式集成技术结 像\"杂货店\"的\"烟草店\"图像。研究还发现软标签能额 合使用。对抗学习方面，生成对抗网络\n换言之，相同类别的不同图像不应使",
      "full_text": "证明单个网络的泛化能力。最近提出的快照集成 烟草店 图书馆 （等人）旨在解决训练集成模型的成Huang 2017a 书店 玩具店本问题。与快照集成不同，本文主要关注测试集成 模型的成本。我们的方法基于近期提出的知识蒸馏 糖果店 （Hinton、Vinyals 和 Dean 2015；Papernot 等人杂货店； 等人； 等人）和对抗学习2017 Li 2017 Yim 2017 （Goodfellow 等人 2014），因此我们将回顾与本研 究最直接相关的工作。隐式集成。本质上，我们\" \" 图 2：左侧是 ImageNet 中\"烟草店\"类别的训练样本示 的方法是一种\"隐式\"集成，通常在训练和测试阶段 例，右侧展示不同训练架构生成的软分布。软标签都具有高效性。典型的隐式集成方法包括：\" \" 蕴含更丰富的信息，能为视觉关联场景提供更全面 Dropout（Srivastava 等人 2014）、DropConnection 的覆盖。 （等人）、随机深度（等人Wan 2013 Huang 2016）、Swapout（Singh、Hoiem 和 Forsyth 2016） 等。这些方法通常在训练过程中创建大量共享权重 在不增加任何测试成本的前提下，我们通过整合不 的网络，在测试时隐式地集成它们。相比之下，我 同神经网络的多样化输出作为监督信号来指导目标 们的方法专注于相同输入下标签的细微差异。与 网络训练。参考网络被称为教师网络，目标网络则 我们工作最为相似的可能是近期提出的标签精炼方 称为学生网络。我们摒弃传统的独热向量标签，转 法（等人，），该方法专注于利Bagherinezhad 2018 而采用能更好覆盖共现对象和视觉关联场景的软标 用先前训练好的神经网络生成的软化标签进行单模 签。我们认为标签应当针对特定图像提供信息量 型优化，并通过迭代学习构建更精确的新网络。我 换言之，相同类别的不同图像不应使用完全相—— 们的方法与之不同之处在于引入了对抗模块，迫使 同的标签。具体而言，如图 2 所示，外观类似\"图 模型学习教师模型与学生模型之间的差异，这能提 书馆的烟草店图像，其标签分布应当有别于更\" \" \" 升模型泛化能力，并可与任何其他隐式集成技术结 像\"杂货店\"的\"烟草店\"图像。研究还发现软标签能额 合使用。对抗学习方面，生成对抗网络\n换言之，相同类别的不同图像不应使用完全相—— 们的方法与之不同之处在于引入了对抗模块，迫使 同的标签。具体而言，如图 2 所示，外观类似\"图 模型学习教师模型与学生模型之间的差异，这能提 书馆的烟草店图像，其标签分布应当有别于更\" \" \" 升模型泛化能力，并可与任何其他隐式集成技术结 像\"杂货店\"的\"烟草店\"图像。研究还发现软标签能额 合使用。对抗学习方面，生成对抗网络 外提供数据集的类内与类间关联信息。 （等人，）被提出用于通过神经网Goodfellow 2014 为进一步提升学生网络的鲁棒性，我们引入对抗学络从随机噪声生成逼真图像。该框架包含两个组 习策略，强制使学生网络生成与教师网络相似的输件：一个作为生成器，另一个作为判别器。生成器 出。实验表明，方法在不同数据集上的多种MEAL 负责合成图像以欺骗判别器，同时判别器试图区分 流行网络架构中均能持续提升准确率。例如，基于真实与伪造图像。通常，生成器和判别器通过相互 网络（）的 在shake-shake Gastaldi 2017 MEAL CIFAR- 对抗实现同步训练。在本研究中，我们采用生成 10 数据集上实现了 2.54%的测试错误率，相对提升器合成学生特征，并利用判别器对同一输入图像下 了；在 数据集上，基于 11.2% ImageNet ResNet-50教师模型与学生模型的输出进行区分。对抗学习的 的 MEAL 取得了 21.79%/5.99%的验证错误率，显著优势在于，生成器会尝试产生与教师模型相似的特 优于基线模型。 征，使得判别器无法区分。这一过程提升了学生网 络训练的鲁棒性，并已应用于图像生成（Johnson,）、目标检测（Gupta, and Fei-Fei 2018 Bai et al.）等诸多领域。2018 知识迁移。从训练好的神经网络中提取知识并将其 本文的创新贡献主要体现在以下三个方面。 迁移到另一个新网络的方法已在(Hinton, Vinyals, and 我们基于师生学习范式，设计了一个包含对抗学Dean 2015; Chen, Goodfellow, and Shlens 2016; Li et al. • 习的端到端深度神经网络集成框架。 2017; Yim et al. 2017; Bagherinezhad et al. 2018; Anil et\n迁移到另一个新网络的方法已在(Hinton, Vinyals, and 我们基于师生学习范式，设计了一个包含对抗学Dean 2015; Chen, Goodfellow, and Shlens 2016; Li et al. • 习的端到端深度神经网络集成框架。 2017; Yim et al. 2017; Bagherinezhad et al. 2018; Anil et 等研究中得到充分探索。典型的知识迁移al. 2018) 方式是师生学习范式，即利用教师网络最终输出的 • 该方法能在不增加测试成本的前提下，实现多神 软化分布来向学生网络传递信息。通过这种教学流经网络集成的目标。\n该方法在、 和 数据集程，学生能够以更高效的形式学习教师处理给定任 • CIFAR-10/100 SVHN ImageNet 务的方式。 等人 将待迁移的蒸馏上，针对多种现有网络架构提升了当前最优的准 Yim (Yim et al. 2017) 确率。 知识定义为不同中间层之间的流动特征，并计算配 对层间内积...\n相关工作2. 已有大量关于神经网络集成方法的研究（和Hansen Salamon 1990；Perrone 和 Cooper 1995；Krogh 和；； 等；Vedelsby 1995Dietterich 2000 Huang 2017a Lakshminarayanan、Pritzel 和 Blundell 2017）。然而这 些早期研究大多聚焦于... 1 基线模型（）的误差率为。Shake-shake Gastaldi 2017 2.86% 4887\n教师网络A …教师模型 选择机制 模块 N 全连接层 教师 二元交叉熵 损失函数 教师网络 对齐 对齐 对齐 相似性损失 相似性损失 相似性损失 生成器 判别器 判别器 判别器 对齐 对齐 对齐 学生网络 2018 年）图 3：我们提出的架构概览。我们将同一图像输入教师网络和学生网络，生成用于相似性损失和判 别器的中间及最终输出。该模型通过对抗方式与多个判别器网络进行训练。在训练过程中，模型接收来自已 训练教师网络的监督信号而非独热编码的真实标签，且教师网络的参数始终保持固定。\n来自两个网络的参数。 等人 络则在相同图像集上进行训练，但采用由 生成Bagherinezhad S T （等人，年）研究了标签各种特的标签。更正式地说，我们可以将此过程视为在新Bagherinezhad 2018 性的影响，并提出了标签精炼方法在通过师生学标记数据集上训练—— S 习范式检查整个数据集后，迭代更新真实标签。 D = (X, T(X))˜。在教师网络训练完成后，我们在训练 学生网络时固定其参数。",
      "keywords": [],
      "page_range": [
        2,
        2
      ],
      "summary_status": "failed",
      "llm_meta": {
        "model": "gpt-4o-mini",
        "temperature": 0.3,
        "prompt_version": "v1",
        "created_at": "2026-02-07T09:01:37.115585+00:00"
      }
    },
    {
      "group_id": "group-2",
      "chunk_indices": [
        6
      ],
      "char_count": 979,
      "summary": "我们通过最小化学生网络输出与教师网络生成的软 概述3. 标签之间的相似度距离来训练学生网络 S。设 p(X) 孪生网络结构 我们的框架采用类孪生架构，包含， 分",
      "digest": "我们通过最小化学生网络输出与教师网络生成的软 概述3. 标签之间的相似度距离来训练学生网络 S。设 p(X) 孪生网络结构 我们的框架采用类孪生架构，包含， 分别表示教师模型和学生模= T(X)[c]p(X) = S(X)[c] T 教师分支和学生分支的双流网络。两个分支的结构 型 对类别赋予的概率。该相似度度量可表述 S c 可以相同或不同，但必须具有相同数量的模块，以 为： 便利用中间输出。如图所示，我们的方法整体框 3 架由教师网络、学生网络、对齐层、相似度损失层 L= d(T(X), S(X)) 和判别器组成。 ∑ (1) = d(p(X), p(X))教师网络和学生网络经过处理生成用于对齐的中间 输出。对齐层是一个自适应池化过程，它接收相同 c 本研究探讨了三种距离度量方式，包括`距离、`距 或不同长度的特征向量作为输入，并输出固定长度 离以及散度。具体实验对比结果如表 所示。 KL 1 的新特征。我们通过让学生网络与多个判别器进行 现将各度量公式表述如下： 对抗训练，强制模型输出学生和教师的相似特征。\n后续章节将详细阐述这些组件的具体实现。 采用`距离来最小化学生模型估计概率值与教师模 型参考概率值之间的绝对差异。其公式表述为： n 1 ∑ ∑ ∣ ∣ L(S) = ∣p(X) − p(X) ∣(2) n 基于对抗学习的知识蒸馏 c i=14. (AL) 距离或欧几里得距离是指欧几里得空间中的直线距` 离。我们使用`损失函数来最小化误差，该误差是学 相似性度量4.1 生输出概率与教师概率之间所有平方差的总和。 可` 给定数据集，我们预先使用针对独热编码 以表示为： D = (X, Y) 图像级标签的交叉熵损失在该数据集上预训练教师 网络 T。学生网- n 1 ∑ ∑ ∥ ∥ L(S) = ∥p(X) − p(X) ∥(3) 2真实标签 n c i=1 4888\n0.9 0.1 0.6 0.2 0.3 自适应池化0.5 0.7 0.3 0 0.5 0 0 0 0.1!\n教师输出 0 0 2 索引 0 0 2 索引 输出尺寸 = 3 数值 梯度!! 0.9 0.6 0.7 0.3 0.5 0.1 教师？\n前进 反向传播 学生？\n学生输出 图：前向与反向阶段中自适应池化的处理流程。此 5 处以最大池化操作为例进行说明。",
      "full_text": "我们通过最小化学生网络输出与教师网络生成的软 概述3. 标签之间的相似度距离来训练学生网络 S。设 p(X) 孪生网络结构 我们的框架采用类孪生架构，包含， 分别表示教师模型和学生模= T(X)[c]p(X) = S(X)[c] T 教师分支和学生分支的双流网络。两个分支的结构 型 对类别赋予的概率。该相似度度量可表述 S c 可以相同或不同，但必须具有相同数量的模块，以 为： 便利用中间输出。如图所示，我们的方法整体框 3 架由教师网络、学生网络、对齐层、相似度损失层 L= d(T(X), S(X)) 和判别器组成。 ∑ (1) = d(p(X), p(X))教师网络和学生网络经过处理生成用于对齐的中间 输出。对齐层是一个自适应池化过程，它接收相同 c 本研究探讨了三种距离度量方式，包括`距离、`距 或不同长度的特征向量作为输入，并输出固定长度 离以及散度。具体实验对比结果如表 所示。 KL 1 的新特征。我们通过让学生网络与多个判别器进行 现将各度量公式表述如下： 对抗训练，强制模型输出学生和教师的相似特征。\n后续章节将详细阐述这些组件的具体实现。 采用`距离来最小化学生模型估计概率值与教师模 型参考概率值之间的绝对差异。其公式表述为： n 1 ∑ ∑ ∣ ∣ L(S) = ∣p(X) − p(X) ∣(2) n 基于对抗学习的知识蒸馏 c i=14. (AL) 距离或欧几里得距离是指欧几里得空间中的直线距` 离。我们使用`损失函数来最小化误差，该误差是学 相似性度量4.1 生输出概率与教师概率之间所有平方差的总和。 可` 给定数据集，我们预先使用针对独热编码 以表示为： D = (X, Y) 图像级标签的交叉熵损失在该数据集上预训练教师 网络 T。学生网- n 1 ∑ ∑ ∥ ∥ L(S) = ∥p(X) − p(X) ∥(3) 2真实标签 n c i=1 4888\n0.9 0.1 0.6 0.2 0.3 自适应池化0.5 0.7 0.3 0 0.5 0 0 0 0.1!\n教师输出 0 0 2 索引 0 0 2 索引 输出尺寸 = 3 数值 梯度!! 0.9 0.6 0.7 0.3 0.5 0.1 教师？\n前进 反向传播 学生？\n学生输出 图：前向与反向阶段中自适应池化的处理流程。此 5 处以最大池化操作为例进行说明。",
      "keywords": [],
      "page_range": [
        3,
        3
      ],
      "summary_status": "failed",
      "llm_meta": {
        "model": "gpt-4o-mini",
        "temperature": 0.3,
        "prompt_version": "v1",
        "created_at": "2026-02-07T09:01:37.115585+00:00"
      }
    },
    {
      "group_id": "group-3",
      "chunk_indices": [
        7
      ],
      "char_count": 703,
      "summary": "0.9 0.1 0.6 0.2 0.3 自适应池化0.5 0.7 0.3 0 0.5 0 0 0 0.1!\n教师输出 0 0 2 索引 0 0 2 索引 输出尺",
      "digest": "0.9 0.1 0.6 0.2 0.3 自适应池化0.5 0.7 0.3 0 0.5 0 0 0 0.1!\n教师输出 0 0 2 索引 0 0 2 索引 输出尺寸 = 3 数值 梯度!! 0.9 0.6 0.7 0.3 0.5 0.1 教师？\n前进 反向传播 学生？\n学生输出 图：前向与反向阶段中自适应池化的处理流程。此 5 处以最大池化操作为例进行说明。\n图：我们提出的判别器示意图。我们将教师和学 4 生的输出拼接作为判别器的输入。该判别器是一个 ∑ 三层全连接网络。 L= L (7) 散度是衡量一个概率分布与另一个参考概率分布 j∈A KL 其中代表我们选定用于输出的层集合。在实验 A 差异的指标。在此我们通过最小化学生网络 的输 S 中，我们采用网络每个模块的最后一层（按模块划 出与教师网络生成的软标签 之间的 散度 p(X) p(X) KL 分）。\n来训练学生网络。我们的损失函数为： 4.3 堆叠判别器 我们通过训练学生网络并冻结教师模块，使其与 S 一系列堆叠判别器进行对抗性学习，从而生成学 D 生输出。判别器试图通过最大化以下目标函数 D ∑ ∑n 1 p(X) （Goodfellow 等人，2014）来对其输入 x 进行教师或 L(S) = − p(X) log() 学生分类： n p(X) c i=1 L= E log D(x) + E log(1 − D(x)) (8) ∑ ∑n 1 x∼p x∼p = − p(X) logp(X) (4) 其中 是生成网络的输出。同时，试图通过 n x ∼ p S S c i=1 最小化来生成相似的输出以欺骗判别器。 L ∑ ∑n",
      "full_text": "0.9 0.1 0.6 0.2 0.3 自适应池化0.5 0.7 0.3 0 0.5 0 0 0 0.1!\n教师输出 0 0 2 索引 0 0 2 索引 输出尺寸 = 3 数值 梯度!! 0.9 0.6 0.7 0.3 0.5 0.1 教师？\n前进 反向传播 学生？\n学生输出 图：前向与反向阶段中自适应池化的处理流程。此 5 处以最大池化操作为例进行说明。\n图：我们提出的判别器示意图。我们将教师和学 4 生的输出拼接作为判别器的输入。该判别器是一个 ∑ 三层全连接网络。 L= L (7) 散度是衡量一个概率分布与另一个参考概率分布 j∈A KL 其中代表我们选定用于输出的层集合。在实验 A 差异的指标。在此我们通过最小化学生网络 的输 S 中，我们采用网络每个模块的最后一层（按模块划 出与教师网络生成的软标签 之间的 散度 p(X) p(X) KL 分）。\n来训练学生网络。我们的损失函数为： 4.3 堆叠判别器 我们通过训练学生网络并冻结教师模块，使其与 S 一系列堆叠判别器进行对抗性学习，从而生成学 D 生输出。判别器试图通过最大化以下目标函数 D ∑ ∑n 1 p(X) （Goodfellow 等人，2014）来对其输入 x 进行教师或 L(S) = − p(X) log() 学生分类： n p(X) c i=1 L= E log D(x) + E log(1 − D(x)) (8) ∑ ∑n 1 x∼p x∼p = − p(X) logp(X) (4) 其中 是生成网络的输出。同时，试图通过 n x ∼ p S S c i=1 最小化来生成相似的输出以欺骗判别器。 L ∑ ∑n",
      "keywords": [],
      "page_range": [
        1,
        1
      ],
      "summary_status": "failed",
      "llm_meta": {
        "model": "gpt-4o-mini",
        "temperature": 0.3,
        "prompt_version": "v1",
        "created_at": "2026-02-07T09:01:37.115585+00:00"
      }
    },
    {
      "group_id": "group-4",
      "chunk_indices": [
        8
      ],
      "char_count": 983,
      "summary": "+ 1 由于训练过程中教师网络的参数固定，第一项可被 p(X) logp(X) n 移除，最终目标损失函数为： c i=1 其中第二项代表教师网络软标签的熵，对",
      "digest": "+ 1 由于训练过程中教师网络的参数固定，第一项可被 p(X) logp(X) n 移除，最终目标损失函数为： c i=1 其中第二项代表教师网络软标签的熵，对于 而言 T 是常数项。我们可以将其移除，并简化为最小化以 L = E log(1 − D(x)) (9) 下交叉熵损失： x∼p 学生模型 在公式 中，表示教师模型与学生模型输出的拼 10 x 接结果。我们将 x 输入判别器——一个三层全连接 网络。判别器的完整结构如图 所示。 ∑ ∑n 4 1 L(S) = − p(X) logp(X) (5) 多阶段判别器。采用多阶段判别器可以逐步细化学 n c i=1 生模型的输出。如图 3 所示，最终的对抗损失是各 阶段损失的加和： 中间对齐4.2 ∑自适应池化。自适应池化层的目的是对齐教师网络 L= L (10) 和学生网络的中间输出。这类层与普通的池化层 j∈A （如平均池化或最大池化）类似，但能够针对不同 设|A|表示判别器数量。实验中，我们对 CIFAR 尺寸的输入生成预定义长度的输出。凭借这一特 （）和 （等）数据Krizhevsky 2009 SVHN Netzer 2011 性，我们可以使用不同的教师网络并将其输出池化 集使用 3 个判别器，对 ImageNet（Deng 等 2009） 为与学生网络输出相同的长度。池化层在降低特征 使用个判别器。 5 图分辨率的同时还能实现空间不变性。因此，对于 基于相似性与判别器的联合训练根据上述定义4.4 中间输出，我们的损失函数为： 与分析，我们将公式 7 中的相似性损失与公式 10 中的对抗性损失整合至最终损失函数中。整个框架 通过以下目标函数进行端到端训练： L= d(f (T), f (S)) (6) (11) 其中α和β为权衡权重。通过交叉验证，我们在L = αL + βL其中 T 和 S 分别表示教师网络和学生网络第 j 层的输 实验中将其设为。同时采用加权系数来平衡不同模出，是可选用平均或最大值运算的自适应池化函 1f 块的贡献度：对于 3 模块网络使用[0.01, 0.05, 1]，5数。图 5 展示了自适应池化的过程。由于我们采用 模块网络则采用。多个中间层，最终的相似度损失是各层损失的加权 [0.001, 0.01, 0.05, 0.1, 1] 和： 4889",
      "full_text": "+ 1 由于训练过程中教师网络的参数固定，第一项可被 p(X) logp(X) n 移除，最终目标损失函数为： c i=1 其中第二项代表教师网络软标签的熵，对于 而言 T 是常数项。我们可以将其移除，并简化为最小化以 L = E log(1 − D(x)) (9) 下交叉熵损失： x∼p 学生模型 在公式 中，表示教师模型与学生模型输出的拼 10 x 接结果。我们将 x 输入判别器——一个三层全连接 网络。判别器的完整结构如图 所示。 ∑ ∑n 4 1 L(S) = − p(X) logp(X) (5) 多阶段判别器。采用多阶段判别器可以逐步细化学 n c i=1 生模型的输出。如图 3 所示，最终的对抗损失是各 阶段损失的加和： 中间对齐4.2 ∑自适应池化。自适应池化层的目的是对齐教师网络 L= L (10) 和学生网络的中间输出。这类层与普通的池化层 j∈A （如平均池化或最大池化）类似，但能够针对不同 设|A|表示判别器数量。实验中，我们对 CIFAR 尺寸的输入生成预定义长度的输出。凭借这一特 （）和 （等）数据Krizhevsky 2009 SVHN Netzer 2011 性，我们可以使用不同的教师网络并将其输出池化 集使用 3 个判别器，对 ImageNet（Deng 等 2009） 为与学生网络输出相同的长度。池化层在降低特征 使用个判别器。 5 图分辨率的同时还能实现空间不变性。因此，对于 基于相似性与判别器的联合训练根据上述定义4.4 中间输出，我们的损失函数为： 与分析，我们将公式 7 中的相似性损失与公式 10 中的对抗性损失整合至最终损失函数中。整个框架 通过以下目标函数进行端到端训练： L= d(f (T), f (S)) (6) (11) 其中α和β为权衡权重。通过交叉验证，我们在L = αL + βL其中 T 和 S 分别表示教师网络和学生网络第 j 层的输 实验中将其设为。同时采用加权系数来平衡不同模出，是可选用平均或最大值运算的自适应池化函 1f 块的贡献度：对于 3 模块网络使用[0.01, 0.05, 1]，5数。图 5 展示了自适应池化的过程。由于我们采用 模块网络则采用。多个中间层，最终的相似度损失是各层损失的加权 [0.001, 0.01, 0.05, 0.1, 1] 和： 4889",
      "keywords": [],
      "page_range": [
        4,
        4
      ],
      "summary_status": "failed",
      "llm_meta": {
        "model": "gpt-4o-mini",
        "temperature": 0.3,
        "prompt_version": "v1",
        "created_at": "2026-02-07T09:01:37.115585+00:00"
      }
    },
    {
      "group_id": "group-5",
      "chunk_indices": [
        9,
        10,
        11,
        12
      ],
      "char_count": 2619,
      "summary": "基于对抗学习的多模型集成5. 我们采用了标准数据增强方案(Lee 等人 2015; （） 等人、 和 MEAL Romero 2015; Larsson Mai",
      "digest": "基于对抗学习的多模型集成5. 我们采用了标准数据增强方案(Lee 等人 2015; （） 等人、 和 MEAL Romero 2015; Larsson Maire Shakhnarovich 2016; Huang 等人 2017a; Liu 等人 2017)。本节报告 我们采用了一种简单直观的训练方法实现模型集 的是在全训练集上训练后的测试错误率。\n成。由于不同网络结构会产生不同的输出分布（可 （街景门牌号码数据集）。该数据集（SVHN Netzer 视为软标签知识），我们利用这些软标签来训练学/ 等人，2011）包含 32×32 像素的彩色数字图像， 生网络，从而将不同架构的知识压缩到单一网络 每个数字对应一个类别。训练集和测试集分别包含 中。这样就能以零额外测试成本实现多神经网络集 604,388 张和 26,032 张图像。遵循先前研究 成的矛盾性目标。 （等人，； 等人，；Goodfellow 2013 Huang 2016 2017a；Liu 等人，2017），我们划分出 6,000 张图 像作为验证集，其余图像用于训练且不进行数据增 强。\n学习流程5.1 ImageNet（图像网络）。ILSVRC 2012 分类数据集 （等人，）包含 个类别，共计Deng 2009 1,000 120为明确理解学生网络的学习机制，我们设定两个条 万张训练图像和 5 万张验证图像。我们采用 件：首先，学生网络与教师网络结构相同；其次， （、 和，）的数据增KrizhevskySutskever Hinton 2012在集成学习过程中，我们固定学生网络结构，并在 强方案，并在测试时应用与（等人，Huang 每次迭代中随机选择教师网络结构。）相同的操作2017a 学习流程包含两个阶段：首先预训练教师网络构建 网络架构6.2 模型库，由于使用分类任务训练这些模型，本阶段 我们采用了几种流行的网络架构作为教师模型库， 可采用交叉熵损失作为主要训练目标；其 softmax 包括 （和）、 VGGNetSimonyan Zisserman 2015 次通过最小化公式 11 中的损失函数 L，使学生网络 ResNet（He 等人 2016）、DenseNet（Huang 等人 输出逼近教师网络输出。）、 （等人）、2017b MobileNet Howard 2017 shakes",
      "full_text": "基于对抗学习的多模型集成5. 我们采用了标准数据增强方案(Lee 等人 2015; （） 等人、 和 MEAL Romero 2015; Larsson Maire Shakhnarovich 2016; Huang 等人 2017a; Liu 等人 2017)。本节报告 我们采用了一种简单直观的训练方法实现模型集 的是在全训练集上训练后的测试错误率。\n成。由于不同网络结构会产生不同的输出分布（可 （街景门牌号码数据集）。该数据集（SVHN Netzer 视为软标签知识），我们利用这些软标签来训练学/ 等人，2011）包含 32×32 像素的彩色数字图像， 生网络，从而将不同架构的知识压缩到单一网络 每个数字对应一个类别。训练集和测试集分别包含 中。这样就能以零额外测试成本实现多神经网络集 604,388 张和 26,032 张图像。遵循先前研究 成的矛盾性目标。 （等人，； 等人，；Goodfellow 2013 Huang 2016 2017a；Liu 等人，2017），我们划分出 6,000 张图 像作为验证集，其余图像用于训练且不进行数据增 强。\n学习流程5.1 ImageNet（图像网络）。ILSVRC 2012 分类数据集 （等人，）包含 个类别，共计Deng 2009 1,000 120为明确理解学生网络的学习机制，我们设定两个条 万张训练图像和 5 万张验证图像。我们采用 件：首先，学生网络与教师网络结构相同；其次， （、 和，）的数据增KrizhevskySutskever Hinton 2012在集成学习过程中，我们固定学生网络结构，并在 强方案，并在测试时应用与（等人，Huang 每次迭代中随机选择教师网络结构。）相同的操作2017a 学习流程包含两个阶段：首先预训练教师网络构建 网络架构6.2 模型库，由于使用分类任务训练这些模型，本阶段 我们采用了几种流行的网络架构作为教师模型库， 可采用交叉熵损失作为主要训练目标；其 softmax 包括 （和）、 VGGNetSimonyan Zisserman 2015 次通过最小化公式 11 中的损失函数 L，使学生网络 ResNet（He 等人 2016）、DenseNet（Huang 等人 输出逼近教师网络输出。）、 （等人）、2017b MobileNet Howard 2017 shakeshake（Gastaldi 2017）等。对于 VGGNet，我 学习过程在算法中阐述如下。 们使用带有批量归一化（和）的 1 Ioffe Szegedy 2015 19 层版本。对于 ResNet，在 CIFAR 和 SVHN 数据集 上使用 层网络，在 上使用 层网算法：基于对抗学习的多模型集成（）。 18 ImageNet 50 1 MEAL 络。对于 DenseNet，我们采用深度 L=100、增长率 的 结构。对于 网络，使用第一阶段： k=24 BC shakeshake 26 构建并预训练教师模型库，包含： 层 2×96d 版本。需要注意的是，由于计算成本较 T = {T, T,... T } VGGNet （和）、 （等）、高，我们仅在学生网络为 架构时才将其Simonyan Zisserman 2015 ResNet He 2016 shakeshake （等）、 （等DenseNet Huang 2017b MobileNet Howard 作为教师模型使用。）、 （）等模型。第二阶段：2017 Shake-ShakeGastaldi\nT = {T, T,... T } VGGNet （和）、 （等）、高，我们仅在学生网络为 架构时才将其Simonyan Zisserman 2015 ResNet He 2016 shakeshake （等）、 （等DenseNet Huang 2017b MobileNet Howard 作为教师模型使用。）、 （）等模型。第二阶段：2017 Shake-ShakeGastaldi 2017 表 1：使用 VGGNet-19 w/BN 在 CIFAR-10 数据集上 的消融研究结果。详见第 节说明。 6.3 1: 函数 T SM (T) `dis. `dis. 交叉熵 中间对抗 测试错误率(%) 基准模型(VGG-19 w/BN)(Simonyan 和 2: T← RS(T). 随机选择 Zisserman 2015) 6.34 3: 返回 T 结束函数! 6.97 4:! 6.22 5: 每次迭代执行以下操作：! 6.18 ← 随机选择一个教师模型6: T T SM (T). 7: S= arg minL(T, S).!! 6.10 对学生模型进行对抗学习!! 6.17!!! 5.83!!! 7.578: 结束循环 消融实验6.3 实验与分析6. 我们首先探究框架的各个设计原则。为此消 MEAL 我们在多个基准数据集上实证验证了 方法的有 融研究，我们在 数据集上使用 MEAL CIFAR-10 VGGNet-19 效性。所有实验均在 PyTorch 平台(Paszke 等人 2017) w/BN（同时作为教师和学生模型）设计了若干对照 实现。 实验。除非考察特定组件或结构，所有实验均采用 统一配置。\n数据集6.1 实验结果主要汇总于表。前三行数据表明我们仅 1 使用了、或交叉熵数据集。两个 数据集 包 ` `CIFAR CIFAR (Krizhevsky 2009) 含尺寸为 的彩色自然图像。 包含 32×32 CIFAR-10 10 个类别， 包含个类别。每个数据集 在四边各填充3 像素零值后，随机裁剪生成 图像，CIFAR-100 100 4 32x32 中，训练集和测试集分别包含 和 张图 并以概率进行水平镜像翻转。 50,000 10,000 0.5 像。 4890\n3.80 1.80 3.76 Single 20.23 Single 1.77 Single 24.0 23.85 Single Single AL Single AL Single AL 23.71 Single AL3.75 3.74 3.73 20True Ens. True Ens. 1.75 True Ens. 23.5 True Ens.",
      "keywords": [],
      "page_range": [
        5,
        5
      ],
      "summary_status": "failed",
      "llm_meta": {
        "model": "gpt-4o-mini",
        "temperature": 0.3,
        "prompt_version": "v1",
        "created_at": "2026-02-07T09:01:37.115585+00:00"
      }
    },
    {
      "group_id": "group-6",
      "chunk_indices": [
        13,
        14,
        15
      ],
      "char_count": 2373,
      "summary": "Our Ens.） Our Ens.） Our Ens.） Our Ens. 3.70 %） 测试错误率（% 19.04 测试错误率（% 测试错误率（23.0 ",
      "digest": "Our Ens.） Our Ens.） Our Ens.） Our Ens. 3.70 %） 测试错误率（% 19.04 测试错误率（% 测试错误率（23.0 测试误差（% 19 22.76 3.65 1.70 1.69 22.5 3.60 18 17.73 1.66 22.0Top-1 3.56 1.65 1.64 21.69 17.213.55 21.517 3.50 1.60 21.0 CIFAR-10 CIFAR-100 SVHN ImageNet 图：在、、 和 数据集上的错误率（）。每幅图中从左至右依次展示： 6 CIFAR-10CIFAR-100 SVHN ImageNet % 1) 基础模型；2) 采用对抗学习的基础模型；3) 真实集成/传统集成方法；4) 我们的集成结果。前三个数据集使用 作为学生模型，最后一个数据集（）采用。DenseNet ImageNet ResNet 从网络最后一层提取的损失。这与知识蒸馏方法类 表：在 数据集上与 基准方法 3 CIFAR-10 Dropout 似。我们可以观察到使用交叉熵能获得最佳准确 (Srivastava 等 2014)的错误率(%)对比 率。随后我们采用更多中间层输出来计算损失，如 网络架构 Dropout (%) 我们的集成方法 (%)第 4、5 行所示。显然，包含更多网络层能提升性 带 的 和 BN VGG-19 (Simonyan Zisserman 2015) 6.89 5.55 能。最后我们引入判别器来验证对抗学习的有效 GoogLeNet (Szegedy 等人, 2015) 5.37 4.83 ResNet-18 (He 等人, 2016) 性。结合交叉熵、中间层和对抗学习取得了最优结 4.69 4.35 果。此外，我们采用基于平均的自适应池化进行对 等人DenseNet-BC (k=24) (Huang, 2017b) 3.75 3.54 齐。也尝试过最大池化操作，但准确率显著下降 （）。6.32% 与传统集成方法的对比结果。结果汇总于图传统集成方法的计算量是各独立模型之和。因此我6.4 6 们的方法在实现更优性能的同时还具有更高效率。和表 2 中。在图 6 中，我们比较了相同网络架构在 多个数据集（除 外）上的错误率。可以 最值得注意的是，我们的 MEAL Plus 在\n(Huan",
      "full_text": "Our Ens.） Our Ens.） Our Ens.） Our Ens. 3.70 %） 测试错误率（% 19.04 测试错误率（% 测试错误率（23.0 测试误差（% 19 22.76 3.65 1.70 1.69 22.5 3.60 18 17.73 1.66 22.0Top-1 3.56 1.65 1.64 21.69 17.213.55 21.517 3.50 1.60 21.0 CIFAR-10 CIFAR-100 SVHN ImageNet 图：在、、 和 数据集上的错误率（）。每幅图中从左至右依次展示： 6 CIFAR-10CIFAR-100 SVHN ImageNet % 1) 基础模型；2) 采用对抗学习的基础模型；3) 真实集成/传统集成方法；4) 我们的集成结果。前三个数据集使用 作为学生模型，最后一个数据集（）采用。DenseNet ImageNet ResNet 从网络最后一层提取的损失。这与知识蒸馏方法类 表：在 数据集上与 基准方法 3 CIFAR-10 Dropout 似。我们可以观察到使用交叉熵能获得最佳准确 (Srivastava 等 2014)的错误率(%)对比 率。随后我们采用更多中间层输出来计算损失，如 网络架构 Dropout (%) 我们的集成方法 (%)第 4、5 行所示。显然，包含更多网络层能提升性 带 的 和 BN VGG-19 (Simonyan Zisserman 2015) 6.89 5.55 能。最后我们引入判别器来验证对抗学习的有效 GoogLeNet (Szegedy 等人, 2015) 5.37 4.83 ResNet-18 (He 等人, 2016) 性。结合交叉熵、中间层和对抗学习取得了最优结 4.69 4.35 果。此外，我们采用基于平均的自适应池化进行对 等人DenseNet-BC (k=24) (Huang, 2017b) 3.75 3.54 齐。也尝试过最大池化操作，但准确率显著下降 （）。6.32% 与传统集成方法的对比结果。结果汇总于图传统集成方法的计算量是各独立模型之和。因此我6.4 6 们的方法在实现更优性能的同时还具有更高效率。和表 2 中。在图 6 中，我们比较了相同网络架构在 多个数据集（除 外）上的错误率。可以 最值得注意的是，我们的 MEAL Plus 在\n(Huang, 2017b) 3.75 3.54 齐。也尝试过最大池化操作，但准确率显著下降 （）。6.32% 与传统集成方法的对比结果。结果汇总于图传统集成方法的计算量是各独立模型之和。因此我6.4 6 们的方法在实现更优性能的同时还具有更高效率。和表 2 中。在图 6 中，我们比较了相同网络架构在 多个数据集（除 外）上的错误率。可以 最值得注意的是，我们的 MEAL Plus 在 ImageNet 上取 ImageNet 得了 错误率、 错误率 的优观察到，在这些数据集上我们的结果始终优于单一 Top-1 21.79% Top-5 5.99% 模型和传统集成方法。传统集成方法是通过对所有 异表现，远超原始 的 和传统 ResNet-50 23.85%/7.13% 集成方法的。这显示出该方法在大规教师模型的最终预测结果取平均获得的。表 2 展示 22.76%/6.49% 了相同数据集上不同网络架构的错误率对比。在大模真实数据集上的巨大潜力。\n多数情况下，我们的集成方法比所有基线（包括单 一模型和传统集成）都取得了更低的错误率。 表 4：ImageNet 数据集验证错误率(%) 表：数据集上不同网络架构的错误率 2CIFAR-10 方法 Top-1 准确率(%) Top-5 准确率(%) 浮点运算次数 单图推理时间 （%） 教师网络: VGG-19 w/BN 25.76 8.15 195.2 亿次 5.70×10 秒 ResNet-50 23.85 7.13 40.9 亿次 1.10×10 秒 我们的方法(ResNet-50) 23.58 6.86 40.9 亿次 1.10×10 秒 传统集成方法 22.76 6.49 23.61B 1.67 × 10s 我们的增强版(ResNet-50) 21.79 5.99 4.09B 1.10 × 10s 网络架构 单一模型（%） 传统集成（%） 本方法集成（%） MobileNet (Howard et al. 2017) 10.70 – 8.09 VGG-19 w/ BN (Simonyan and Zisserman 2015) 6.34 – 5.55 DenseNet-BC (k=24) (Huang et al. 2017b) 3.76 3.73 3.54 Shake-Shake-26 2x96d (Gastaldi 2017) 2.86 2.79 2.54 与 Dropout 的对比。我们将 MEAL 与\"隐式\"方法 进行对比。如表 所Dropout(Srivastava et al. 2014) 3 示，本次对比采用了多种网络架构。所有模型均训 练相同周期数，训练过程中节点丢弃概率设为 0.2。可以观察到，我们的方法在所有网络上都取 得了优于 的性能表现。 Dropout 我们在 上的基于学习的集成结果。如表 ImageNet 4 图 7：我们的集成方法在 CIFAR-10 数据集上不同训 所示，我们将我们的集成方法与原始模型和传统集 练预算下的准确率表现 成方法进行比较。我们使用带 的 和 BN VGG19 ResNet-50 作为教师模型，并采用 ResNet50 作为学 生模型 4表示使用更强大的教师模型如 ResNet-101/152 4891",
      "keywords": [],
      "page_range": [
        6,
        6
      ],
      "summary_status": "failed",
      "llm_meta": {
        "model": "gpt-4o-mini",
        "temperature": 0.3,
        "prompt_version": "v1",
        "created_at": "2026-02-07T09:01:37.115585+00:00"
      }
    },
    {
      "group_id": "group-7",
      "chunk_indices": [
        16,
        17
      ],
      "char_count": 1745,
      "summary": "MobileNet VGG19-BN 密集连接网络 6.7 6.2 3.75 10.0 基线： （等 5.9 VGG19-BN 基线：6.34%（Simonya",
      "digest": "MobileNet VGG19-BN 密集连接网络 6.7 6.2 3.75 10.0 基线： （等 5.9 VGG19-BN 基线：6.34%（Simonyan 密集连接网络基线：MobileNet 10.70% Howard 等人，2015） 3.76%） 人，2017 年）） 3.70 （Huang 等人，2017 年） 5.8% 9.5 % (%)测试错误率（测试错误率（测试错误率 3.65 9.0 5.7 8.5 3.60 5.6 3.558.0 5.5 7.5 3.501 2 3 4 5 1 2 3 4 5 1 2 3 4 5 集成数量 集成模型数量 集成模型数量 图：、带 的 和密集连接网络在 数据集上的错误率 8MobileNet BN VGG-19 CIFAR-10 (%) 图：通过 （和）对k = 10 t-SNE Maaten Hinton 2008 ImageNet 数据集验证图像的可视化结果。我们在 个类别中随机选取个类别进行展示。左侧 图：四个网络间的概率分布对比。左图： 1000 10 9 是采用标准训练策略的单一模型结果，右侧是我们 SqueezeNet 与 VGGNet 对比；右图：ResNet 与 对比。 的集成模型结果。\nDenseNet，右图展示的是 关1, 2,..., 1000 (pResNet, pDenseNet) 系。若两个网络的标签分布完全一致，气泡将落在 分析6.5 主对角线上。有趣的是，左侧（较弱网络组合）的 预测多样性明显高于右侧（较强网络组合）。这种 集成规模的有效性。图 8 展示了三种架构在 CIFAR- 现象合乎逻辑，因为更强的模型通常会产生更接近 数据集上随集成规模变化的性能表现。虽然集10 真实标签的预测。简而言之，这种预测差异可被用 成更多模型通常能获得更高准确率，但我们有两个 于构建有效的集成模型，而我们的方法正是利用这 重要发现：首先，观察到我们的单模型集成已显\" \" 种多样性监督来提升基准模型性能。\n著超越基线模型，这证明了对抗学习的有效性；其 次，当使用过多集成模型训练时， 和VGGNet DenseNet 网络会出现准确率下降现象。在大多数情 况下，四个模型的集成能获得最佳性能。\n著超越基线模型，这证明了对抗学习的有效性；其 次，当使用过多集成模型训练时， 和VGGNet DenseNe",
      "full_text": "MobileNet VGG19-BN 密集连接网络 6.7 6.2 3.75 10.0 基线： （等 5.9 VGG19-BN 基线：6.34%（Simonyan 密集连接网络基线：MobileNet 10.70% Howard 等人，2015） 3.76%） 人，2017 年）） 3.70 （Huang 等人，2017 年） 5.8% 9.5 % (%)测试错误率（测试错误率（测试错误率 3.65 9.0 5.7 8.5 3.60 5.6 3.558.0 5.5 7.5 3.501 2 3 4 5 1 2 3 4 5 1 2 3 4 5 集成数量 集成模型数量 集成模型数量 图：、带 的 和密集连接网络在 数据集上的错误率 8MobileNet BN VGG-19 CIFAR-10 (%) 图：通过 （和）对k = 10 t-SNE Maaten Hinton 2008 ImageNet 数据集验证图像的可视化结果。我们在 个类别中随机选取个类别进行展示。左侧 图：四个网络间的概率分布对比。左图： 1000 10 9 是采用标准训练策略的单一模型结果，右侧是我们 SqueezeNet 与 VGGNet 对比；右图：ResNet 与 对比。 的集成模型结果。\nDenseNet，右图展示的是 关1, 2,..., 1000 (pResNet, pDenseNet) 系。若两个网络的标签分布完全一致，气泡将落在 分析6.5 主对角线上。有趣的是，左侧（较弱网络组合）的 预测多样性明显高于右侧（较强网络组合）。这种 集成规模的有效性。图 8 展示了三种架构在 CIFAR- 现象合乎逻辑，因为更强的模型通常会产生更接近 数据集上随集成规模变化的性能表现。虽然集10 真实标签的预测。简而言之，这种预测差异可被用 成更多模型通常能获得更高准确率，但我们有两个 于构建有效的集成模型，而我们的方法正是利用这 重要发现：首先，观察到我们的单模型集成已显\" \" 种多样性监督来提升基准模型性能。\n著超越基线模型，这证明了对抗学习的有效性；其 次，当使用过多集成模型训练时， 和VGGNet DenseNet 网络会出现准确率下降现象。在大多数情 况下，四个模型的集成能获得最佳性能。\n著超越基线模型，这证明了对抗学习的有效性；其 次，当使用过多集成模型训练时， 和VGGNet DenseNet 网络会出现准确率下降现象。在大多数情 况下，四个模型的集成能获得最佳性能。\n训练预算。在数据集上，标准训练周期为 6.6 学习特征的可视化分析 CIFAR 300 轮次。直观来看，我们的集成方法能从更多训为进一步探究模型实际学习到的内容，我们对单一 练预算中获益，因为我们使用了多样化的软分布作模型和集成模型的嵌入特征进行了可视化呈现。该 为标签。图 7 展示了性能与训练预算的关系。结果 可视化采用 工具（和， 年） tSNE Maaten Hinton 2008 表明超过轮次是最优选择，我们的模型约在 400 绘制，特征来源于 ResNet-50 最后一个卷积层（2048 500 轮次时达到完全收敛。 维）。我们在 上随机选取 个类别进行 ImageNet 10 监督信号的多样性。我们假设不同架构生成的软标 展示，结果如图 10 所示，可以明显看出我们的模型 签不仅信息丰富，而且在目标类别上具有多样性。具有更优的特征嵌入效果。\n我们通过可视化两个不同网络 输出的两两 softmax 相关性来定性衡量这种多样性。具体而言，我们计 结论7. 算 ImageNet 数据集中每张训练图像的 softmax 预测 我们提出了 一种基于学习的集成方法，通值，并可视化对应的成对结果。图展示了四种架 MEAL—— 9 过对抗学习将多模型知识压缩至单一网络。在构的气泡图。左图中，每个气泡的坐标代表一对第、 和 三个基准数据集上个预测值（） CIFAR-10/100 SVHN ImageNet k pSequeezeNet, pVGGNet 的实验验证了该方法的有效性，其在多种网络架构 上均达到了最先进的准确率。后续工作将重点探索 MEAL 在跨域集成与自适应方面的应用。 4892",
      "keywords": [],
      "page_range": [
        7,
        7
      ],
      "summary_status": "failed",
      "llm_meta": {
        "model": "gpt-4o-mini",
        "temperature": 0.3,
        "prompt_version": "v1",
        "created_at": "2026-02-07T09:01:37.115585+00:00"
      }
    },
    {
      "group_id": "group-8",
      "chunk_indices": [
        18,
        19,
        20
      ],
      "char_count": 2604,
      "summary": "致谢 Larsson, G.; Maire, M.; 与 Shakhnarovich, G. 2016. FractalNet： 本研究部分由国家重点研发计划（",
      "digest": "致谢 Larsson, G.; Maire, M.; 与 Shakhnarovich, G. 2016. FractalNet： 本研究部分由国家重点研发计划（编号 无需残差的超深度神经网络。arXiv 预印本。 2017YFC0803700）、国家自然科学基金（编号 arXiv:1605.07648 和）以及上海市科学技术委员会Lee, C.-Y.; Xie, S.; Gallagher, P. W.; 等. 2015. 深度监督网络。 61572138 U1611461 发表于 AISTATS。\n参考文献 李毅、杨军、宋阳、曹磊、罗杰和李立杰， 年。2017 阿尼尔，；佩雷拉，；帕索斯，；奥尔曼迪，；基于蒸馏学习的噪声标签学习。收录于 会议。R. G. A. R. ICCV 达尔，；辛顿，。通过在线蒸馏进行大规G. E. G. E. 2018 刘钊、李杰、沈哲、黄刚、严硕和张诚， 年。通过2017 模分布式神经网络训练。发表于。 ICLR 网络瘦身学习高效卷积网络。收录于 会议。 ICCV 巴盖里内扎德，H.；霍顿，M.；拉斯特加里，M.；法哈 马腾·范登和辛顿·杰弗里，2008 年。使用 t-SNE 进行数据 迪，。标签精炼厂：通过标签递进改进A. 2018 ImageNet 可视化。\n分类。发表于。 ECCV 《机器学习研究期刊》第 卷（月）： 页。 9 11 2579-2605 白，Y.；张，Y.；丁，M.；加尼姆，B. 2018。利用生成对 Netzer, Y.; Wang, T.; Coates, A.; Bissacco, A.; Wu, B.; 及 Ng, A. Y.\n抗网络在野外寻找微小面孔。陈，T.；古德费洛，I.；施\n分类。发表于。 ECCV 《机器学习研究期刊》第 卷（月）： 页。 9 11 2579-2605 白，Y.；张，Y.；丁，M.；加尼姆，B. 2018。利用生成对 Netzer, Y.; Wang, T.; Coates, A.; Bissacco, A.; Wu, B.; 及 Ng, A. Y.\n抗网络在野外寻找微小面孔。陈，T.；古德费洛，I.；施\n2011. 通过无监督特征学习识别自然图像中的数字。收录 伦斯，。：通过知识迁移加速学习。发表于J. 2016 Net2net 于《深度学习与无监督特征学习研讨会》 年第NIPS",
      "full_text": "致谢 Larsson, G.; Maire, M.; 与 Shakhnarovich, G. 2016. FractalNet： 本研究部分由国家重点研发计划（编号 无需残差的超深度神经网络。arXiv 预印本。 2017YFC0803700）、国家自然科学基金（编号 arXiv:1605.07648 和）以及上海市科学技术委员会Lee, C.-Y.; Xie, S.; Gallagher, P. W.; 等. 2015. 深度监督网络。 61572138 U1611461 发表于 AISTATS。\n参考文献 李毅、杨军、宋阳、曹磊、罗杰和李立杰， 年。2017 阿尼尔，；佩雷拉，；帕索斯，；奥尔曼迪，；基于蒸馏学习的噪声标签学习。收录于 会议。R. G. A. R. ICCV 达尔，；辛顿，。通过在线蒸馏进行大规G. E. G. E. 2018 刘钊、李杰、沈哲、黄刚、严硕和张诚， 年。通过2017 模分布式神经网络训练。发表于。 ICLR 网络瘦身学习高效卷积网络。收录于 会议。 ICCV 巴盖里内扎德，H.；霍顿，M.；拉斯特加里，M.；法哈 马腾·范登和辛顿·杰弗里，2008 年。使用 t-SNE 进行数据 迪，。标签精炼厂：通过标签递进改进A. 2018 ImageNet 可视化。\n分类。发表于。 ECCV 《机器学习研究期刊》第 卷（月）： 页。 9 11 2579-2605 白，Y.；张，Y.；丁，M.；加尼姆，B. 2018。利用生成对 Netzer, Y.; Wang, T.; Coates, A.; Bissacco, A.; Wu, B.; 及 Ng, A. Y.\n抗网络在野外寻找微小面孔。陈，T.；古德费洛，I.；施\n分类。发表于。 ECCV 《机器学习研究期刊》第 卷（月）： 页。 9 11 2579-2605 白，Y.；张，Y.；丁，M.；加尼姆，B. 2018。利用生成对 Netzer, Y.; Wang, T.; Coates, A.; Bissacco, A.; Wu, B.; 及 Ng, A. Y.\n抗网络在野外寻找微小面孔。陈，T.；古德费洛，I.；施\n2011. 通过无监督特征学习识别自然图像中的数字。收录 伦斯，。：通过知识迁移加速学习。发表于J. 2016 Net2net 于《深度学习与无监督特征学习研讨会》 年第NIPS 2011。邓，；董，；索赫尔，；李，；等。ICLR J. W. R. L.-J. 卷。5。：一个大规模分层图像数据库。发表于2009ImageNet Papernot, N.; Abadi, M.; Erlingsson, U.; Goodfellow, I.; 及。迪特里希，。机器学习中的集成方法。CVPR T. G. 2000 Talwar, K. 2017. 基于私有训练数据的深度学习半监督知识 发表于多分类器系统国际研讨会，。加斯塔尔迪，1-15 X. 迁移。发表于《ICLR》。。 正则化。 预印本2017Shake-shake arXiv Paszke, A.; Gross, S.; Chintala, S.; Chanan, G.; Yang, E.; DeVito, arXiv:1705.07485。\n及Z.; Lin, Z.; Desmaison, A.; Antiga, L.; Lerer, A. 2017. PyTorch 古德费洛，；沃德法利，；米尔扎，；库维尔，I. J. - D. M. 中的自动微分机制。；本吉奥，。 网络。发表于。古德A. Y. 2013 Maxout ICML 和 当网络产生分歧时：混 费洛，；普热阿巴迪，；米尔扎，；徐，；沃德 Perrone, M. P., Cooper, L. N. 1995. I. - J. M. B. - 合神经网络的集成方法收录于《我们如何学习；我们如 法利，；奥泽尔，；库维尔，；本吉奥，。.\nD. S. A. Y. 2014 何记忆：探索大脑与神经系统理解：Leon N Cooper 精选 生成对抗网络。发表于 NIPS。\n论文集》. 世界科技出版社.\nD. S. A. Y. 2014 何记忆：探索大脑与神经系统理解：Leon N Cooper 精选 生成对抗网络。发表于 NIPS。\n论文集》. 世界科技出版社.\n汉森（）与萨拉蒙（） 年发表Hansen, L. K. Salamon, P. 1990 342–358. 《神经网络集成方法》，载于《模式分析与机器智能IEEE 和 汇刊》。 Romero, A.; Ballas, N.; Kahou, S. E.; Chassang, A.; Gatta, C.; 12(10):993-1001：瘦身深度网络的训练技巧发表于Bengio, Y. 2015. Fitnets. 何恺明（）、张翔（）、任少卿（He, K. Zhang, X. Ren, 和 超深度卷积网络在ICLR. Simonyan, K., Zisserman, A. 2015.）、孙剑（） 年在 会议上提出《深度S. Sun, J. 2016 CVPR 大规模图像识别中的应用发表于. ICLR. Singh, S.; Hoiem, D.; 残差学习在图像识别中的应用》。辛顿（）、Hinton, G. 和：深度架构集成学习方法收录 Forsyth, D. 2016. Swapout. 维尼亚尔斯（）、迪恩（） 年发表Vinyals, O. Dean, J. 2015 于《神经信息处理系统进展》, 28–36. 《神经网络知识蒸馏技术》， 预印本arXiv 等Srivastava, N.; Hinton, G. E.; Krizhevsky, A.;. 2014. arXiv:1503.02531。霍华德（Howard, A. G.）团队 2017 年开：防止神经网络过拟合的简单方法Dropout. JMLR. Szegedy,发《MobileNets：面向移动视觉应用的高效卷积神经网 等 卷积网络的深度探C.; Liu, W.; Jia, Y.; Sermanet, P.;. 2015. 络》。\n索发表于. CVPR.\n万林；蔡勒，；张帅；乐存，；弗格斯， 年。",
      "keywords": [],
      "page_range": [
        8,
        8
      ],
      "summary_status": "failed",
      "llm_meta": {
        "model": "gpt-4o-mini",
        "temperature": 0.3,
        "prompt_version": "v1",
        "created_at": "2026-02-07T09:01:37.115585+00:00"
      }
    },
    {
      "group_id": "group-9",
      "chunk_indices": [
        21
      ],
      "char_count": 831,
      "summary": "索发表于. CVPR.\n万林；蔡勒，；张帅；乐存，；弗格斯， 年。\n预印本。 M. Y. R. 2013 arXiv arXiv:1704.04861 使用 D",
      "digest": "索发表于. CVPR.\n万林；蔡勒，；张帅；乐存，；弗格斯， 年。\n预印本。 M. Y. R. 2013 arXiv arXiv:1704.04861 使用 DropConnect 正则化神经网络。发表于 ICML。尹俊 黄高（）、孙雨（）、刘子纬（）、塞德拉（）、温伯格（） 年Huang, G. Sun, Y. Liu, Z. Sedra, D. Weinberger, K. Q. 2016 浩；朱大勋；裴正勋；金正勋 2017 年。知识蒸馏的馈 采用随机深度的深度网络。发表于欧洲计算机视觉会议。(ECCV) 赠：快速优化、网络最小化与迁移学习。发表于 CVPR。\n黄高、李毅、普莱斯、刘子川、霍普克罗夫特和温伯格于 年发表《快照集成：训练 次获得个模型》。2017 a 1 M 发表于国际学习表征会议(ICLR)。\n黄高、刘子川、温伯格和范德马滕 密集连接卷积网络。发表于。 与2017b. CVPR Ioffe, S. 批量归一化：通过减少内部协变量偏移Szegedy, C. 2015. 加速深度网络训练。 预印本。arXiv arXiv:1502.03167 Johnson, J.; Gupta, A.; 与 Fei-Fei, L. 2018. 基于场景图的图像 生成。发表于。 与 CVPRKrizhevsky, A.; Sutskever, I.; Hinton, 使用深度卷积神经网络进行 分类。发表G. 2012. ImageNet 于。 从微小图像中学习多层特 NIPSKrizhevsky, A. 2009. 征。技术报告。 与 神经网络集Krogh, A., Vedelsby, J. 1995. 成、交叉验证与主动学习。发表于。 NIPS Lakshminarayanan, B.; Pritzel, A.; 与 Blundell, C. 2017. 使用深 度集成实现简单可扩展的预测不确定性估计。发表于 NIPS。 4893",
      "full_text": "索发表于. CVPR.\n万林；蔡勒，；张帅；乐存，；弗格斯， 年。\n预印本。 M. Y. R. 2013 arXiv arXiv:1704.04861 使用 DropConnect 正则化神经网络。发表于 ICML。尹俊 黄高（）、孙雨（）、刘子纬（）、塞德拉（）、温伯格（） 年Huang, G. Sun, Y. Liu, Z. Sedra, D. Weinberger, K. Q. 2016 浩；朱大勋；裴正勋；金正勋 2017 年。知识蒸馏的馈 采用随机深度的深度网络。发表于欧洲计算机视觉会议。(ECCV) 赠：快速优化、网络最小化与迁移学习。发表于 CVPR。\n黄高、李毅、普莱斯、刘子川、霍普克罗夫特和温伯格于 年发表《快照集成：训练 次获得个模型》。2017 a 1 M 发表于国际学习表征会议(ICLR)。\n黄高、刘子川、温伯格和范德马滕 密集连接卷积网络。发表于。 与2017b. CVPR Ioffe, S. 批量归一化：通过减少内部协变量偏移Szegedy, C. 2015. 加速深度网络训练。 预印本。arXiv arXiv:1502.03167 Johnson, J.; Gupta, A.; 与 Fei-Fei, L. 2018. 基于场景图的图像 生成。发表于。 与 CVPRKrizhevsky, A.; Sutskever, I.; Hinton, 使用深度卷积神经网络进行 分类。发表G. 2012. ImageNet 于。 从微小图像中学习多层特 NIPSKrizhevsky, A. 2009. 征。技术报告。 与 神经网络集Krogh, A., Vedelsby, J. 1995. 成、交叉验证与主动学习。发表于。 NIPS Lakshminarayanan, B.; Pritzel, A.; 与 Blundell, C. 2017. 使用深 度集成实现简单可扩展的预测不确定性估计。发表于 NIPS。 4893",
      "keywords": [],
      "page_range": [
        1,
        1
      ],
      "summary_status": "failed",
      "llm_meta": {
        "model": "gpt-4o-mini",
        "temperature": 0.3,
        "prompt_version": "v1",
        "created_at": "2026-02-07T09:01:37.115585+00:00"
      }
    }
  ]
}