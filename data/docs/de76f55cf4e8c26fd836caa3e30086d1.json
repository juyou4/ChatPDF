{
  "filename": "AdvRoad.pdf",
  "upload_time": "2026-02-03T19:46:01.432474",
  "data": {
    "full_text": "Invisible Triggers, Visible Threats! Road-Style Adversarial Creation Attack for\nVisual 3D Detection in Autonomous Driving\nJianWang,LijunHe,YixingYong,HaixiaBi,FanLi*\nSchoolofInformationandCommunicationsEngineering,Xi’anJiaotongUniversity\nwj851329121@stu.xjtu.edu.cn,lijunhe@mail.xjtu.edu.cn,yongyx@stu.xjtu.edu.cn,haixia.bi@mail.xjtu.edu.cn,\nlifan@mail.xjtu.edu.cn\nAbstract\nModernautonomousdriving(AD)systemsleverage3Dob-\njectdetectiontoperceiveforegroundobjectsin3Denviron-\nmentsforsubsequentpredictionandplanning.Visual3Dde-\ntectionbasedonRGBcamerasprovidesacost-effectiveso-\nlution compared to the LiDAR paradigm. While achieving\npromising detection accuracy, current deep neural network-\nbased models remain highly susceptible to adversarial ex-\namples. The underlying safety concerns motivate us to in-\nvestigate realistic adversarial attacks in AD scenarios. Pre-\nvious work has demonstrated the feasibility of placing ad-\nversarialpostersontheroadsurfacetoinducehallucinations\nin the detector. However, the unnatural appearance of the\nposters makes them easily noticeable by humans, and their\nfixed content can be readily targeted and defended. To ad-\ndresstheselimitations,weproposetheAdvRoadtogenerate\ndiverse road-style adversarial posters. The adversaries have\nnaturalistic appearances resembling the road surface while\ncompromisingthedetectortoperceivenon-existentobjectsat\ntheattacklocations.Weemployatwo-stageapproach,termed\nRoad-Style Adversary Generation and Scenario-Associated\nAdaptation,tomaximizetheattackeffectivenessontheinput\nFigure 1: Illustration of the adversarial FP attacks on the\nscenewhileensuringthenaturalappearanceoftheposter,al-\nroad. The 3D detection system will perceive a ghost ob-\nlowingtheattacktobecarriedoutstealthilywithoutdrawing\njectneartheposter.Comparedwithpreviouswork(left),our\nhumanattention.ExtensiveexperimentsshowthatAdvRoad\ngeneralizes well to different detectors, scenes, and spoofing poster(right)ishardertoattracthumanattention,makingit\nlocations.Moreover,physicalattacksfurtherdemonstratethe morelikelytoposearealthreat.\npracticalthreatsinreal-worldenvironments.\nCode—https://github.com/WangJian981002/AdvRoad etal.2023;Wangetal.2023b).Recentstudieshaverevealed\nthatcarefullydesignedinputs,suchasadditiveperturbations\n(Zhangetal.2024,2021;Goodfellow,Shlens,andSzegedy\nIntroduction\n2014;Athalyeetal.2018)andlocalpatches(Guesmietal.\nVisual3Dobjectdetection(Maetal.2024;Huetal.2023;\n2024;Thys,VanRanst,andGoedeme´ 2019;Huetal.2024,\nChen et al. 2017) has emerged as a pivotal technology in\n2025), can catastrophically alter the output of DNNs, and\nautonomous driving systems (Mao et al. 2023; Chen et al.\ntheseadversarialexamplescanbesuccessfullyimplemented\n2024; Gulino et al. 2023), offering cost-effective environ-\ninphysicalscenarios(Satoetal.2021).Thissecuritythreat\nmentalperceptionthroughwidelyaccessibleRGBcameras.\nposesunpredictableconsequencesgiventhelife-criticalna-\nDespite its computational efficiency and hardware afford-\ntureof3Dperceptionsystems,whichmotivatesustoinves-\nability compared to LiDAR-dependent methods, the relia-\ntigaterealisticadversarialattacksfor3Dobjectdetectionin\nbilityofdeepneuralnetworks(DNNs)insafety-criticalsce-\nreal-worldenvironments.\nnariosremainsquestionableduetotheirvulnerabilitytoad-\nAdversarialattackson3Dobjectdetectorscanbedivided\nversarial attacks (Yang et al. 2025; Lin et al. 2024; Han\ninto two types based on model errors: false negatives (FN)\nwhererealobjectsevadedetection,andfalsepositives(FP)\n*Correspondingauthor.\nCopyright©2026,AssociationfortheAdvancementofArtificial wherenon-existenttargetsareidentified.Mostexistingstud-\nIntelligence(www.aaai.org).Allrightsreserved. ies (Zhu et al. 2023; Abdelfattah et al. 2021; Cheng et al.\n5202\nvoN\n11\n]VC.sc[\n1v51080.1152:viXra\n\nVictimModel AttackWay Consequence\nMaliciouslasersignalinjection\nFN\n(Caoetal.2023;Jinetal.2023;Hauetal.2021)\nLiDAR-based Maliciouslasersignalinjection\nFP\n(Jinetal.2023;Sunetal.2020;Caoetal.2019a;Wangetal.2023a)\n3Dadversarialmesh(Tuetal.2020;Caoetal.2019b) FN\nAdversarialcamouflage(Li,Qing,andChen2023) FN\nAdversarialpatch\nCamera-based FN\n(Zhuetal.2023;Wang,Li,andHe2025;Chengetal.2023;Xieetal.2023)\nAdversarialposter(Wangetal.2025) FP\nTable1:Thesummarizationofphysicaladversarialattackstargeting3DobjectdetectioninAD.\n2023; Tu et al. 2020; Zhang, Hou, and Yuan 2024; Wang, First, we use drones to take aerial photos of ground scenes\nLi, and He 2025) focus on FN attacks — for example, at- and construct a road image collection for training the style\ntaching adversarialpatches tovehicles tomake them invis- discriminator.Then,wegraduallyupdatethegeneratorbyit-\nible to detectors, which may result in a rear-end collision. erativelyrenderingthemappedposterontothesceneimage\nHowever,implementingFNattackstypicallyrequiresphys- and backpropagating the gradients based on the adversar-\nical access to the target object, limiting their practical ap- ialobjectiveandstylediscriminator.Thefirststageensures\nplication.FPattacks,ontheotherhand,aimtomakedetec- that the generated posters are similar to the source collec-\ntors”see”imaginaryobstacles,potentiallytriggeringsudden tionimageswhilebeingabletocompromisethedetector.In\nbrakingordangerouslanechangesbyautonomousvehicles. the second stage, we derive a local-optimal poster tailored\nDespiteposingsimilarsafetyrisksasFNattacks,FPattacks toaspecificinput,aimingtoenhanceitsdeceptiveeffective-\nforvisual3Ddetectionremainpoorlystudiedinthecurrent ness within the given scenario. Concretely, we initialize a\nattackliterature. posterfromthegeneratortrainedinthefirststage,randomly\nRecently,Wangetal.(Wangetal.2025)pioneeredphysi- sampleandplaceitatvariouslocationsinthecurrentscene,\ncalFPattacktargetingvisual3Ddetectorsbyplacingacare- and then backpropagate the gradients to the latent space to\nfullyoptimizedposterontheroad,therebyinducingthede- optimizethenoisevectortowardalocallyoptimalsolution.\ntector to perceive a ghost object near the poster (as shown Note that in this stage, the generator is frozen. Therefore,\nin Fig. 1 left). Since the poster is 2D and lacks thickness, thefoundadversarynotonlyhasnaturalisticroadstylesbut\nit is flexible to print and launch the attack. Moreover, the alsoachievesthestrongestattackeffectivenessinthecurrent\ngenerated poster has strong generalization ability, allowing scene.\nittobeeffectiveinvariousscenarios.Theylearntheposter Inshort,ourcontributionsare:\nbyproposinganimage-3Dapplyingalgorithmthatcandif- • WepresentanaturalisticFPattackpipelineforinducing\nferentiably render the 3D space poster onto the image, and theghostobjectontheroad.Thecraftedposterscansig-\ndirectly optimizing the poster’s pixel values. However, the nificantly evade human perception while compromising\nfollowing weaknesses remain: ❶ The content of the poster the3Dmodels,therebyincreasingthepracticalthreatto\nsignificantly differs from the road surface, making it easily theADsystem.\nnoticedbyhumans.Directlyoptimizingposterpixelscannot\n• We introduce Road-Style Adversary Generation and\nconstrainthelearnedcontent,whichoftenhaspatternswith\nScenario-Associated Adaptation to maximize the attack\nnon-naturalistic appearances. ❷ Each training session can\ncapabilityoftheadversarialposter.Moreover,alladver-\nonlygenerateoneposter,makingiteasytobetargetedand\nsaries are effective across various scenes and at certain\ndefended. They generate a single adversarial poster that is\nobservationdistances(e.g.,≤10m).\neffective across all scene images. Despite achieving a high\n• Extensive experiments in both the digital and physical\nattacksuccessrate,thesinglepostercanbeeasilyexploited\nworlds demonstrate the effectiveness of our approach\nand defended against (e.g., by fine-tuning the model with\nwith improved stealthiness. In addition, our posters are\ndatacontainingthisadversary).\nharder to defend against using existing defense tech-\nIn response to limitations ❶ and ❷, we propose a novel\nniques.\nFP attack pipeline that generates diverse road-style adver-\nsarialposters.Allpostershavepatternssimilartotheback-\nRelatedWork\nground road surface, making them harder to attract human\nattention,allowingtheattacktoproceedsilently.Ourframe- 3D object detection is the most crucial perception task in\nworkemploysatwo-stageapproach,Road-StyleAdversary modular autonomous driving systems, which identifies and\nGeneration and Scenario-Associated Adaptation, to gener- locates surrounding traffic participants like vehicles and\natediversenaturalisticadversaries.Inthefirststage,weuti- pedestrians in 3D space. Errors in detection results grad-\nlize GAN-based techniques to train an adversarial genera- ually accumulate, thereby affecting subsequent predictions\ntor that maps latent noise vectors to road-style adversaries. andplanning.\n\nUpdate generator G, Stage 1\nUpdate discriminator D, Stage 1\nRoad\nreal\nImage\nCollection\nfake\n…\nGenerator Discriminator\n3D position sampling\nImage-3D 3D Detector\nRoad Image Collection Scene image Rendering\nUpdate noise n ( ), Stage2\nFigure 2: The AdvRoad framework. Stage 1 trains an adversarial generator that outputs universal road-style posters; Stage 2\nupdatestheposter(thelatentvector)toenhancetheattackcapabilityforthegivenscene.\nRecent research efforts have developed various physical theresponsey∗undertheadversarialinput:\nattack methods targeting LiDAR-based and camera-based maxlogp(y∗|R(x,δ,t)) (1)\ndetectionalgorithms.Weprovideasummaryoftheseworks δ\nin terms of physical attack ways and attack consequences\nwherepistheprobabilityfunction;δ istheadversarytobe\ninTable1.ForLiDAR-basedapproaches,attackersmustal-\noptimized,whichcaneitherbeanexplicitrepresentationof\nter the captured LiDAR point clouds. This can be achieved the poster (e.g., a pixel array P ∈ [0,255]3×H×W) or an\nby strategically emitting laser pulses toward the target Li- implicit representation (e.g., a generator G : n ∈ Rd →\nDAR sensor (Cao et al. 2019a; Jin et al. 2023; Cao et al. P ∈[0,255]3×H×W,n∼N(0,1)).\n2023)orplacing3Dadversarialobjectsintheenvironment\nContinuous Attack Goals. When driving, the observa-\n(Tuetal.2020;Caoetal.2019b).However,alteringLiDAR\ntionofthescenechangescontinuously,suchasvaryingdis-\ndatatypicallyrequirescomplexequipmentlikelaserdiodes,\ntances and viewing angles. The practical threat posed by\nphotodiodes,orindustrial-grade3Dprinters.Thislimitsthe\na road-surface poster is substantially reduced if its effec-\nattack’s flexibility in dynamically changing AD scenarios.\ntiveness is confined to a specific scenario or location. Be-\nForcamera-basedapproaches,attackerscanutilizemoreaf-\ncause the AD system is likely to classify targets appearing\nfordableadversarialpatchestoperturbthecapturedimages,\ninmerelyoneortwoframesassensornoise.Consequently,\nleadingtovariousdetectionerrors.ExtendingWangetal.’s\nthese posters must exhibit universality to remain effective\nframework(Wangetal.2025)ofusingroadsurfaceposters\nacrossvaryingscenariosandviewingdistances.\ntocreatefake3Dobjects,wefurtherstudyhowtohidethese\nTo this end, we leverage the Expectation of Transforma-\npatternsfromhumandrivers.Thespoofingcapabilitytode-\ntion(EoT)(Athalyeetal.2018)acrossalltrainingsamples\ntectorsandstealthinesstohumansmaketheattackmoredan-\nandawiderangeofspoofinglocationstoenhancethephys-\ngerousinrealdrivingscenarios.\nical robustness and generality of the attack. Formally, the\noptimizationobjectivebecomes:\nProblemDefinition δ =argmaxXXlogp(y∗|R(x,δ,t)) (2)\nx∈Xt∈T\nWeinvestigateadversarialFPattacksagainstvisual3Dob-\nwhere X comprises all possible image inputs and T is the\nject detection models by placing the learned poster on the\nsetofpositiontransformationparameters.\nroad surface. Specifically, attackers apply the adversarial\nposter to a benign image x by firstly sampling the poster ProposedAdvRoadFramework\nlocationin3Dspaceandthenrenderingtheposterontothe\nRoad-StyleAdversaryGeneration\nimage.ThisresultsinanadversarialinputR(x,δ,t),where\nR(·) is the rendering function that applies the adversary δ Fig.2presentstheframeworkofourroad-stylecreationat-\nto the input x according to the sampled transformation pa- tack. The first stage aims to learn an adversarial generator\nrametert.Ourgoalistoinducethe3Ddetector,denotedas thatoutputsdiverseroad-styleposterswhilecontainingcrit-\nF ,toproduceadesiredresponsey∗ attheposterposition, icalforegroundfeatures,enablingthemtoinduceFPpredic-\nθ\nwhich is formally defined by maximizing the likelihood of tionsinthedetector.WeemployastandardGANpipelineto\n\nintegrateroadsurfacestyleandspoofinginformationtothe versariallossL andupdatevectorn.Thisprocessisfor-\nobj\ngenerator. mulatedas:\nRoad Image Collection. We utilize a DJI drone to cap-\ntureaerialphotographyoftrafficscenes,obtainingaseriesof\nn0 =n\n(5)\nraw images containing diverse road surfaces. We then crop n i+1 =n i−α·∇ niJ(F θ(R(x,G(n i),t)),y∗)\nauthenticroadpatchesfromthecollectedaerialimages,with\nWe repeat this process until reach the maximum iteration\neachpatchdimensionapproximatingvehiclesize(2m×4m).\nnumber. To preserve realism, we ensure that the updated\nThe built collection comprises over 2,000 road surface im-\nagescoveringvariousroadpatternsandstyles(asshownin noise n i+1 falls into the hypersphere of radius η centered\nFig. 2 left). This collection serves as the real reference for\natinitialnoisen0 ineachiteration.Thefinalposterexhibits\nstrongestdeceptivecapabilityinthecurrentscenewhilebe-\ntrainingthestylediscriminator,whilethesyntheticcounter-\ningauthentic.\nparts are generated by the generator. The inclusion of au-\nthenticimageryfacilitateslearningtherealisticroadpatterns\nImage-3DRendering\nfrom the generator, thereby enhancing the visual indistin-\nguishabilityofadversarialoutputstohumandrivers. Conventional 2D patch rendering (Thys, Van Ranst, and\nAdversarial Objective. The adversarial generator G is Goedeme´2019;LeeandKolter2019;Huetal.2021)solely\ntrainedonthewholedetectiondatasetX.Givenaframeof performsscalingandrotatingthepatchaccordingtotheob-\ninput image x ∈ X, we first sample the poster locations jects’ 2D bounding boxes. Although convenient, the phys-\nin the 3D space then render the poster G(n),n ∈ Rd to ical size of the patch and its position in 3D space are not\nthexthroughdifferentiableImage-3Drendering(discussed considered, which are critical for realistic physical attacks\nlater). Then, we prepare the adversarial label y∗ for the in- on 3D detectors. Following (Wang et al. 2025; Zhu et al.\nput R(x,δ,t). We mask out the regions of real objects on 2023), we briefly introduce how to render the poster from\nthe input image using ground truth (GT) bounding box an- the3Droadsurfaceontotheimage.\nnotations, and replace the GT labels with spoofing bound- First, we sample the 3D spatial positions of posters to\ning boxes introduced by the posters. This approach pro- place them on the road surface. Within a sector spanning\nvides dual advantages: First, masking surrounding objects ±∆ relative to the vehicle’s heading direction and a dis-\nθ\npreventsthegradientbeingvanishingbyaveraging.Second, tance range of d to d meters, we randomly sample\nmin max\nwe can reuse the detector’s native loss function to directly placementlocationswhileavoidingoverlappingwithexist-\ncalculatetheadversarialloss.Formally,theadversarialloss ing scene objects. Second, we project the four poster cor-\nis: ner points onto the image plane using the camera’s intrin-\nL =J(F (R(x,G(n),t)),y∗) (3) sicandextrinsicmatrices,therebydeterminingtheadversar-\nobj θ\nial region in the image (the quadrangle region defined by\nwhereJ(·)istheoriginallossfunctionfordetectorF .The\nθ projected corner points). Third, for each pixel within this\nother training objective comes from style discriminator D.\nregion, we inversely calculate its 3D coordinates aided by\nWe freeze the D and maximize the discriminator’s confi-\nroadheightinformation(approximatedfromthebottomface\ndenceinclassifyingthegenerator’soutputsasreal.Thefinal\nheight of the nearest scene object to the poster). Finally,\ntrainingobjectiveforthegeneratoris:\neachpixel’sRGBvalueiscalculatedviabilinearinterpola-\nL =L +λ·L (4) tionbasedonits3Dpositionrelativetotheposter.Formore\nG cls obj\ndetailsrefertosupplementary-A.\nWe alternately train the generator and the discriminator,\ngradually injecting spoofing and style information into the Experiment\ngeneratedposters.\nExperimentalSetup\nScenario-AssociatedAdaptation\nVictim Model. The vision-based BEV space 3D detec-\nAfter the first stage training, the posters output by the gen- tor BEVDet (Huang et al. 2021), BEVDet4D (Huang and\neratorbothresembletheroadsurfaceandmaintainacertain Huang2022),andBEVFormer(Lietal.2024)areselected\ndegree of deception. They can serve as a universal trap to as victim models for the attack, considering their repre-\ntriggerFPpredictionsinthe3Ddetector.However,thegen- sentativeness and the fact that BEV space inherently sup-\neratedpostersrelyonsamplingnoisefromthelatentspace— ports most downstream perception tasks for AD (Hu et al.\na process that involves inherent randomness and may lead 2023).Foreachdetector,theResNet50(Heetal.2016)and\nto unstable attack effects. Therefore, we further introduce SwinTransformer-Tiny (Liu et al. 2021) are used as image\nScenario-AssociatedAdaptationtoenhancetheattackcapa- backbonerespectively.\nbilityofthepostersinspecificscenarios. Dataset. For the digital attack, we use nuScenes dataset\nSpecifically,giventheinputscenariox,wefirstrandomly (Caesar et al. 2020) to train the adversary and perform the\ninitialize the noise vector n from the Gaussian distribution attack.nuScenesisalarge-scale,multi-modaldatasetspecif-\nN(0,1)andfednintothefrozengeneratortogetthespoof- icallydesignedforADand3Dobjectdetection.Thetraining\ningposter.Then,werandomlysampletheposterlocationsin andvalidationsetcontains28,130and6,019framesrespec-\nthe current scene and perform rendering. Finally, we back- tively,witheachframeincludingimagedatafromsixcam-\npropagate the gradient to the latent space based on the ad- erasand360◦ 3Dobjectannotations.Wetrainalldetectors\n\nASR(%,↑)\nModel Attack LPIPS↓\n2.0m 1.5m 1.0m 0.5m\nBenign - 1.5 0.3 0.1 0\nBEVDet Random 0.2136 8.0 4.9 2.9 0.8\n-R50 Realpicture 0.2066 30.4 22.8 15.7 6.3\nAdvRoad 0.1472 62.6 55.6 42.7 23.3\nBenign - 1.2 0.2 0 0\nBEVDet Random 0.2138 1.7 0.7 0.4 0.1\n(a) AdvRoad\n-SwinT Realpicture 0.2066 25.7 19.0 12.1 4.9\nAdvRoad 0.1337 60.2 56.3 47.6 28.8\nBenign - 1.2 0.1 0 0\n(b) AdvPoster (c) Real Picture BEVDet4D Random 0.2137 3.4 1.9 1.2 0.3\n-R50 Realpicture 0.2066 45.1 38.1 29.0 14.9\nFigure 3: Visualizations of attack results in the digital do- AdvRoad 0.1331 49.1 42.9 32.7 17.7\nmain. We place the spoofing poster on the road surface to\nBenign - 1.2 0.3 0 0\nlaunch the attack. (1) AdvRoad, our road-style naturalistic\nBEVDet4D Random 0.2136 1.4 0.3 0 0\nadversarialposter;(2)AdvPoster(Wangetal.2025),gener-\n-SwinT Realpicture 0.2066 23.4 19.3 13.7 7.3\natedbydirectlyoptimizingthepixelvalues;(3)RealPicture,\nAdvRoad 0.1370 39.1 35.1 27.8 15.7\nuseimagesofrealvehiclesasposters.\nBenign - 1.4 0.3 0 0\nBEVFormer Random 0.1304 1.4 0.3 0 0\n-R50 Realpicture 0.1260 6.3 3.5 1.8 0.7\non the training set following their official settings and de-\nAdvRoad 0.0822 44.5 32.7 20.7 8.2\ntection performances are given in supplementary-B.1. The\nconfidence scores for the detected objects are over 0.1 for Benign - 1.5 0.3 0 0\nallmodelsfollowing(Wangetal.2025;Tuetal.2020). BEVFormer Random 0.1306 1.5 0.5 0.1 0\nEvaluationMetric.Theattacksuccessrate(ASR)isused -SwinT Realpicture 0.1260 20.9 16.6 10.4 4.3\nAdvRoad 0.0818 37.3 30.6 21.0 8.9\nto evaluate the creation attack, which measures the propor-\ntionofsuccessfullydetectedfakeobjectsamongallspoofing\nTable2:Digitalattackresultsofadversarialcreationattack\nattempts.Weconsiderafakeobjectissuccessfullydetected\ninthenuScenesdataset.\nwhen theminimum distancebetween thedetector’s predic-\ntions and the center of the poster is less than d . Multi-\nthr\nple center distance thresholds, {2.0m,1.5m,1.0m,0.5m},\nareadoptedforcomprehensiveevaluation.Unlikeusingthe attacklocations(withafixedrandomseed)consideringthe\nIoUasanindicator,precisealignmentofthedetectedbound- miscalculationcases,wherethedetectionresultsforthereal\ning box with the y∗ in terms of size and orientation is less objects are incorrectly counted to spoofed ones. Random:\ncritical. Since the AD system may lead to dangerous con- randomlyinitializeaposterfortheattack.Realpicture:use\nsequences as long as a fake obstacle is perceived near the imagesofrealvehiclesaspostersfortheattack(Fig.3(c)).\nposter. Table 2 shows the digital attack results in nuScenes\nMoreover, we use the Learned Perceptual Image Patch dataset.Weachievegoodattackperformanceacrosssixdif-\nSimilarity(LPIPS)score(Zhangetal.2018)toassesstheen- ferent 3D detectors, successfully inducing FP predictions\nvironmentalconsistencyoftheattack,whichmeasuresper- near the poster locations (see Fig. 3(a) for the visualiza-\nceptualsimilaritybetweenbenignandattackedimages. tion results). This holds regardless of whether the target\nImplementation Details. We set the category of the model uses a CNN-based or Transformer-based backbone,\nspoofing object to the most common vehicle, with the a geometry-based or network-based PV-to-BEV transfor-\nposter’s physical size being 2m × 4m. For spoofing loca- mation, or an anchor point-based or query-based detection\ntions, we aim to induce FP predictions either in front of head.ForADsystems,suchanerrorrate(exceeding 40%)\norbehindtheself-vehicle.Therefore,thepostersareplaced iscatastrophic.Asuddenlyappearingobjectwithin10me-\nat a distance of 7 to 10 meters from the self-vehicle with tersinfrontoftheego-vehiclecantriggeremergencybrak-\n∆ = 5◦.Withinthisrange,theADsystem’smisjudgment ingorlane-changingdecisions,potentiallyleadingtosevere\nθ\nleaveslittletimeforthedrivertoreact.Wesample1,000val- safety incidents. Moreover, since our posters resemble the\nidationframesandplacepostersattwolocationsperframe, road surface, drivers have limited time to react and effec-\nyielding2,000attacksforASRcomputation.Seethesupple- tivelyintervene.\nmentarymaterialsformoretrainingdetails. Sinceweavoidoverlappingwithsceneobjectswhensam-\npling attack locations, miscalculation cases are nearly neg-\nMainResult\nligible, e.g., the ASR for Benign consistently < 1.5% un-\nWe verify the effectiveness of our road-style adversarial derCD2.0m.Moreover,weobserveaninterestingresultthat\nposter(AdvRoad)incomparisonwithBenign,Random,and takingarealvehicleimageasthespoofingpostermayalso\nRealpicture.Specifically,Benign:originalscenewithoutthe lead to FP errors. Specifically, Real picture can achieve an\nadversarialpattern,however,westillsampleandrecordthe ASR of up to 45.1% under CD2.0m for BEVDet4D-R50.\n\n\u0000\u001b\u0000\u0013\n\u0000\u0019\u0000\u0013\n\u0000\u0017\u0000\u0013\n\u0000\u0015\u0000\u0013\n\u0000\u0013\n\u0000\u0013\u0000\u0011\u0000\u0018\u0000P \u0000\u0014\u0000\u0011\u0000\u0013\u0000P \u0000\u0014\u0000\u0011\u0000\u0018\u0000P \u0000\u0015\u0000\u0011\u0000\u0013\u0000P\n\u0000&\u0000H\u0000Q\u0000W\u0000H\u0000U\u0000\u0003\u0000'\u0000L\u0000V\u0000W\u0000D\u0000Q\u0000F\u0000H\n\u0000\f\u0000\b\u0000\u000b\u0000\u0003\u0000H\u0000W\u0000D\u00005\u0000\u0003\u0000V\u0000V\u0000H\u0000F\u0000F\u0000X\u00006\u0000\u0003\u0000N\u0000F\u0000D\u0000W\u0000W\u0000$\n\u0000%\u0000(\u00009\u0000'\u0000H\u0000W\n\u0000\u001c\u0000\u0014\u0000\u0011\u0000\u0013\n\u0000$ \u0000$\u0000G \u0000G\u0000Y \u0000Y\u00003 \u00003\u0000R \u0000R\u0000V \u0000V\u0000W \u0000W\u0000H \u0000H\u0000U \u0000U\u0000\u000f\u0000\u000f \u0000\u0003\u0000\u0003 \u0000Z\u0000Z \u0000\u0012\u0000\u0012 \u0000\u0003\u0000R \u0000'\u0000\u0003\u0000' \u0000H\u0000I\u0000H \u0000\u0011\u0000I\u0000\u0011 \u0000\u001b\u0000\u0016\u0000\u0011\u0000\u0017 \u0000\u001b\u0000\u0013\n\u0000$\u0000G\u0000Y\u00005\u0000R\u0000D\u0000G\u0000\u000f\u0000\u0003\u0000Z\u0000\u0012\u0000R\u0000\u0003\u0000'\u0000H\u0000I\u0000\u0011\n\u0000$\u0000G\u0000Y\u00005\u0000R\u0000D\u0000G\u0000\u000f\u0000\u0003\u0000Z\u0000\u0012\u0000\u0003\u0000'\u0000H\u0000I\u0000\u0011 \u0000\u0019\u0000\u0017\u0000\u0011\u0000\u001b \u0000\u0019\u0000\u0015\u0000\u0011\u0000\u0019 \u0000\u0019\u0000\u0013\n\u0000\u0018\u0000\u0018\u0000\u0011\u0000\u0019\n\u0000\u0017\u0000\u0015\u0000\u0011\u0000\u001a \u0000\u0017\u0000\u0013\n\u0000\u0016\u0000\u0016\u0000\u0011\u0000\u0015\n\u0000\u0015\u0000\u0016\u0000\u0011\u0000\u0016 \u0000\u0015\u0000\u0014\u0000\u0011\u0000\u001c \u0000\u0015\u0000\u0013\n\u0000\u0014\u0000\u0013\u0000\u0011\u0000\u001c \u0000\u0014\u0000\u0016\u0000\u0011\u0000\u0015 \u0000\u001a\u0000\u0011\u0000\u0013\n\u0000\u0013\u0000\u0011\u0000\u0014 \u0000\u0013\u0000\u0011\u0000\u0015 \u0000\u0013\u0000\u0011\u0000\u0016 \u0000\u0014\u0000\u0011\u0000\u0019 \u0000\u0013\n\u0000\u0013\u0000\u0011\u0000\u0018\u0000P \u0000\u0014\u0000\u0011\u0000\u0013\u0000P \u0000\u0014\u0000\u0011\u0000\u0018\u0000P \u0000\u0015\u0000\u0011\u0000\u0013\u0000P\n\u0000&\u0000H\u0000Q\u0000W\u0000H\u0000U\u0000\u0003\u0000'\u0000L\u0000V\u0000W\u0000D\u0000Q\u0000F\u0000H\n\u0000\f\u0000\b\u0000\u000b\u0000\u0003\u0000H\u0000W\u0000D\u00005\u0000\u0003\u0000V\u0000V\u0000H\u0000F\u0000F\u0000X\u00006\u0000\u0003\u0000N\u0000F\u0000D\u0000W\u0000W\u0000$\n\u0000%\u0000(\u00009\u0000)\u0000R\u0000U\u0000P\u0000H\u0000U Stage ASR(%,↑)\n\u0000\u001b\u0000\u0015\u0000\u0011\u0000\u0019\n\u0000$ \u0000$\u0000G \u0000G\u0000Y \u0000Y\u00003 \u00003\u0000R \u0000R\u0000V \u0000V\u0000W \u0000W\u0000H \u0000H\u0000U \u0000U\u0000\u000f \u0000\u000f\u0000\u0003 \u0000\u0003\u0000Z \u0000Z\u0000\u0012 \u0000\u0012\u0000R \u0000\u0003\u0000'\u0000\u0003\u0000' \u0000H\u0000I\u0000H \u0000\u0011\u0000I\u0000\u0011 \u0000\u001a\u0000\u0016\u0000\u0011\u0000\u0016 1th 2nd 2.0m1.5m1.0m0.5m\n\u0000$\u0000G\u0000Y\u00005\u0000R\u0000D\u0000G\u0000\u000f\u0000\u0003\u0000Z\u0000\u0012\u0000R\u0000\u0003\u0000'\u0000H\u0000I\u0000\u0011\n\u0000$\u0000G\u0000Y\u00005\u0000R\u0000D\u0000G\u0000\u000f\u0000\u0003\u0000Z \u0000\u0018\u0000\u0012 \u0000\u001a\u0000\u0003\u0000' \u0000\u0011\u0000\u0013\u0000H\u0000I\u0000\u0011 AdvRoad@1 ✓ 23.4 19.2 13.1 6.8\nAdvRoad@2 ✓ 26.7 21.9 16.3 7.3\n\u0000\u0017\u0000\u0017\u0000\u0011\u0000\u0018\nAdvRoad ✓ ✓ 62.6 55.6 42.7 23.3\n\u0000\u0015\u0000\u001c\u0000\u0011\u0000\u001a \u0000\u0016\u0000\u0015\u0000\u0011\u0000\u001a AdvRoad∗ ✓ ✓ 67.0 60.5 48.6 27.2\n\u0000\u0015\u0000\u0013\u0000\u0011\u0000\u001a \u0000\u0014\u0000\u001b\u0000\u0011\u0000\u001a\n\u0000\u0014\u0000\u0015\u0000\u0011\u0000\u0015 \u0000\u001b\u0000\u0018\u0000\u0011\u0000\u0011\u0000\u0015\u0000\u0018 \u0000\u001b\u0000\u0011\u0000\u0018\n\u0000\u0013 \u0000\u0013\u0000\u0011\u0000\u0014 \u0000\u0013\u0000\u0011\u0000\u0018 \u0000\u0014\u0000\u0011\u0000\u001b Table3:AblationsforRoad-StyleAdversaryGenerationand\nScenario-Associated Adaptation. The results (ASR-%) are\ngivenonBEVDet-R50.\nAdvRoad AdvPoster AdvRoad AdvPoster\nLPIPS 0.1472 0.1929 LPIPS 0.0822 0.1104\n(a) (b)\nASR(%,↑)\nPhysicalSize LPIPS↓\nFigure 4: Comparison with AdvPoster w/ (dash line) and 2.0m1.5m1.0m0.5m\nw/o (solid line) defense. All victim models use ResNet50\n1.5m×3.0m 0.1123 31.3 26.5 19.9 10.4\nasimagebackbone.\n2.0m×3.0m 0.1292 49.4 42.1 32.5 17.7\n2.0m×3.5m 0.1384 56.6 50.4 38.6 21.2\n2.0m×4.0m 0.1472 62.6 55.6 42.7 23.3\nAlthoughthepictureposteris2Dandlacksthickness,itcan\n2.0m×4.5m 0.1555 66.1 58.1 44.0 23.5\nstillprovideintrinsicforegroundvisualcuesthatthedetector\n2.0m×5.0m 0.1633 67.6 59.3 45.0 23.1\ncapturesandrecognizes.However,similartoarealobject,a\n‘flat’vehicleisalsolikelytoattractthedriver’sattentionand\nhashigherLPIPSscorescomparedwithAdvRoad. Table4:Ablationsforthephysicalsizeofroadposters.The\nresultsaregivenonBEVDet-R50.\nComparisonwithCurrentWork\nWe compare our attack with AdvPoster (Wang et al. 2025)\ntors. It is easy for the models to filter out these adversarial\nintermsofattackperformance,naturality,anddefensediffi-\npatternsinsidetheimage.However,AdvRoadstillachieves\nculty,whichexplicitlylearnstheadversarybydirectlyopti-\nmizingthepixelvaluesoftheposter.\n∼20%ASRunderCD2.0m,whichdemonstratesthestrong\nresilienceofourattackwhenfacingthedefense.Thisisbe-\nAttack Performance. The results are given in Fig. 4\ncauseAdvRoadcangeneratealargenumberofdiversead-\nwith aligned experimental settings (e.g., poster’s physical\nversaries, and these posters exhibit textures similar to the\nsize, attack distances). The solid lines represent the orig-\nroadsurface,thusfurtherincreasingthedifficultyofdefense.\ninal attack performance without defense. As shown, Ad-\nMoredefenseresultsaregiveninsupplementary-B.3.\nvPoster achieves superior attack performance compared\nto our method, attaining ASR of 91% and 82.6% under\nAblation\nCD2.0m on BEVDet and BEVFormer respectively. This\ndemonstratestheeffectivenessofdirectlyoptimizingtheex- TwoStageApproach.Weconductanablationstudytoval-\nplicitrepresentationofadversaries. idate the effectiveness of each component in the AdvRoad.\nNaturality. AdvPoster optimizes a single deceptive The results are shown in Table 3. We first briefly intro-\nposteracrossentireinputscenes.Whiledemonstratinghigh duce the ablation settings. AdvRoad@1 directly uses the\nattack efficacy, the learned patterns exhibit uncontrollable outputs from Stage 1 for the attack; AdvRoad@2 follows\nand often abstract characteristics. As shown in Fig. 3(b), the typical GAN paradigm by first training a road poster\nAdvPoster appears visually distinct from road surfaces and generator without the supervision of the adversarial objec-\nisveryattention-grabbing.Incontrast,ourAdvRoadinjects tive L . Then, we freeze the generator using Scenario-\nobj\nstyle information into the generator through implicit ad- AssociatedAdaptationtosearchthelatentvectortoperform\nversarialrepresentations,producingnatural-lookingposters the attack; AdvRoad∗ extends the update iteration to 50 in\nthat blend seamlessly into road textures and achieving a Stage 2. AdvRoad@1 achieves 23.4% ASR after the Stage\nlowerLPIPSscore.Thisenablesstealthyattackswhileam- 1 training. This reflects the attack performance when ran-\nplifying practical security threats. More quantitative visual domly selecting a poster from the generator and placing it\ncomparisonsareprovidedinsupplementary-B.2. withinthe7–10mrange.Additionally,evenwithanaturally\nDefenseDifficulty.ForAdvPoster,singletraininggener- trainedgeneratorwithoutinjectingadversarialinformation,\nates only one unique adversarial example with salient dis- searching the latent space can still discover deceptive con-\ncriminativefeatures,itismorelikelytobetargetedandde- tent,achievinganASRof26.7%.CombiningtheRoad-Style\nfended by the AD system. Therefore, we employ adversar- AdversaryGenerationandScenario-AssociatedAdaptation,\nialaugmentationasthedefense.Specifically,weincorporate AdvRoad boosts the ASR to 62.6%, which highlights the\nthelearnedpostersintothetrainingsetandfine-tunethede- effectivenessofourtwo-stageattackpipeline.Also,increas-\ntector for extra 2 epochs. The attack results after defense ingtheupdateiterationsinStage2canfurtherimprovethe\nareshowninFig.4(dashlines).WeobservethatAdvPoster ASR.\nonlyachieveslessthan2%ASRagainstthedefendeddetec- Physical Size. Theoretically, the more pixels an attacker\n\n\u0000\u0017\u0000\u0013\n\u0000\u0016\u0000\u0018\n\u0000\u0016\u0000\u0013\n\u0000\u0015\u0000\u0018\n\u0000\u0015\u0000\u0013\n\u0000\u0014\u0000\u0018\n\u0000\u0014\u0000\u0013\n\u0000\u0018\n\u0000\u001a\u0000P \u0000\u001b\u0000P \u0000\u001c\u0000P \u0000\u0014\u0000\u0013\u0000P \u0000\u0014\u0000\u0014\u0000P \u0000\u0014\u0000\u0015\u0000P\n\u00006\u0000S\u0000R\u0000R\u0000I\u0000\u0003\u0000'\u0000L\u0000V\u0000W\u0000D\u0000Q\u0000F\u0000H\u0000\u0003\u0000\u000b\u0000P\u0000H\u0000W\u0000H\u0000U\u0000\f\n\u0000\f\u0000\b\u0000\u000b\u0000\u0003\u0000H\u0000W\u0000D\u00005\u0000\u0003\u0000V\u0000V\u0000H\u0000F\u0000F\u0000X\u00006\u0000\u0003\u0000N\u0000F\u0000D\u0000W\u0000W\u0000$\n\u0000\u0017\u0000\u0013\u0000\u0011\u0000\u0019 \u0000\u0017\u0000\u0014\u0000\u0011\u0000\u0014 \u0000&\u0000'\u0000 \u0000\u0015\u0000\u0011\u0000\u0013\u0000P\n\u0000&\u0000'\u0000 \u0000\u0014\u0000\u0011\u0000\u0018\u0000P\n\u0000\u0016\u0000\u0016 \u0000\u0016\u0000\u0018 \u0000\u0011\u0000\u0011 \u0000\u0016\u0000\u0017 \u0000\u0016\u0000\u0016\u0000\u0011\u0000\u001a \u0000&\u0000'\u0000 \u0000\u0014\u0000\u0011\u0000\u0013\u0000P \u0000\u0016\u0000\u0014\u0000\u0011\u0000\u0016 \u0000\u0016\u0000\u0014\u0000\u0011\u0000\u0016 \u0000\u0016\u0000\u0013\u0000\u0011\u0000\u0018 \u0000&\u0000'\u0000 \u0000\u0013\u0000\u0011\u0000\u0018\u0000P\n\u0000\u0015\u0000\u001b\u0000\u0011\u0000\u0014\n\u0000\u0015\u0000\u0018\u0000\u0011\u0000\u0016\n\u0000\u0015\u0000\u0017\u0000\u0011\u0000\u0013\n\u0000\u0014\u0000\u001c\u0000\u0011\u0000\u001b\n\u0000\u0014\u0000\u0019\u0000\u0011\u0000\u0018\n\u0000\u0014\u0000\u001a\u0000\u0011\u0000\u001a \u0000\u0014\u0000\u0014\u0000\u0019\u0000\u001a\u0000\u0011\u0000\u0011\u0000\u001a\u0000\u001a \u0000\u0014\u0000\u001a\u0000\u0011\u0000\u001a\n\u0000\u0014\u0000\u0016\u0000\u0011\u0000\u0018\n\u0000\u001b\u0000\u0011\u0000\u0016\n\u0000\u0016\u0000\u0018\u0000\u0019 \u0000\u0011\u0000\u0011\u0000\u0011 \u0000\u0014\u0000\u0015\u0000\u0015 \u0000\u0017\u0000\u0018\u0000\u0011\u0000\u0011\u0000\u0014\u0000\u0015\nFigure5:AttackresultsontheKITTIdataset.TheASRs(%)\natdifferentspoofingdistancesaregiven.\nFigure6:Physicalattackenvironmentandresults.\ncan manipulate in an image, the stronger attack capability\nbecomes. However, since posters placed on road surfaces\nCondition ASR\nundergo perspective projection when captured by cameras,\nincreasing the physical size of posters yields diminishing Sunlitarea 49.4%(170/344)\nmarginalreturnsinpixelgainsfortheadversarialregion.On Shadedarea 28.3%(78/276)\nthe other hand, since AdvRoad performs an instance-level Posterwrinkled 40.2%(103/256)\nattackthataimstoinduceaghostvehiclenearthepostercen- Partialocclusion 43.8%(92/210)\nter, excessively large posters would actually hinder models Indoor 19.5%(57/292)\nfrom achieving precise localization. Our most lenient eval-\nuation metric (Center distance ≤ 2m) exactly matches the Table 5: Quantitative attack results under different condi-\nedge position of a 4m-long poster. As shown in Table 4, tions.\nincreasing the physical size can improve the ASR. How-\never, when the poster length exceeds 4m, the incremental\ngainsbecomelimited.Specifically,a5m-longpostershows thecustom3Ddetector.Then,wetrainthegenerator,select\na decrease in ASR under the strict evaluation criterion of aspoofingposter,andprintitfortheattack.\nCD0.5m. However, all the posters have textures similar to Fig.6(b-d)illustratessomephysicalattackresults.Itcan\ntheroadsurface,makingthemdifficultforhumanstodetect. be seen that the poster can successfully induce the de-\ntector to generate false predictions at its location. Despite\nAttacktoBroaderDataset some color deviations in the printing process (we use cost-\nTo verify the generalization ability of AdvRoad across dif- effective banner fabric for printing), the poster remains ef-\nferent datasets, we further conduct attack experiments on fective. This is because, during training, we apply random\nKITTI scenes (Geiger, Lenz, and Urtasun 2012). We use brightnessandcontrastadjustments,aswellasinjectrandom\nBEVDet as the victim model and the ASRs at different noise,toenhancetherobustnessofposters.Thequantitative\nspoofing distances are shown in Fig. 5. We observe that results under different physical conditions are given in Ta-\ntheposterachievesthestrongestattackeffectivenessatdis- ble5.Inaddition,thetexturesimilartotheroadsurfacecan\ntances between 9 and 10 meters. When the distance is too further reduce the attention from human drivers. Consider\nshort, the poster may not be fully captured by the camera, usingfabricswithbettercolorfidelity,suchascanvas,tore-\nwhileatlongerdistances,theadversarialregionintheimage ducethecolordifferencewiththebackgroundroadsurface,\nbecomeslimited,leadingtoadeclineinattackperformance. thereby making the attack more covert. Further analysis of\nFurther discussions on AdvRoad—such as its transfer- thephysicalattacksisprovidedinthesupplementary-B.5.\nabilityandthetrade-offbetweendiversityandattackeffec-\ntiveness—canbefoundinthesupplementary-B.4. Conclusion\nThis paper introduces AdvRoad, a naturalistic FP attack\nPhysicalAttackExperiment\npipeline for visual 3D object detection in AD. AdvRoad\nTo assess the practicality of our AdvRoad, we conduct at- leverages Road-Style Adversary Generation and Scenario-\ntackexperimentsinphysical-worldenvironments.Sincevi- Associated Adaptation to perform stealthy adversarial at-\nsual 3D detectors are typically camera-dependent (e.g., the tacks for human drivers, inducing ‘ghost’ objects for the\nPV2BEVtransformationisrelatedtothecamera’sintrinsic perceptionsystemandpotentiallycausingreal-worldthreats\nparameters ), physical experiments first require training a suchasemergencybraking.Extensiveexperimentsonboth\n3Ddetectoradaptedtothecustomsceneandcamera.There- digital and physical domains demonstrate the effectiveness\nfore,webuiltaphysicaldetectionplatformwithafront-view of AdvRoad. Compared with previous work, our attack is\nRGBcameraanda16-lineLiDAR(Fig.6(a)).TheLiDAR hardertodetectanddefendagainst,highlightingsignificant\nsensorisonlyusedtoannotatethesceneobjectsfortraining securityriskstoADsystems.\n\nAcknowledgments Guesmi, A.; Ding, R.; Hanif, M. A.; Alouani, I.; and\nShafique, M. 2024. Dap: A dynamic adversarial patch for\nThisworkwassupportedinpartbytheNationalNaturalSci-\nevadingpersondetectors. InProceedingsoftheIEEE/CVF\nence Foundation of China under Grant 62531012, in part\nConference on Computer Vision and Pattern Recognition,\nby the National Key Research and Development Program\n24595–24604.\nofChinaunderGrant2022YFA1003800,theKeyResearch\nandDevelopmentProgramofShaanxiProvinceunderGrant Gulino, C.; Fu, J.; Luo, W.; Tucker, G.; Bronstein, E.; Lu,\n2025CY-YBXM-040, and in part by the XJTU Research Y.;Harb,J.;Pan,X.;Wang,Y.;Chen,X.;etal.2023. Way-\nFundforAlScienceunderGrant2025YXYC004. max: An accelerated, data-driven simulator for large-scale\nautonomousdrivingresearch. AdvancesinNeuralInforma-\ntionProcessingSystems,36:7730–7742.\nReferences Han,S.;Lin,C.;Shen,C.;Wang,Q.;andGuan,X.2023.In-\nterpreting adversarial examples in deep learning: A review.\nAbdelfattah,M.;Yuan,K.;Wang,Z.J.;andWard,R.2021.\nACMComputingSurveys,55(14s):1–38.\nAdversarialattacksoncamera-lidarmodelsfor3dcardetec-\nHau, Z.; Co, K. T.; Demetriou, S.; and Lupu, E. C. 2021.\ntion. In IEEE/RSJ International Conference on Intelligent\nObject removal attacks on lidar-based 3d object detectors.\nRobotsandSystems,2189–2194.IEEE.\narXivpreprintarXiv:2102.03722.\nAthalye, A.; Engstrom, L.; Ilyas, A.; and Kwok, K. 2018.\nHe,K.;Zhang,X.;Ren,S.;andSun,J.2016. Deepresidual\nSynthesizing robust adversarial examples. In International\nlearningforimagerecognition. InProceedingsoftheIEEE\nConferenceonMachineLearning,284–293.PMLR.\nConference on Computer Vision and Pattern Recognition,\nCaesar,H.;Bankiti,V.;Lang,A.H.;Vora,S.;Liong,V.E.;\n770–778.\nXu,Q.;Krishnan,A.;Pan,Y.;Baldan,G.;andBeijbom,O.\nHu,C.;Shi,W.;Yao,W.;Jiang,T.;Tian,L.;Chen,X.;and\n2020. nuscenes:Amultimodaldatasetforautonomousdriv-\nLi, W. 2024. Adversarial infrared curves: An attack on in-\ning. InProceedingsoftheIEEE/CVFConferenceonCom-\nfrared pedestrian detectors in the physical world. Neural\nputerVisionandPatternRecognition,11621–11631.\nNetworks,178:106459.\nCao, Y.; Bhupathiraju, S. H.; Naghavi, P.; Sugawara, T.;\nHu,C.;Shi,W.;Yao,W.;Jiang,T.;Tian,L.;andLi,W.2025.\nMao, Z. M.; and Rampazzi, S. 2023. You can’t see me:\nTwo-stageoptimizedunifiedadversarialpatchforattacking\nPhysical removal attacks on {lidar-based} autonomous ve-\nvisible-infraredcross-modaldetectorsinthephysicalworld.\nhiclesdrivingframeworks.InUSENIXSecuritySymposium,\nAppliedSoftComputing,112818.\n2993–3010.\nHu,Y.;Yang,J.;Chen,L.;Li,K.;Sima,C.;Zhu,X.;Chai,\nCao, Y.; Xiao, C.; Cyr, B.; Zhou, Y.; Park, W.; Rampazzi,\nS.;Du,S.;Lin,T.;Wang,W.;etal.2023. Planning-oriented\nS.;Chen,Q.A.;Fu,K.;andMao,Z.M.2019a. Adversar-\nautonomous driving. In Proceedings of the IEEE/CVF\nial sensor attack on lidar-based perception in autonomous\nConference on Computer Vision and Pattern Recognition,\ndriving. InProceedingsoftheACMSIGSACConferenceon\n17853–17862.\nComputerandCommunicationsSecurity,2267–2281.\nHu,Y.-C.-T.;Kung,B.-H.;Tan,D.S.;Chen,J.-C.;Hua,K.-\nCao, Y.; Xiao, C.; Yang, D.; Fang, J.; Yang, R.; Liu, L.;andCheng,W.-H.2021.Naturalisticphysicaladversarial\nM.; and Li, B. 2019b. Adversarial objects against patchforobjectdetectors. InProceedingsoftheIEEE/CVF\nlidar-based autonomous driving systems. arXiv preprint InternationalConferenceonComputerVision,7848–7857.\narXiv:1907.05418.\nHuang,J.;andHuang,G.2022. Bevdet4d:Exploittemporal\nChen,L.;Wu,P.;Chitta,K.;Jaeger,B.;Geiger,A.;andLi, cues in multi-camera 3d object detection. arXiv preprint\nH. 2024. End-to-end autonomous driving: Challenges and arXiv:2203.17054.\nfrontiers. IEEE Transactions on Pattern Analysis and Ma-\nHuang, J.; Huang, G.; Zhu, Z.; Ye, Y.; and Du, D. 2021.\nchineIntelligence.\nBevdet:High-performancemulti-camera3dobjectdetection\nChen,X.;Ma,H.;Wan,J.;Li,B.;andXia,T.2017. Multi- inbird-eye-view. arXivpreprintarXiv:2112.11790.\nview 3d object detection network for autonomous driving. Jin, Z.; Ji, X.; Cheng, Y.; Yang, B.; Yan, C.; and Xu, W.\nInProceedingsoftheIEEEConferenceonComputerVision 2023. Pla-lidar:Physicallaserattacksagainstlidar-based3d\nandPatternRecognition,1907–1915. objectdetectioninautonomousvehicle.InIEEESymposium\nCheng, Z.; Choi, H.; Liang, J.; Feng, S.; Tao, G.; Liu, D.; onSecurityandPrivacy,1822–1839.IEEE.\nZuzak,M.;andZhang,X.2023. Fusionisnotenough:Sin- Lee, M.; and Kolter, Z. 2019. On physical adver-\nglemodalattacksonfusionmodelsfor3Dobjectdetection. sarial patches for object detection. arXiv preprint\narXivpreprintarXiv:2304.14614. arXiv:1906.11897.\nGeiger, A.; Lenz, P.; and Urtasun, R. 2012. Are we ready Li,L.;Qing,L.;andChen,Y.-C.2023. Adv3d:Generating\nforautonomousdriving?thekittivisionbenchmarksuite. In 3dadversarialexamplesindrivingscenarioswithnerf.\nIEEEConferenceonComputerVisionandPatternRecogni- Li, Z.; Wang, W.; Li, H.; Xie, E.; Sima, C.; Lu, T.; Yu, Q.;\ntion,3354–3361.IEEE. andDai,J.2024. Bevformer:learningbird’s-eye-viewrep-\nGoodfellow,I.J.;Shlens,J.;andSzegedy,C.2014.Explain- resentationfromlidar-cameraviaspatiotemporaltransform-\ning and harnessing adversarial examples. arXiv preprint ers. IEEE Transactions on Pattern Analysis and Machine\narXiv:1412.6572. Intelligence.\n\nLin, C.; Ji, X.; Yang, Y.; Li, Q.; Zhao, Z.; Peng, Z.; Wang, Zhang, J.; Lou, Y.; Wang, J.; Wu, K.; Lu, K.; and Jia, X.\nR.;Fang,L.;andShen,C.2024. HardAdversarialExample 2021. Evaluating adversarial attacks on driving safety in\nMiningforImprovingRobustFairness. IEEETransactions vision-basedautonomousvehicles. IEEEInternetofThings\nonInformationForensicsandSecurity. Journal,9(5):3443–3456.\nLiu, Z.; Lin, Y.; Cao, Y.; Hu, H.; Wei, Y.; Zhang, Z.; Lin, Zhang,R.;Isola,P.;Efros,A.A.;Shechtman,E.;andWang,\nS.; and Guo, B. 2021. Swin transformer: Hierarchical vi- O.2018. Theunreasonableeffectivenessofdeepfeaturesas\nsiontransformerusingshiftedwindows. InProceedingsof aperceptualmetric. InProceedingsoftheIEEEConference\nthe IEEE/CVF International Conference on Computer Vi- onComputerVisionandPatternRecognition,586–595.\nsion,10012–10022. Zhang, T.; Wang, L.; Zhang, X.; Zhang, Y.; Jia, B.; Liang,\nMa, Y.; Wang, T.; Bai, X.; Yang, H.; Hou, Y.; Wang, Y.; S.;Hu,S.;Fu,Q.;Liu,A.;andLiu,X.2024. VisualAdver-\nQiao, Y.; Yang, R.; and Zhu, X. 2024. Vision-centric bev sarial Attack on Vision-Language Models for Autonomous\nperception:Asurvey. IEEETransactionsonPatternAnaly- Driving. arXivpreprintarXiv:2411.18275.\nsisandMachineIntelligence. Zhang, Y.; Hou, J.; and Yuan, Y. 2024. A comprehensive\nMao,J.;Shi,S.;Wang,X.;andLi,H.2023.3Dobjectdetec- study of the robustness for lidar-based 3d object detectors\ntion for autonomous driving: A comprehensive survey. In- against adversarial attacks. International Journal of Com-\nternationalJournalofComputerVision,131(8):1909–1963. puterVision,132(5):1592–1624.\nSato,T.;Shen,J.;Wang,N.;Jia,Y.;Lin,X.;andChen,Q.A. Zhu, Z.; Zhang, Y.; Chen, H.; Dong, Y.; Zhao, S.; Ding,\n2021. Dirtyroadcanattack:Securityofdeeplearningbased W.; Zhong, J.; and Zheng, S. 2023. Understanding the ro-\nautomated lane centering under Physical-World attack. In bustness of 3D object detection with bird’s-eye-view rep-\nUSENIXsecuritysymposium,3309–3326. resentations in autonomous driving. In Proceedings of\ntheIEEE/CVFConferenceonComputerVisionandPattern\nSun, J.; Cao, Y.; Chen, Q. A.; and Mao, Z. M. 2020. To-\nRecognition,21600–21610.\nwardsrobustLiDAR-basedperceptioninautonomousdriv-\ning: General black-box adversarial sensor attack and coun-\ntermeasures. InUSENIXSecuritySymposium,877–894.\nThys,S.;VanRanst,W.;andGoedeme´,T.2019.Foolingau-\ntomated surveillancecameras: adversarialpatches to attack\nperson detection. In Proceedings of the IEEE/CVF Con-\nferenceonComputerVisionandPatternRecognitionWork-\nshops,0–0.\nTu,J.;Ren,M.;Manivasagam,S.;Liang,M.;Yang,B.;Du,\nR.; Cheng, F.; and Urtasun, R. 2020. Physically realizable\nadversarialexamplesforlidarobjectdetection. InProceed-\ningsoftheIEEE/CVFConferenceonComputerVisionand\nPatternRecognition,13716–13725.\nWang,J.;Li,F.;andHe,L.2025. AUnifiedFrameworkfor\nAdversarialPatchAttacksagainstVisual3DObjectDetec-\ntioninAutonomousDriving.IEEETransactionsonCircuits\nandSystemsforVideoTechnology.\nWang, J.; Li, F.; Lv, S.; He, L.; and Shen, C. 2025. Physi-\ncallyRealizableAdversarialCreatingAttackagainstVision-\nbasedBEVSpace3DObjectDetection. IEEETransactions\nonImageProcessing.\nWang,J.;Li,F.;Zhang,X.;andSun,H.2023a. Adversarial\nobstacle generation against lidar-based 3d object detection.\nIEEETransactionsonMultimedia,26:2686–2699.\nWang, Z.; Yang, H.; Feng, Y.; Sun, P.; Guo, H.; Zhang, Z.;\nandRen,K.2023b. Towardstransferabletargetedadversar-\nialexamples. InProceedingsoftheIEEE/CVFConference\nonComputerVisionandPatternRecognition,20534–20543.\nXie, S.; Li, Z.; Wang, Z.; and Xie, C. 2023. On the adver-\nsarialrobustnessofcamera-based3dobjectdetection. arXiv\npreprintarXiv:2301.10766.\nYang,B.;Zhang,H.;Wang,J.;Yang,Y.;Lin,C.;Shen,C.;\nandZhao,Z.2025. AdversarialExampleSoups:Improving\nTransferabilityandStealthinessforFree.IEEETransactions\nonInformationForensicsandSecurity.\n\nSupplementary Materials for Invisible Triggers, Visible Threats! Road-Style\nAdversarial Creation Attack for Visual 3D Detection in Autonomous Driving\nJianWang,LijunHe,YixingYong,HaixiaBi,FanLi*\nSchoolofInformationandCommunicationsEngineering,Xi’anJiaotongUniversity\nwj851329121@stu.xjtu.edu.cn,lijunhe@mail.xjtu.edu.cn,yongyx@stu.xjtu.edu.cn,haixia.bi@mail.xjtu.edu.cn,\nlifan@mail.xjtu.edu.cn\nA.DetailsofImage-3DRendering\nInthissection,wepresentthedetailsoftheImage-3Dren-\ndering algorithm that differentiably render the 3D space\nposterontotheimage.Ingeneral,thecoreofthealgorithm Adversarial poster Place on 3D\nliesinfindingtherelativepositionofeachpixelintheadver- road surface\nsarial image region on the predefined poster, enabling per-\npixelinterpolation.\nSpecifically, we first calculate the projection matrix\nM3D→img ∈ R4×4 according to the camera’s intrinsic and Poster on Project the poster to Image\nextrinsicparameters.M3D→img canprojectpointsfromthe captured Image ia nc tc rio nrd sii cn ,g\na\nt no\nd\nc ra om ae dr ha\ne\ne igx htr ti n prs ii oc,\nr\n3D LiDAR coordinate system to the image plane. Then,\ngiven four poster corners {p3d ∈ R3|i = 1,2,3,4} in Figure1:IllustrationofImage-3Drendering.\ni\n3D coordinate system, we get four projected corner points\n{pimg ∈R2|i=1,2,3,4}inimageplane:\ni Model Backbone InputResolution mAP NDS\nResNet50 256×704 31.7 39.4\n[u i,v i,d i,1]T =M3D→img[x i,y i,z i,1]T BEVDet Swin-Tiny 256×704 33.4 41.8\n(1)\npimg =(u /d ,v /d ) BEVDet4D ResNet50 256×704 34.6 48.0\ni i i i i (8Frames) Swin-Tiny 256×704 36.3 48.9\nTheadversarialimageregionistheintersectionbetweenthe BEVFormer ResNet50 480×800 26.7 36.9\nquadrangle region defined by the projected corner points -Tiny Swin-Tiny 480×800 27.1 37.8\nand the image. For each pixel in this region, we need to\ncompute its position in the 3D space. However, we cannot Table1:Detectionperformanceofallvictimdetectorsonthe\ncompute it directly due to the lack of per-pixel depth in- nuScenesvalidationset.\nformation d . Nevertheless, we can indirectly calculate the\ni\n3D position of each point by leveraging the known height\ninformation z of the poster. Formally, for an adver-\nheight set with a batchsize of 40 (we accumulate the gradients of\nsarial point pi img = (u i,v i), the corresponding 3D point mini-batch multiple times to achieve a larger batchsize to\np3 id =(x i,y i,z i)canbesolved: stabilize training). The weight factor λ = 0.1. Stage 2 up-\ndatestherandomlyinitializedlatentvector30iterationsfor\n[x ,y ,z ,1]T =M−1 [u d ,v d ,d ,1]T\ni i i 3D→img i i i i i\n(2)\neachinputframe.\nz =z\ni height\nFinally, the color pixel of pimg is interpolated across the B.1DetectionPerformanceofVictimModels\ni\nneighborvaluesaroundp3dontheposter.\ni We present the detection performance of all six victim 3D\nB.AdditionalExperimentalResults detectors in Table 1. For the BEVDet and BEVDet4D, we\ntrain the model on 4 NVIDIA GeForce RTX 3090 GPUs\nTrainingDetail.Instage1,wetrainthegeneratoranddis-\nwithlearningrate2e-4for20epochs(withCBGS)anddrop\ncriminator alternately with an iteration ratio 1 : 10, using\nthe learning rate at epoch 17 by a factor of 0.1. The BEV\nAdamoptimizerwithalearningrateof0.0001.Thegenera-\ngrid size is 0.6m × 0.6m and 0.8m × 0.8m for BEVDet\ntoristotallyupdatedfor16epochsonthenuScenestraining\nand BEVDet4D respectively. For the BEVFormer, we train\nthemodelfor24epochswiththeCosineAnnealingstrategy\n*Correspondingauthors.\nCopyright©2026,AssociationfortheAdvancementofArtificial (initiallearningrateis2e-4).TheBEVgridsizeis0.512m×\nIntelligence(www.aaai.org).Allrightsreserved. 0.512m.\n\nB.4Discussion\nTransferability.WeevaluatethetransferabilityofAdvRoad\nacross different detectors through the black-box settings,\nwhere attackers have no access to the details of the target\nmodel. Since the latent vector search in Stage 2 requires\ninteraction between the adversary input and the model, we\nonlyusepostersgeneratedinStage1fortheattack.Specifi-\ncally,wefirstusethegeneratortrainedonthesourcemodel\nto randomly generate 500 posters, then select the 10 most\neffectiveones(withthehighestconfidence)toattackthetar-\nget models. This process does not require any information\naboutthetargetmodels.\n\u00007\u0000D\u0000U\u0000J\u0000H\u0000W\u0000\u0003\u00000\u0000R\u0000G\u0000H\u0000O\u0000V\n\u0000% \u0000( \u00009\n\u0000'\u0000H\u0000W\u0000\u0010 \u0000%\u00005 \u0000\u0018 \u0000(\u0000\u0013\n\u00009\n\u0000'\u0000H\u0000W\u0000\u0010 \u0000%\u00006 \u0000Z \u0000(\u0000L \u00009\u0000Q \u0000'\u00007 \u0000H\u0000W\u0000\u0017 \u0000%\u0000' \u0000(\u0000\u0010\u00005 \u00009\u0000\u0018 \u0000'\u0000\u0013 \u0000H\u0000W\u0000\u0017 \u0000%\u0000' \u0000(\u0000\u0010\u00006 \u00009\u0000Z \u0000)\u0000L \u0000R\u0000Q \u0000U\u00007 \u0000P \u0000%\u0000H\u0000U \u0000(\u0000\u0010 \u00009\u00005 \u0000)\u0000\u0018 \u0000R\u0000\u0013 \u0000U\u0000P\u0000H\u0000U\u0000\u0010\u00006 \u0000Z\u0000L\u0000Q \u00007\n\u0000%\u0000(\u00009\u0000'\u0000H\u0000W\u0000\u0010\u00005\u0000\u0018\u0000\u0013\n\u0000%\u0000(\u00009\u0000'\u0000H\u0000W\u0000\u0010\u00006\u0000Z\u0000L\u0000Q\u00007\n\u0000%\u0000(\u00009\u0000'\u0000H\u0000W\u0000\u0017\u0000'\u0000\u0010\u00005\u0000\u0018\u0000\u0013\n\u0000%\u0000(\u00009\u0000'\u0000H\u0000W\u0000\u0017\u0000'\u0000\u0010\u00006\u0000Z\u0000L\u0000Q\u00007\nFigure 2: Quantitative visual comparison in terms of the\nLPIPS(↓)withotherattackposters. \u0000%\u0000(\u00009\u0000)\u0000R\u0000U\u0000P\u0000H\u0000U\u0000\u0010\u00005\u0000\u0018\u0000\u0013\n\u0000%\u0000(\u00009\u0000)\u0000R\u0000U\u0000P\u0000H\u0000U\u0000\u0010\u00006\u0000Z\u0000L\u0000Q\u00007\nASR(%,↑)\nAttack\n2.0m 1.5m 1.0m 0.5m\nAdvPoster 19.7% 14.6% 10.4% 3.9%\nAdvRoad 32.4% 25.5% 14.8% 7.1%\nTable2:Attackresultsafterapplyingadversarialsegmenta-\ntionasdefense.\nB.2VisualizationofDifferentAttackPosters\nWe provide more visual comparisons with other attack\nposters in Fig. 2. The LPIPS score (↓) evaluates the per-\nceptual similarity by utilizing neural networks to compare\nmulti-layer features between benign and attacked images.\nThe results show that AdvRoad exhibits the best conceal-\nmentandenvironmentalconsistency.\nB.3AdversarialSegmentationasDefense\nWetrainalightweightadversarialsegmentationnetworkto\npredict the poster areas in the image. During evaluation,\nthe poster region in the input image is first segmented and\nmaskedoutbeforeperformingdetection.TheresultingASR\nonBEVDet-R50afterapplyingthisdefenseisshowninTa-\nble2.AlthoughAdvRoadhasalowerASRthanAdvPoster\nwithout defense, it shows stronger resistance to the fine-\ntuned detector and adversarial segmentation. This robust-\nness comes from: 1) its similarity to the road background,\nand2)diversepostercontent.\n\u0000V\u0000O\u0000H\u0000G\u0000R\u00000\u0000\u0003\u0000H\u0000F\u0000U\u0000X\u0000R\u00006\n\u0000\u0017\u0000\u0018\n\u0000\u0016\u0000\u0015\u0000\u0011\u0000\u0014 \u0000\u001b\u0000\u0011\u0000\u0018 \u0000\u0015\u0000\u0015\u0000\u0011\u0000\u0017 \u0000\u0014\u0000\u001a\u0000\u0011\u0000\u0019 \u0000\u0014\u0000\u0016\u0000\u0011\u0000\u0017 \u0000\u001b\u0000\u0011\u0000\u0013\n\u0000\u0017\u0000\u0013\n\u0000\u0014\u0000\u0013\u0000\u0011\u0000\u001b \u0000\u0017\u0000\u0015\u0000\u0011\u0000\u0019 \u0000\u0014\u0000\u0013\u0000\u0011\u0000\u0018 \u0000\u0015\u0000\u0018\u0000\u0011\u0000\u0018 \u0000\u001c\u0000\u0011\u0000\u0018 \u0000\u001c\u0000\u0011\u0000\u0014 \u0000\u0016\u0000\u0018\n\u0000\u0016\u0000\u0013\n\u0000\u0014\u0000\u0015\u0000\u0011\u0000\u001b \u0000\u001c\u0000\u0011\u0000\u0013 \u0000\u0015\u0000\u0018\u0000\u0011\u0000\u0014 \u0000\u001b\u0000\u0011\u0000\u001a \u0000\u0019\u0000\u0011\u0000\u0017 \u0000\u0015\u0000\u0011\u0000\u001c\n\u0000\u0015\u0000\u0018\n\u0000\u001c\u0000\u0011\u0000\u0015 \u0000\u0014\u0000\u0014\u0000\u0011\u0000\u0018 \u0000\u0014\u0000\u0015\u0000\u0011\u0000\u0016 \u0000\u0017\u0000\u0018\u0000\u0011\u0000\u0015 \u0000\u0018\u0000\u0011\u0000\u001c \u0000\u001a\u0000\u0011\u0000\u001a \u0000\u0015\u0000\u0013\n\u0000\u0014\u0000\u0018\n\u0000\u0018\u0000\u0011\u0000\u0016 \u0000\u0015\u0000\u0011\u0000\u0017 \u0000\u0014\u0000\u0016\u0000\u0011\u0000\u001c \u0000\u0016\u0000\u0011\u0000\u0018 \u0000\u0017\u0000\u0014\u0000\u0011\u0000\u0015 \u0000\u001b\u0000\u0011\u0000\u001a\n\u0000\u0014\u0000\u0013\n\u0000\u0018\u0000\u0011\u0000\u0018 \u0000\u0015\u0000\u0011\u0000\u0018 \u0000\u001a\u0000\u0011\u0000\u0016 \u0000\u0016\u0000\u0011\u0000\u0016 \u0000\u0014\u0000\u0017\u0000\u0011\u0000\u0019 \u0000\u0015\u0000\u0014\u0000\u0011\u0000\u001b\n\u0000\u0018\nFigure3:Transferresultsacrosssixdetectors.TheASR(%)\nunderCD2.0maregiven.\nThe transfer results are provided in Fig. 3. We make the\nfollowingobservations.First,detectorsthatadoptthesame\nPV2BEV transformation exhibit better transferability. For\nexample,thefourmodelswithintheBEVDetseriesachieve\na minimum ASR of 8.5%, while the posters generated on\nBEVFormer showed a lower limit on BEVDet. Such as a\nminimum of 2.4%, which almost fails in this case. Since\ntheBEVDetseriesrequiresexplicitper-pixeldepthestima-\ntion for feature projection, whereas BEVFormer does not,\nthis may lead to differences in the semantic focus of the\nlearned posters. Second, detectors with the same backbone\nexhibitbettertransferability.Forexample,posterslearnedon\nBEVDet-SwinTachieve25.5%ASRonBEVDet4D-SwinT,\ncompared with 10.5% on BEVDet4D-R50. These results\nmayprovideinsightsfordesigningmoretransferableadver-\nsarialattacks.\nDiversityandEffectiveness.Toexploretheupperbound\noftheattackcapabilityoftheimplicitrepresentationofthe\nadversarial poster, we supervise the generator using only\nL , without considering gradients from L . The results\nobj cls\nare given in Table 3. It can be observed that AdvRoad†\nachievesasignificantimprovementinASRcomparedtothe\nAdvRoad, at the cost of natural appearance. Some of the\nposteroutputfromthegeneratorisvisualizedinFig.4.We\nfind that no matter what the latent vector input is, the gen-\n\nASR(%,↑)\nModel Attack Diversity Natural-looking LPIPS↓\n2.0m 1.5m 1.0m 0.5m\nAdvPoster × × 0.1929 91.0 83.4 64.8 33.2\nBEVDet-R50 AdvRoad ✓ ✓ 0.1472 62.6 55.6 42.7 23.3\nAdvRoad† × × 0.2100 80.3 69.4 49.4 22.1\nAdvPoster × × 0.1737 91.8 84.7 66.5 38.3\nBEVDet-SwinT AdvRoad ✓ ✓ 0.1337 60.2 56.3 47.6 28.8\nAdvRoad† × × 0.2172 86.7 81.5 69.2 41.9\nAdvPoster × × 0.1758 86.9 78.6 58.7 30.8\nBEVDet4D-R50 AdvRoad ✓ ✓ 0.1331 49.1 42.9 32.7 17.7\nAdvRoad† × × 0.2223 79.0 71.8 55.6 29.6\nAdvPoster × × 0.1748 92.7 87.9 73.4 40.8\nBEVDet4D-SwinT AdvRoad ✓ ✓ 0.1370 39.1 35.1 27.8 15.7\nAdvRoad† × × 0.1966 86.8 80.5 64.9 36.6\nAdvPoster × × 0.1104 82.6 73.3 57.0 29.7\nBEVFormer-R50 AdvRoad ✓ ✓ 0.0822 44.5 32.7 20.7 8.2\nAdvRoad† × × 0.1082 70.1 58.0 41.2 19.8\nAdvPoster × × 0.1026 83.9 74.8 58.0 31.0\nBEVFormer-SwinT AdvRoad ✓ ✓ 0.0818 37.3 30.6 21.0 8.9\nAdvRoad† × × 0.1196 74.9 65.4 48.5 24.3\nTable3:DigitalattackresultsofdifferentcreationpostersinthenuScenesdataset.†denotestrainingthegeneratorunderthe\nsupervisionofadversarialobjectiveL only.\nobj\nB.5FurtherAnalysisofthePhysicalAttack\nInpractice,ourphysicalexperimentsyieldthefollowingin-\n(a) BEVDet-R50\nsights: 1. Factors affecting overall color—such as lighting,\nprintcolordeviation,andreflectivity—arekeytoattacksuc-\ncess. Due to AdvRoad’s similarity to road surfaces, its de-\n(b) BEVDet-SwinT ceptivepatternsrequirehighcolorfidelity.Incontrast,Adv-\nPoster’svividpatternsshowgreaterrobustnesstosuchfac-\ntors.2.Localdistortions(e.g.,wrinkles,occlusions)usually\n(c) BEVDet4D-R50 cause only positional shifts in detection results and do not\ninvalidatetheattack.Thissuggeststhattheadversarialinfor-\nmationisdistributedacrossthewholeposterandisinsensi-\ntive to local damage. 3. Although we didn’t test under rain\n(d) BEVDet4D-SwinT\nornightconditions,wesuspectbothmethodswouldperform\npoorly,asmuchinformationwouldbelostafterimagecap-\nture. For example, 3D detectors already struggle to detect\n(e) BEVFormer-R50 real vehicles at night. A potential solution is to use projec-\ntorstodisplaytheposter,whichweplantoexploreinfuture\nwork.\n(f) BEVFormer-SwinT\nFigure 4: Visualization of the posters for AdvRoad†. The\nposters from the same model (randomly generating 6 sam-\nplesforeachmodel)sharesimilarcontentandhaveunnatu-\nralpatterns.\neratoroutputssimilarcontentandlosesthediversity.More-\nover,theexplicitrepresentationoftheadversary,AdvPoster,\ndemonstratesstrongerattackcapabilityandhigheroptimiza-\ntionefficiency.Similarly,atthecostofdiversityandvisual\nnaturalness.\n\n",
    "total_pages": 12,
    "pages": [
      {
        "page": 1,
        "content": "Invisible Triggers, Visible Threats! Road-Style Adversarial Creation Attack for\nVisual 3D Detection in Autonomous Driving\nJianWang,LijunHe,YixingYong,HaixiaBi,FanLi*\nSchoolofInformationandCommunicationsEngineering,Xi’anJiaotongUniversity\nwj851329121@stu.xjtu.edu.cn,lijunhe@mail.xjtu.edu.cn,yongyx@stu.xjtu.edu.cn,haixia.bi@mail.xjtu.edu.cn,\nlifan@mail.xjtu.edu.cn\nAbstract\nModernautonomousdriving(AD)systemsleverage3Dob-\njectdetectiontoperceiveforegroundobjectsin3Denviron-\nmentsforsubsequentpredictionandplanning.Visual3Dde-\ntectionbasedonRGBcamerasprovidesacost-effectiveso-\nlution compared to the LiDAR paradigm. While achieving\npromising detection accuracy, current deep neural network-\nbased models remain highly susceptible to adversarial ex-\namples. The underlying safety concerns motivate us to in-\nvestigate realistic adversarial attacks in AD scenarios. Pre-\nvious work has demonstrated the feasibility of placing ad-\nversarialpostersontheroadsurfacetoinducehallucinations\nin the detector. However, the unnatural appearance of the\nposters makes them easily noticeable by humans, and their\nfixed content can be readily targeted and defended. To ad-\ndresstheselimitations,weproposetheAdvRoadtogenerate\ndiverse road-style adversarial posters. The adversaries have\nnaturalistic appearances resembling the road surface while\ncompromisingthedetectortoperceivenon-existentobjectsat\ntheattacklocations.Weemployatwo-stageapproach,termed\nRoad-Style Adversary Generation and Scenario-Associated\nAdaptation,tomaximizetheattackeffectivenessontheinput\nFigure 1: Illustration of the adversarial FP attacks on the\nscenewhileensuringthenaturalappearanceoftheposter,al-\nroad. The 3D detection system will perceive a ghost ob-\nlowingtheattacktobecarriedoutstealthilywithoutdrawing\njectneartheposter.Comparedwithpreviouswork(left),our\nhumanattention.ExtensiveexperimentsshowthatAdvRoad\ngeneralizes well to different detectors, scenes, and spoofing poster(right)ishardertoattracthumanattention,makingit\nlocations.Moreover,physicalattacksfurtherdemonstratethe morelikelytoposearealthreat.\npracticalthreatsinreal-worldenvironments.\nCode—https://github.com/WangJian981002/AdvRoad etal.2023;Wangetal.2023b).Recentstudieshaverevealed\nthatcarefullydesignedinputs,suchasadditiveperturbations\n(Zhangetal.2024,2021;Goodfellow,Shlens,andSzegedy\nIntroduction\n2014;Athalyeetal.2018)andlocalpatches(Guesmietal.\nVisual3Dobjectdetection(Maetal.2024;Huetal.2023;\n2024;Thys,VanRanst,andGoedeme´ 2019;Huetal.2024,\nChen et al. 2017) has emerged as a pivotal technology in\n2025), can catastrophically alter the output of DNNs, and\nautonomous driving systems (Mao et al. 2023; Chen et al.\ntheseadversarialexamplescanbesuccessfullyimplemented\n2024; Gulino et al. 2023), offering cost-effective environ-\ninphysicalscenarios(Satoetal.2021).Thissecuritythreat\nmentalperceptionthroughwidelyaccessibleRGBcameras.\nposesunpredictableconsequencesgiventhelife-criticalna-\nDespite its computational efficiency and hardware afford-\ntureof3Dperceptionsystems,whichmotivatesustoinves-\nability compared to LiDAR-dependent methods, the relia-\ntigaterealisticadversarialattacksfor3Dobjectdetectionin\nbilityofdeepneuralnetworks(DNNs)insafety-criticalsce-\nreal-worldenvironments.\nnariosremainsquestionableduetotheirvulnerabilitytoad-\nAdversarialattackson3Dobjectdetectorscanbedivided\nversarial attacks (Yang et al. 2025; Lin et al. 2024; Han\ninto two types based on model errors: false negatives (FN)\nwhererealobjectsevadedetection,andfalsepositives(FP)\n*Correspondingauthor.\nCopyright©2026,AssociationfortheAdvancementofArtificial wherenon-existenttargetsareidentified.Mostexistingstud-\nIntelligence(www.aaai.org).Allrightsreserved. ies (Zhu et al. 2023; Abdelfattah et al. 2021; Cheng et al.\n5202\nvoN\n11\n]VC.sc[\n1v51080.1152:viXra"
      },
      {
        "page": 2,
        "content": "VictimModel AttackWay Consequence\nMaliciouslasersignalinjection\nFN\n(Caoetal.2023;Jinetal.2023;Hauetal.2021)\nLiDAR-based Maliciouslasersignalinjection\nFP\n(Jinetal.2023;Sunetal.2020;Caoetal.2019a;Wangetal.2023a)\n3Dadversarialmesh(Tuetal.2020;Caoetal.2019b) FN\nAdversarialcamouflage(Li,Qing,andChen2023) FN\nAdversarialpatch\nCamera-based FN\n(Zhuetal.2023;Wang,Li,andHe2025;Chengetal.2023;Xieetal.2023)\nAdversarialposter(Wangetal.2025) FP\nTable1:Thesummarizationofphysicaladversarialattackstargeting3DobjectdetectioninAD.\n2023; Tu et al. 2020; Zhang, Hou, and Yuan 2024; Wang, First, we use drones to take aerial photos of ground scenes\nLi, and He 2025) focus on FN attacks — for example, at- and construct a road image collection for training the style\ntaching adversarialpatches tovehicles tomake them invis- discriminator.Then,wegraduallyupdatethegeneratorbyit-\nible to detectors, which may result in a rear-end collision. erativelyrenderingthemappedposterontothesceneimage\nHowever,implementingFNattackstypicallyrequiresphys- and backpropagating the gradients based on the adversar-\nical access to the target object, limiting their practical ap- ialobjectiveandstylediscriminator.Thefirststageensures\nplication.FPattacks,ontheotherhand,aimtomakedetec- that the generated posters are similar to the source collec-\ntors”see”imaginaryobstacles,potentiallytriggeringsudden tionimageswhilebeingabletocompromisethedetector.In\nbrakingordangerouslanechangesbyautonomousvehicles. the second stage, we derive a local-optimal poster tailored\nDespiteposingsimilarsafetyrisksasFNattacks,FPattacks toaspecificinput,aimingtoenhanceitsdeceptiveeffective-\nforvisual3Ddetectionremainpoorlystudiedinthecurrent ness within the given scenario. Concretely, we initialize a\nattackliterature. posterfromthegeneratortrainedinthefirststage,randomly\nRecently,Wangetal.(Wangetal.2025)pioneeredphysi- sampleandplaceitatvariouslocationsinthecurrentscene,\ncalFPattacktargetingvisual3Ddetectorsbyplacingacare- and then backpropagate the gradients to the latent space to\nfullyoptimizedposterontheroad,therebyinducingthede- optimizethenoisevectortowardalocallyoptimalsolution.\ntector to perceive a ghost object near the poster (as shown Note that in this stage, the generator is frozen. Therefore,\nin Fig. 1 left). Since the poster is 2D and lacks thickness, thefoundadversarynotonlyhasnaturalisticroadstylesbut\nit is flexible to print and launch the attack. Moreover, the alsoachievesthestrongestattackeffectivenessinthecurrent\ngenerated poster has strong generalization ability, allowing scene.\nittobeeffectiveinvariousscenarios.Theylearntheposter Inshort,ourcontributionsare:\nbyproposinganimage-3Dapplyingalgorithmthatcandif- • WepresentanaturalisticFPattackpipelineforinducing\nferentiably render the 3D space poster onto the image, and theghostobjectontheroad.Thecraftedposterscansig-\ndirectly optimizing the poster’s pixel values. However, the nificantly evade human perception while compromising\nfollowing weaknesses remain: ❶ The content of the poster the3Dmodels,therebyincreasingthepracticalthreatto\nsignificantly differs from the road surface, making it easily theADsystem.\nnoticedbyhumans.Directlyoptimizingposterpixelscannot\n• We introduce Road-Style Adversary Generation and\nconstrainthelearnedcontent,whichoftenhaspatternswith\nScenario-Associated Adaptation to maximize the attack\nnon-naturalistic appearances. ❷ Each training session can\ncapabilityoftheadversarialposter.Moreover,alladver-\nonlygenerateoneposter,makingiteasytobetargetedand\nsaries are effective across various scenes and at certain\ndefended. They generate a single adversarial poster that is\nobservationdistances(e.g.,≤10m).\neffective across all scene images. Despite achieving a high\n• Extensive experiments in both the digital and physical\nattacksuccessrate,thesinglepostercanbeeasilyexploited\nworlds demonstrate the effectiveness of our approach\nand defended against (e.g., by fine-tuning the model with\nwith improved stealthiness. In addition, our posters are\ndatacontainingthisadversary).\nharder to defend against using existing defense tech-\nIn response to limitations ❶ and ❷, we propose a novel\nniques.\nFP attack pipeline that generates diverse road-style adver-\nsarialposters.Allpostershavepatternssimilartotheback-\nRelatedWork\nground road surface, making them harder to attract human\nattention,allowingtheattacktoproceedsilently.Ourframe- 3D object detection is the most crucial perception task in\nworkemploysatwo-stageapproach,Road-StyleAdversary modular autonomous driving systems, which identifies and\nGeneration and Scenario-Associated Adaptation, to gener- locates surrounding traffic participants like vehicles and\natediversenaturalisticadversaries.Inthefirststage,weuti- pedestrians in 3D space. Errors in detection results grad-\nlize GAN-based techniques to train an adversarial genera- ually accumulate, thereby affecting subsequent predictions\ntor that maps latent noise vectors to road-style adversaries. andplanning."
      },
      {
        "page": 3,
        "content": "Update generator G, Stage 1\nUpdate discriminator D, Stage 1\nRoad\nreal\nImage\nCollection\nfake\n…\nGenerator Discriminator\n3D position sampling\nImage-3D 3D Detector\nRoad Image Collection Scene image Rendering\nUpdate noise n ( ), Stage2\nFigure 2: The AdvRoad framework. Stage 1 trains an adversarial generator that outputs universal road-style posters; Stage 2\nupdatestheposter(thelatentvector)toenhancetheattackcapabilityforthegivenscene.\nRecent research efforts have developed various physical theresponsey∗undertheadversarialinput:\nattack methods targeting LiDAR-based and camera-based maxlogp(y∗|R(x,δ,t)) (1)\ndetectionalgorithms.Weprovideasummaryoftheseworks δ\nin terms of physical attack ways and attack consequences\nwherepistheprobabilityfunction;δ istheadversarytobe\ninTable1.ForLiDAR-basedapproaches,attackersmustal-\noptimized,whichcaneitherbeanexplicitrepresentationof\nter the captured LiDAR point clouds. This can be achieved the poster (e.g., a pixel array P ∈ [0,255]3×H×W) or an\nby strategically emitting laser pulses toward the target Li- implicit representation (e.g., a generator G : n ∈ Rd →\nDAR sensor (Cao et al. 2019a; Jin et al. 2023; Cao et al. P ∈[0,255]3×H×W,n∼N(0,1)).\n2023)orplacing3Dadversarialobjectsintheenvironment\nContinuous Attack Goals. When driving, the observa-\n(Tuetal.2020;Caoetal.2019b).However,alteringLiDAR\ntionofthescenechangescontinuously,suchasvaryingdis-\ndatatypicallyrequirescomplexequipmentlikelaserdiodes,\ntances and viewing angles. The practical threat posed by\nphotodiodes,orindustrial-grade3Dprinters.Thislimitsthe\na road-surface poster is substantially reduced if its effec-\nattack’s flexibility in dynamically changing AD scenarios.\ntiveness is confined to a specific scenario or location. Be-\nForcamera-basedapproaches,attackerscanutilizemoreaf-\ncause the AD system is likely to classify targets appearing\nfordableadversarialpatchestoperturbthecapturedimages,\ninmerelyoneortwoframesassensornoise.Consequently,\nleadingtovariousdetectionerrors.ExtendingWangetal.’s\nthese posters must exhibit universality to remain effective\nframework(Wangetal.2025)ofusingroadsurfaceposters\nacrossvaryingscenariosandviewingdistances.\ntocreatefake3Dobjects,wefurtherstudyhowtohidethese\nTo this end, we leverage the Expectation of Transforma-\npatternsfromhumandrivers.Thespoofingcapabilitytode-\ntion(EoT)(Athalyeetal.2018)acrossalltrainingsamples\ntectorsandstealthinesstohumansmaketheattackmoredan-\nandawiderangeofspoofinglocationstoenhancethephys-\ngerousinrealdrivingscenarios.\nical robustness and generality of the attack. Formally, the\noptimizationobjectivebecomes:\nProblemDefinition δ =argmaxXXlogp(y∗|R(x,δ,t)) (2)\nx∈Xt∈T\nWeinvestigateadversarialFPattacksagainstvisual3Dob-\nwhere X comprises all possible image inputs and T is the\nject detection models by placing the learned poster on the\nsetofpositiontransformationparameters.\nroad surface. Specifically, attackers apply the adversarial\nposter to a benign image x by firstly sampling the poster ProposedAdvRoadFramework\nlocationin3Dspaceandthenrenderingtheposterontothe\nRoad-StyleAdversaryGeneration\nimage.ThisresultsinanadversarialinputR(x,δ,t),where\nR(·) is the rendering function that applies the adversary δ Fig.2presentstheframeworkofourroad-stylecreationat-\nto the input x according to the sampled transformation pa- tack. The first stage aims to learn an adversarial generator\nrametert.Ourgoalistoinducethe3Ddetector,denotedas thatoutputsdiverseroad-styleposterswhilecontainingcrit-\nF ,toproduceadesiredresponsey∗ attheposterposition, icalforegroundfeatures,enablingthemtoinduceFPpredic-\nθ\nwhich is formally defined by maximizing the likelihood of tionsinthedetector.WeemployastandardGANpipelineto"
      },
      {
        "page": 4,
        "content": "integrateroadsurfacestyleandspoofinginformationtothe versariallossL andupdatevectorn.Thisprocessisfor-\nobj\ngenerator. mulatedas:\nRoad Image Collection. We utilize a DJI drone to cap-\ntureaerialphotographyoftrafficscenes,obtainingaseriesof\nn0 =n\n(5)\nraw images containing diverse road surfaces. We then crop n i+1 =n i−α·∇ niJ(F θ(R(x,G(n i),t)),y∗)\nauthenticroadpatchesfromthecollectedaerialimages,with\nWe repeat this process until reach the maximum iteration\neachpatchdimensionapproximatingvehiclesize(2m×4m).\nnumber. To preserve realism, we ensure that the updated\nThe built collection comprises over 2,000 road surface im-\nagescoveringvariousroadpatternsandstyles(asshownin noise n i+1 falls into the hypersphere of radius η centered\nFig. 2 left). This collection serves as the real reference for\natinitialnoisen0 ineachiteration.Thefinalposterexhibits\nstrongestdeceptivecapabilityinthecurrentscenewhilebe-\ntrainingthestylediscriminator,whilethesyntheticcounter-\ningauthentic.\nparts are generated by the generator. The inclusion of au-\nthenticimageryfacilitateslearningtherealisticroadpatterns\nImage-3DRendering\nfrom the generator, thereby enhancing the visual indistin-\nguishabilityofadversarialoutputstohumandrivers. Conventional 2D patch rendering (Thys, Van Ranst, and\nAdversarial Objective. The adversarial generator G is Goedeme´2019;LeeandKolter2019;Huetal.2021)solely\ntrainedonthewholedetectiondatasetX.Givenaframeof performsscalingandrotatingthepatchaccordingtotheob-\ninput image x ∈ X, we first sample the poster locations jects’ 2D bounding boxes. Although convenient, the phys-\nin the 3D space then render the poster G(n),n ∈ Rd to ical size of the patch and its position in 3D space are not\nthexthroughdifferentiableImage-3Drendering(discussed considered, which are critical for realistic physical attacks\nlater). Then, we prepare the adversarial label y∗ for the in- on 3D detectors. Following (Wang et al. 2025; Zhu et al.\nput R(x,δ,t). We mask out the regions of real objects on 2023), we briefly introduce how to render the poster from\nthe input image using ground truth (GT) bounding box an- the3Droadsurfaceontotheimage.\nnotations, and replace the GT labels with spoofing bound- First, we sample the 3D spatial positions of posters to\ning boxes introduced by the posters. This approach pro- place them on the road surface. Within a sector spanning\nvides dual advantages: First, masking surrounding objects ±∆ relative to the vehicle’s heading direction and a dis-\nθ\npreventsthegradientbeingvanishingbyaveraging.Second, tance range of d to d meters, we randomly sample\nmin max\nwe can reuse the detector’s native loss function to directly placementlocationswhileavoidingoverlappingwithexist-\ncalculatetheadversarialloss.Formally,theadversarialloss ing scene objects. Second, we project the four poster cor-\nis: ner points onto the image plane using the camera’s intrin-\nL =J(F (R(x,G(n),t)),y∗) (3) sicandextrinsicmatrices,therebydeterminingtheadversar-\nobj θ\nial region in the image (the quadrangle region defined by\nwhereJ(·)istheoriginallossfunctionfordetectorF .The\nθ projected corner points). Third, for each pixel within this\nother training objective comes from style discriminator D.\nregion, we inversely calculate its 3D coordinates aided by\nWe freeze the D and maximize the discriminator’s confi-\nroadheightinformation(approximatedfromthebottomface\ndenceinclassifyingthegenerator’soutputsasreal.Thefinal\nheight of the nearest scene object to the poster). Finally,\ntrainingobjectiveforthegeneratoris:\neachpixel’sRGBvalueiscalculatedviabilinearinterpola-\nL =L +λ·L (4) tionbasedonits3Dpositionrelativetotheposter.Formore\nG cls obj\ndetailsrefertosupplementary-A.\nWe alternately train the generator and the discriminator,\ngradually injecting spoofing and style information into the Experiment\ngeneratedposters.\nExperimentalSetup\nScenario-AssociatedAdaptation\nVictim Model. The vision-based BEV space 3D detec-\nAfter the first stage training, the posters output by the gen- tor BEVDet (Huang et al. 2021), BEVDet4D (Huang and\neratorbothresembletheroadsurfaceandmaintainacertain Huang2022),andBEVFormer(Lietal.2024)areselected\ndegree of deception. They can serve as a universal trap to as victim models for the attack, considering their repre-\ntriggerFPpredictionsinthe3Ddetector.However,thegen- sentativeness and the fact that BEV space inherently sup-\neratedpostersrelyonsamplingnoisefromthelatentspace— ports most downstream perception tasks for AD (Hu et al.\na process that involves inherent randomness and may lead 2023).Foreachdetector,theResNet50(Heetal.2016)and\nto unstable attack effects. Therefore, we further introduce SwinTransformer-Tiny (Liu et al. 2021) are used as image\nScenario-AssociatedAdaptationtoenhancetheattackcapa- backbonerespectively.\nbilityofthepostersinspecificscenarios. Dataset. For the digital attack, we use nuScenes dataset\nSpecifically,giventheinputscenariox,wefirstrandomly (Caesar et al. 2020) to train the adversary and perform the\ninitialize the noise vector n from the Gaussian distribution attack.nuScenesisalarge-scale,multi-modaldatasetspecif-\nN(0,1)andfednintothefrozengeneratortogetthespoof- icallydesignedforADand3Dobjectdetection.Thetraining\ningposter.Then,werandomlysampletheposterlocationsin andvalidationsetcontains28,130and6,019framesrespec-\nthe current scene and perform rendering. Finally, we back- tively,witheachframeincludingimagedatafromsixcam-\npropagate the gradient to the latent space based on the ad- erasand360◦ 3Dobjectannotations.Wetrainalldetectors"
      },
      {
        "page": 5,
        "content": "ASR(%,↑)\nModel Attack LPIPS↓\n2.0m 1.5m 1.0m 0.5m\nBenign - 1.5 0.3 0.1 0\nBEVDet Random 0.2136 8.0 4.9 2.9 0.8\n-R50 Realpicture 0.2066 30.4 22.8 15.7 6.3\nAdvRoad 0.1472 62.6 55.6 42.7 23.3\nBenign - 1.2 0.2 0 0\nBEVDet Random 0.2138 1.7 0.7 0.4 0.1\n(a) AdvRoad\n-SwinT Realpicture 0.2066 25.7 19.0 12.1 4.9\nAdvRoad 0.1337 60.2 56.3 47.6 28.8\nBenign - 1.2 0.1 0 0\n(b) AdvPoster (c) Real Picture BEVDet4D Random 0.2137 3.4 1.9 1.2 0.3\n-R50 Realpicture 0.2066 45.1 38.1 29.0 14.9\nFigure 3: Visualizations of attack results in the digital do- AdvRoad 0.1331 49.1 42.9 32.7 17.7\nmain. We place the spoofing poster on the road surface to\nBenign - 1.2 0.3 0 0\nlaunch the attack. (1) AdvRoad, our road-style naturalistic\nBEVDet4D Random 0.2136 1.4 0.3 0 0\nadversarialposter;(2)AdvPoster(Wangetal.2025),gener-\n-SwinT Realpicture 0.2066 23.4 19.3 13.7 7.3\natedbydirectlyoptimizingthepixelvalues;(3)RealPicture,\nAdvRoad 0.1370 39.1 35.1 27.8 15.7\nuseimagesofrealvehiclesasposters.\nBenign - 1.4 0.3 0 0\nBEVFormer Random 0.1304 1.4 0.3 0 0\n-R50 Realpicture 0.1260 6.3 3.5 1.8 0.7\non the training set following their official settings and de-\nAdvRoad 0.0822 44.5 32.7 20.7 8.2\ntection performances are given in supplementary-B.1. The\nconfidence scores for the detected objects are over 0.1 for Benign - 1.5 0.3 0 0\nallmodelsfollowing(Wangetal.2025;Tuetal.2020). BEVFormer Random 0.1306 1.5 0.5 0.1 0\nEvaluationMetric.Theattacksuccessrate(ASR)isused -SwinT Realpicture 0.1260 20.9 16.6 10.4 4.3\nAdvRoad 0.0818 37.3 30.6 21.0 8.9\nto evaluate the creation attack, which measures the propor-\ntionofsuccessfullydetectedfakeobjectsamongallspoofing\nTable2:Digitalattackresultsofadversarialcreationattack\nattempts.Weconsiderafakeobjectissuccessfullydetected\ninthenuScenesdataset.\nwhen theminimum distancebetween thedetector’s predic-\ntions and the center of the poster is less than d . Multi-\nthr\nple center distance thresholds, {2.0m,1.5m,1.0m,0.5m},\nareadoptedforcomprehensiveevaluation.Unlikeusingthe attacklocations(withafixedrandomseed)consideringthe\nIoUasanindicator,precisealignmentofthedetectedbound- miscalculationcases,wherethedetectionresultsforthereal\ning box with the y∗ in terms of size and orientation is less objects are incorrectly counted to spoofed ones. Random:\ncritical. Since the AD system may lead to dangerous con- randomlyinitializeaposterfortheattack.Realpicture:use\nsequences as long as a fake obstacle is perceived near the imagesofrealvehiclesaspostersfortheattack(Fig.3(c)).\nposter. Table 2 shows the digital attack results in nuScenes\nMoreover, we use the Learned Perceptual Image Patch dataset.Weachievegoodattackperformanceacrosssixdif-\nSimilarity(LPIPS)score(Zhangetal.2018)toassesstheen- ferent 3D detectors, successfully inducing FP predictions\nvironmentalconsistencyoftheattack,whichmeasuresper- near the poster locations (see Fig. 3(a) for the visualiza-\nceptualsimilaritybetweenbenignandattackedimages. tion results). This holds regardless of whether the target\nImplementation Details. We set the category of the model uses a CNN-based or Transformer-based backbone,\nspoofing object to the most common vehicle, with the a geometry-based or network-based PV-to-BEV transfor-\nposter’s physical size being 2m × 4m. For spoofing loca- mation, or an anchor point-based or query-based detection\ntions, we aim to induce FP predictions either in front of head.ForADsystems,suchanerrorrate(exceeding 40%)\norbehindtheself-vehicle.Therefore,thepostersareplaced iscatastrophic.Asuddenlyappearingobjectwithin10me-\nat a distance of 7 to 10 meters from the self-vehicle with tersinfrontoftheego-vehiclecantriggeremergencybrak-\n∆ = 5◦.Withinthisrange,theADsystem’smisjudgment ingorlane-changingdecisions,potentiallyleadingtosevere\nθ\nleaveslittletimeforthedrivertoreact.Wesample1,000val- safety incidents. Moreover, since our posters resemble the\nidationframesandplacepostersattwolocationsperframe, road surface, drivers have limited time to react and effec-\nyielding2,000attacksforASRcomputation.Seethesupple- tivelyintervene.\nmentarymaterialsformoretrainingdetails. Sinceweavoidoverlappingwithsceneobjectswhensam-\npling attack locations, miscalculation cases are nearly neg-\nMainResult\nligible, e.g., the ASR for Benign consistently < 1.5% un-\nWe verify the effectiveness of our road-style adversarial derCD2.0m.Moreover,weobserveaninterestingresultthat\nposter(AdvRoad)incomparisonwithBenign,Random,and takingarealvehicleimageasthespoofingpostermayalso\nRealpicture.Specifically,Benign:originalscenewithoutthe lead to FP errors. Specifically, Real picture can achieve an\nadversarialpattern,however,westillsampleandrecordthe ASR of up to 45.1% under CD2.0m for BEVDet4D-R50."
      },
      {
        "page": 6,
        "content": "\u0000\u001b\u0000\u0013\n\u0000\u0019\u0000\u0013\n\u0000\u0017\u0000\u0013\n\u0000\u0015\u0000\u0013\n\u0000\u0013\n\u0000\u0013\u0000\u0011\u0000\u0018\u0000P \u0000\u0014\u0000\u0011\u0000\u0013\u0000P \u0000\u0014\u0000\u0011\u0000\u0018\u0000P \u0000\u0015\u0000\u0011\u0000\u0013\u0000P\n\u0000&\u0000H\u0000Q\u0000W\u0000H\u0000U\u0000\u0003\u0000'\u0000L\u0000V\u0000W\u0000D\u0000Q\u0000F\u0000H\n\u0000\f\u0000\b\u0000\u000b\u0000\u0003\u0000H\u0000W\u0000D\u00005\u0000\u0003\u0000V\u0000V\u0000H\u0000F\u0000F\u0000X\u00006\u0000\u0003\u0000N\u0000F\u0000D\u0000W\u0000W\u0000$\n\u0000%\u0000(\u00009\u0000'\u0000H\u0000W\n\u0000\u001c\u0000\u0014\u0000\u0011\u0000\u0013\n\u0000$ \u0000$\u0000G \u0000G\u0000Y \u0000Y\u00003 \u00003\u0000R \u0000R\u0000V \u0000V\u0000W \u0000W\u0000H \u0000H\u0000U \u0000U\u0000\u000f\u0000\u000f \u0000\u0003\u0000\u0003 \u0000Z\u0000Z \u0000\u0012\u0000\u0012 \u0000\u0003\u0000R \u0000'\u0000\u0003\u0000' \u0000H\u0000I\u0000H \u0000\u0011\u0000I\u0000\u0011 \u0000\u001b\u0000\u0016\u0000\u0011\u0000\u0017 \u0000\u001b\u0000\u0013\n\u0000$\u0000G\u0000Y\u00005\u0000R\u0000D\u0000G\u0000\u000f\u0000\u0003\u0000Z\u0000\u0012\u0000R\u0000\u0003\u0000'\u0000H\u0000I\u0000\u0011\n\u0000$\u0000G\u0000Y\u00005\u0000R\u0000D\u0000G\u0000\u000f\u0000\u0003\u0000Z\u0000\u0012\u0000\u0003\u0000'\u0000H\u0000I\u0000\u0011 \u0000\u0019\u0000\u0017\u0000\u0011\u0000\u001b \u0000\u0019\u0000\u0015\u0000\u0011\u0000\u0019 \u0000\u0019\u0000\u0013\n\u0000\u0018\u0000\u0018\u0000\u0011\u0000\u0019\n\u0000\u0017\u0000\u0015\u0000\u0011\u0000\u001a \u0000\u0017\u0000\u0013\n\u0000\u0016\u0000\u0016\u0000\u0011\u0000\u0015\n\u0000\u0015\u0000\u0016\u0000\u0011\u0000\u0016 \u0000\u0015\u0000\u0014\u0000\u0011\u0000\u001c \u0000\u0015\u0000\u0013\n\u0000\u0014\u0000\u0013\u0000\u0011\u0000\u001c \u0000\u0014\u0000\u0016\u0000\u0011\u0000\u0015 \u0000\u001a\u0000\u0011\u0000\u0013\n\u0000\u0013\u0000\u0011\u0000\u0014 \u0000\u0013\u0000\u0011\u0000\u0015 \u0000\u0013\u0000\u0011\u0000\u0016 \u0000\u0014\u0000\u0011\u0000\u0019 \u0000\u0013\n\u0000\u0013\u0000\u0011\u0000\u0018\u0000P \u0000\u0014\u0000\u0011\u0000\u0013\u0000P \u0000\u0014\u0000\u0011\u0000\u0018\u0000P \u0000\u0015\u0000\u0011\u0000\u0013\u0000P\n\u0000&\u0000H\u0000Q\u0000W\u0000H\u0000U\u0000\u0003\u0000'\u0000L\u0000V\u0000W\u0000D\u0000Q\u0000F\u0000H\n\u0000\f\u0000\b\u0000\u000b\u0000\u0003\u0000H\u0000W\u0000D\u00005\u0000\u0003\u0000V\u0000V\u0000H\u0000F\u0000F\u0000X\u00006\u0000\u0003\u0000N\u0000F\u0000D\u0000W\u0000W\u0000$\n\u0000%\u0000(\u00009\u0000)\u0000R\u0000U\u0000P\u0000H\u0000U Stage ASR(%,↑)\n\u0000\u001b\u0000\u0015\u0000\u0011\u0000\u0019\n\u0000$ \u0000$\u0000G \u0000G\u0000Y \u0000Y\u00003 \u00003\u0000R \u0000R\u0000V \u0000V\u0000W \u0000W\u0000H \u0000H\u0000U \u0000U\u0000\u000f \u0000\u000f\u0000\u0003 \u0000\u0003\u0000Z \u0000Z\u0000\u0012 \u0000\u0012\u0000R \u0000\u0003\u0000'\u0000\u0003\u0000' \u0000H\u0000I\u0000H \u0000\u0011\u0000I\u0000\u0011 \u0000\u001a\u0000\u0016\u0000\u0011\u0000\u0016 1th 2nd 2.0m1.5m1.0m0.5m\n\u0000$\u0000G\u0000Y\u00005\u0000R\u0000D\u0000G\u0000\u000f\u0000\u0003\u0000Z\u0000\u0012\u0000R\u0000\u0003\u0000'\u0000H\u0000I\u0000\u0011\n\u0000$\u0000G\u0000Y\u00005\u0000R\u0000D\u0000G\u0000\u000f\u0000\u0003\u0000Z \u0000\u0018\u0000\u0012 \u0000\u001a\u0000\u0003\u0000' \u0000\u0011\u0000\u0013\u0000H\u0000I\u0000\u0011 AdvRoad@1 ✓ 23.4 19.2 13.1 6.8\nAdvRoad@2 ✓ 26.7 21.9 16.3 7.3\n\u0000\u0017\u0000\u0017\u0000\u0011\u0000\u0018\nAdvRoad ✓ ✓ 62.6 55.6 42.7 23.3\n\u0000\u0015\u0000\u001c\u0000\u0011\u0000\u001a \u0000\u0016\u0000\u0015\u0000\u0011\u0000\u001a AdvRoad∗ ✓ ✓ 67.0 60.5 48.6 27.2\n\u0000\u0015\u0000\u0013\u0000\u0011\u0000\u001a \u0000\u0014\u0000\u001b\u0000\u0011\u0000\u001a\n\u0000\u0014\u0000\u0015\u0000\u0011\u0000\u0015 \u0000\u001b\u0000\u0018\u0000\u0011\u0000\u0011\u0000\u0015\u0000\u0018 \u0000\u001b\u0000\u0011\u0000\u0018\n\u0000\u0013 \u0000\u0013\u0000\u0011\u0000\u0014 \u0000\u0013\u0000\u0011\u0000\u0018 \u0000\u0014\u0000\u0011\u0000\u001b Table3:AblationsforRoad-StyleAdversaryGenerationand\nScenario-Associated Adaptation. The results (ASR-%) are\ngivenonBEVDet-R50.\nAdvRoad AdvPoster AdvRoad AdvPoster\nLPIPS 0.1472 0.1929 LPIPS 0.0822 0.1104\n(a) (b)\nASR(%,↑)\nPhysicalSize LPIPS↓\nFigure 4: Comparison with AdvPoster w/ (dash line) and 2.0m1.5m1.0m0.5m\nw/o (solid line) defense. All victim models use ResNet50\n1.5m×3.0m 0.1123 31.3 26.5 19.9 10.4\nasimagebackbone.\n2.0m×3.0m 0.1292 49.4 42.1 32.5 17.7\n2.0m×3.5m 0.1384 56.6 50.4 38.6 21.2\n2.0m×4.0m 0.1472 62.6 55.6 42.7 23.3\nAlthoughthepictureposteris2Dandlacksthickness,itcan\n2.0m×4.5m 0.1555 66.1 58.1 44.0 23.5\nstillprovideintrinsicforegroundvisualcuesthatthedetector\n2.0m×5.0m 0.1633 67.6 59.3 45.0 23.1\ncapturesandrecognizes.However,similartoarealobject,a\n‘flat’vehicleisalsolikelytoattractthedriver’sattentionand\nhashigherLPIPSscorescomparedwithAdvRoad. Table4:Ablationsforthephysicalsizeofroadposters.The\nresultsaregivenonBEVDet-R50.\nComparisonwithCurrentWork\nWe compare our attack with AdvPoster (Wang et al. 2025)\ntors. It is easy for the models to filter out these adversarial\nintermsofattackperformance,naturality,anddefensediffi-\npatternsinsidetheimage.However,AdvRoadstillachieves\nculty,whichexplicitlylearnstheadversarybydirectlyopti-\nmizingthepixelvaluesoftheposter.\n∼20%ASRunderCD2.0m,whichdemonstratesthestrong\nresilienceofourattackwhenfacingthedefense.Thisisbe-\nAttack Performance. The results are given in Fig. 4\ncauseAdvRoadcangeneratealargenumberofdiversead-\nwith aligned experimental settings (e.g., poster’s physical\nversaries, and these posters exhibit textures similar to the\nsize, attack distances). The solid lines represent the orig-\nroadsurface,thusfurtherincreasingthedifficultyofdefense.\ninal attack performance without defense. As shown, Ad-\nMoredefenseresultsaregiveninsupplementary-B.3.\nvPoster achieves superior attack performance compared\nto our method, attaining ASR of 91% and 82.6% under\nAblation\nCD2.0m on BEVDet and BEVFormer respectively. This\ndemonstratestheeffectivenessofdirectlyoptimizingtheex- TwoStageApproach.Weconductanablationstudytoval-\nplicitrepresentationofadversaries. idate the effectiveness of each component in the AdvRoad.\nNaturality. AdvPoster optimizes a single deceptive The results are shown in Table 3. We first briefly intro-\nposteracrossentireinputscenes.Whiledemonstratinghigh duce the ablation settings. AdvRoad@1 directly uses the\nattack efficacy, the learned patterns exhibit uncontrollable outputs from Stage 1 for the attack; AdvRoad@2 follows\nand often abstract characteristics. As shown in Fig. 3(b), the typical GAN paradigm by first training a road poster\nAdvPoster appears visually distinct from road surfaces and generator without the supervision of the adversarial objec-\nisveryattention-grabbing.Incontrast,ourAdvRoadinjects tive L . Then, we freeze the generator using Scenario-\nobj\nstyle information into the generator through implicit ad- AssociatedAdaptationtosearchthelatentvectortoperform\nversarialrepresentations,producingnatural-lookingposters the attack; AdvRoad∗ extends the update iteration to 50 in\nthat blend seamlessly into road textures and achieving a Stage 2. AdvRoad@1 achieves 23.4% ASR after the Stage\nlowerLPIPSscore.Thisenablesstealthyattackswhileam- 1 training. This reflects the attack performance when ran-\nplifying practical security threats. More quantitative visual domly selecting a poster from the generator and placing it\ncomparisonsareprovidedinsupplementary-B.2. withinthe7–10mrange.Additionally,evenwithanaturally\nDefenseDifficulty.ForAdvPoster,singletraininggener- trainedgeneratorwithoutinjectingadversarialinformation,\nates only one unique adversarial example with salient dis- searching the latent space can still discover deceptive con-\ncriminativefeatures,itismorelikelytobetargetedandde- tent,achievinganASRof26.7%.CombiningtheRoad-Style\nfended by the AD system. Therefore, we employ adversar- AdversaryGenerationandScenario-AssociatedAdaptation,\nialaugmentationasthedefense.Specifically,weincorporate AdvRoad boosts the ASR to 62.6%, which highlights the\nthelearnedpostersintothetrainingsetandfine-tunethede- effectivenessofourtwo-stageattackpipeline.Also,increas-\ntector for extra 2 epochs. The attack results after defense ingtheupdateiterationsinStage2canfurtherimprovethe\nareshowninFig.4(dashlines).WeobservethatAdvPoster ASR.\nonlyachieveslessthan2%ASRagainstthedefendeddetec- Physical Size. Theoretically, the more pixels an attacker"
      },
      {
        "page": 7,
        "content": "\u0000\u0017\u0000\u0013\n\u0000\u0016\u0000\u0018\n\u0000\u0016\u0000\u0013\n\u0000\u0015\u0000\u0018\n\u0000\u0015\u0000\u0013\n\u0000\u0014\u0000\u0018\n\u0000\u0014\u0000\u0013\n\u0000\u0018\n\u0000\u001a\u0000P \u0000\u001b\u0000P \u0000\u001c\u0000P \u0000\u0014\u0000\u0013\u0000P \u0000\u0014\u0000\u0014\u0000P \u0000\u0014\u0000\u0015\u0000P\n\u00006\u0000S\u0000R\u0000R\u0000I\u0000\u0003\u0000'\u0000L\u0000V\u0000W\u0000D\u0000Q\u0000F\u0000H\u0000\u0003\u0000\u000b\u0000P\u0000H\u0000W\u0000H\u0000U\u0000\f\n\u0000\f\u0000\b\u0000\u000b\u0000\u0003\u0000H\u0000W\u0000D\u00005\u0000\u0003\u0000V\u0000V\u0000H\u0000F\u0000F\u0000X\u00006\u0000\u0003\u0000N\u0000F\u0000D\u0000W\u0000W\u0000$\n\u0000\u0017\u0000\u0013\u0000\u0011\u0000\u0019 \u0000\u0017\u0000\u0014\u0000\u0011\u0000\u0014 \u0000&\u0000'\u0000 \u0000\u0015\u0000\u0011\u0000\u0013\u0000P\n\u0000&\u0000'\u0000 \u0000\u0014\u0000\u0011\u0000\u0018\u0000P\n\u0000\u0016\u0000\u0016 \u0000\u0016\u0000\u0018 \u0000\u0011\u0000\u0011 \u0000\u0016\u0000\u0017 \u0000\u0016\u0000\u0016\u0000\u0011\u0000\u001a \u0000&\u0000'\u0000 \u0000\u0014\u0000\u0011\u0000\u0013\u0000P \u0000\u0016\u0000\u0014\u0000\u0011\u0000\u0016 \u0000\u0016\u0000\u0014\u0000\u0011\u0000\u0016 \u0000\u0016\u0000\u0013\u0000\u0011\u0000\u0018 \u0000&\u0000'\u0000 \u0000\u0013\u0000\u0011\u0000\u0018\u0000P\n\u0000\u0015\u0000\u001b\u0000\u0011\u0000\u0014\n\u0000\u0015\u0000\u0018\u0000\u0011\u0000\u0016\n\u0000\u0015\u0000\u0017\u0000\u0011\u0000\u0013\n\u0000\u0014\u0000\u001c\u0000\u0011\u0000\u001b\n\u0000\u0014\u0000\u0019\u0000\u0011\u0000\u0018\n\u0000\u0014\u0000\u001a\u0000\u0011\u0000\u001a \u0000\u0014\u0000\u0014\u0000\u0019\u0000\u001a\u0000\u0011\u0000\u0011\u0000\u001a\u0000\u001a \u0000\u0014\u0000\u001a\u0000\u0011\u0000\u001a\n\u0000\u0014\u0000\u0016\u0000\u0011\u0000\u0018\n\u0000\u001b\u0000\u0011\u0000\u0016\n\u0000\u0016\u0000\u0018\u0000\u0019 \u0000\u0011\u0000\u0011\u0000\u0011 \u0000\u0014\u0000\u0015\u0000\u0015 \u0000\u0017\u0000\u0018\u0000\u0011\u0000\u0011\u0000\u0014\u0000\u0015\nFigure5:AttackresultsontheKITTIdataset.TheASRs(%)\natdifferentspoofingdistancesaregiven.\nFigure6:Physicalattackenvironmentandresults.\ncan manipulate in an image, the stronger attack capability\nbecomes. However, since posters placed on road surfaces\nCondition ASR\nundergo perspective projection when captured by cameras,\nincreasing the physical size of posters yields diminishing Sunlitarea 49.4%(170/344)\nmarginalreturnsinpixelgainsfortheadversarialregion.On Shadedarea 28.3%(78/276)\nthe other hand, since AdvRoad performs an instance-level Posterwrinkled 40.2%(103/256)\nattackthataimstoinduceaghostvehiclenearthepostercen- Partialocclusion 43.8%(92/210)\nter, excessively large posters would actually hinder models Indoor 19.5%(57/292)\nfrom achieving precise localization. Our most lenient eval-\nuation metric (Center distance ≤ 2m) exactly matches the Table 5: Quantitative attack results under different condi-\nedge position of a 4m-long poster. As shown in Table 4, tions.\nincreasing the physical size can improve the ASR. How-\never, when the poster length exceeds 4m, the incremental\ngainsbecomelimited.Specifically,a5m-longpostershows thecustom3Ddetector.Then,wetrainthegenerator,select\na decrease in ASR under the strict evaluation criterion of aspoofingposter,andprintitfortheattack.\nCD0.5m. However, all the posters have textures similar to Fig.6(b-d)illustratessomephysicalattackresults.Itcan\ntheroadsurface,makingthemdifficultforhumanstodetect. be seen that the poster can successfully induce the de-\ntector to generate false predictions at its location. Despite\nAttacktoBroaderDataset some color deviations in the printing process (we use cost-\nTo verify the generalization ability of AdvRoad across dif- effective banner fabric for printing), the poster remains ef-\nferent datasets, we further conduct attack experiments on fective. This is because, during training, we apply random\nKITTI scenes (Geiger, Lenz, and Urtasun 2012). We use brightnessandcontrastadjustments,aswellasinjectrandom\nBEVDet as the victim model and the ASRs at different noise,toenhancetherobustnessofposters.Thequantitative\nspoofing distances are shown in Fig. 5. We observe that results under different physical conditions are given in Ta-\ntheposterachievesthestrongestattackeffectivenessatdis- ble5.Inaddition,thetexturesimilartotheroadsurfacecan\ntances between 9 and 10 meters. When the distance is too further reduce the attention from human drivers. Consider\nshort, the poster may not be fully captured by the camera, usingfabricswithbettercolorfidelity,suchascanvas,tore-\nwhileatlongerdistances,theadversarialregionintheimage ducethecolordifferencewiththebackgroundroadsurface,\nbecomeslimited,leadingtoadeclineinattackperformance. thereby making the attack more covert. Further analysis of\nFurther discussions on AdvRoad—such as its transfer- thephysicalattacksisprovidedinthesupplementary-B.5.\nabilityandthetrade-offbetweendiversityandattackeffec-\ntiveness—canbefoundinthesupplementary-B.4. Conclusion\nThis paper introduces AdvRoad, a naturalistic FP attack\nPhysicalAttackExperiment\npipeline for visual 3D object detection in AD. AdvRoad\nTo assess the practicality of our AdvRoad, we conduct at- leverages Road-Style Adversary Generation and Scenario-\ntackexperimentsinphysical-worldenvironments.Sincevi- Associated Adaptation to perform stealthy adversarial at-\nsual 3D detectors are typically camera-dependent (e.g., the tacks for human drivers, inducing ‘ghost’ objects for the\nPV2BEVtransformationisrelatedtothecamera’sintrinsic perceptionsystemandpotentiallycausingreal-worldthreats\nparameters ), physical experiments first require training a suchasemergencybraking.Extensiveexperimentsonboth\n3Ddetectoradaptedtothecustomsceneandcamera.There- digital and physical domains demonstrate the effectiveness\nfore,webuiltaphysicaldetectionplatformwithafront-view of AdvRoad. Compared with previous work, our attack is\nRGBcameraanda16-lineLiDAR(Fig.6(a)).TheLiDAR hardertodetectanddefendagainst,highlightingsignificant\nsensorisonlyusedtoannotatethesceneobjectsfortraining securityriskstoADsystems."
      },
      {
        "page": 8,
        "content": "Acknowledgments Guesmi, A.; Ding, R.; Hanif, M. A.; Alouani, I.; and\nShafique, M. 2024. Dap: A dynamic adversarial patch for\nThisworkwassupportedinpartbytheNationalNaturalSci-\nevadingpersondetectors. InProceedingsoftheIEEE/CVF\nence Foundation of China under Grant 62531012, in part\nConference on Computer Vision and Pattern Recognition,\nby the National Key Research and Development Program\n24595–24604.\nofChinaunderGrant2022YFA1003800,theKeyResearch\nandDevelopmentProgramofShaanxiProvinceunderGrant Gulino, C.; Fu, J.; Luo, W.; Tucker, G.; Bronstein, E.; Lu,\n2025CY-YBXM-040, and in part by the XJTU Research Y.;Harb,J.;Pan,X.;Wang,Y.;Chen,X.;etal.2023. Way-\nFundforAlScienceunderGrant2025YXYC004. max: An accelerated, data-driven simulator for large-scale\nautonomousdrivingresearch. AdvancesinNeuralInforma-\ntionProcessingSystems,36:7730–7742.\nReferences Han,S.;Lin,C.;Shen,C.;Wang,Q.;andGuan,X.2023.In-\nterpreting adversarial examples in deep learning: A review.\nAbdelfattah,M.;Yuan,K.;Wang,Z.J.;andWard,R.2021.\nACMComputingSurveys,55(14s):1–38.\nAdversarialattacksoncamera-lidarmodelsfor3dcardetec-\nHau, Z.; Co, K. T.; Demetriou, S.; and Lupu, E. C. 2021.\ntion. In IEEE/RSJ International Conference on Intelligent\nObject removal attacks on lidar-based 3d object detectors.\nRobotsandSystems,2189–2194.IEEE.\narXivpreprintarXiv:2102.03722.\nAthalye, A.; Engstrom, L.; Ilyas, A.; and Kwok, K. 2018.\nHe,K.;Zhang,X.;Ren,S.;andSun,J.2016. Deepresidual\nSynthesizing robust adversarial examples. In International\nlearningforimagerecognition. InProceedingsoftheIEEE\nConferenceonMachineLearning,284–293.PMLR.\nConference on Computer Vision and Pattern Recognition,\nCaesar,H.;Bankiti,V.;Lang,A.H.;Vora,S.;Liong,V.E.;\n770–778.\nXu,Q.;Krishnan,A.;Pan,Y.;Baldan,G.;andBeijbom,O.\nHu,C.;Shi,W.;Yao,W.;Jiang,T.;Tian,L.;Chen,X.;and\n2020. nuscenes:Amultimodaldatasetforautonomousdriv-\nLi, W. 2024. Adversarial infrared curves: An attack on in-\ning. InProceedingsoftheIEEE/CVFConferenceonCom-\nfrared pedestrian detectors in the physical world. Neural\nputerVisionandPatternRecognition,11621–11631.\nNetworks,178:106459.\nCao, Y.; Bhupathiraju, S. H.; Naghavi, P.; Sugawara, T.;\nHu,C.;Shi,W.;Yao,W.;Jiang,T.;Tian,L.;andLi,W.2025.\nMao, Z. M.; and Rampazzi, S. 2023. You can’t see me:\nTwo-stageoptimizedunifiedadversarialpatchforattacking\nPhysical removal attacks on {lidar-based} autonomous ve-\nvisible-infraredcross-modaldetectorsinthephysicalworld.\nhiclesdrivingframeworks.InUSENIXSecuritySymposium,\nAppliedSoftComputing,112818.\n2993–3010.\nHu,Y.;Yang,J.;Chen,L.;Li,K.;Sima,C.;Zhu,X.;Chai,\nCao, Y.; Xiao, C.; Cyr, B.; Zhou, Y.; Park, W.; Rampazzi,\nS.;Du,S.;Lin,T.;Wang,W.;etal.2023. Planning-oriented\nS.;Chen,Q.A.;Fu,K.;andMao,Z.M.2019a. Adversar-\nautonomous driving. In Proceedings of the IEEE/CVF\nial sensor attack on lidar-based perception in autonomous\nConference on Computer Vision and Pattern Recognition,\ndriving. InProceedingsoftheACMSIGSACConferenceon\n17853–17862.\nComputerandCommunicationsSecurity,2267–2281.\nHu,Y.-C.-T.;Kung,B.-H.;Tan,D.S.;Chen,J.-C.;Hua,K.-\nCao, Y.; Xiao, C.; Yang, D.; Fang, J.; Yang, R.; Liu, L.;andCheng,W.-H.2021.Naturalisticphysicaladversarial\nM.; and Li, B. 2019b. Adversarial objects against patchforobjectdetectors. InProceedingsoftheIEEE/CVF\nlidar-based autonomous driving systems. arXiv preprint InternationalConferenceonComputerVision,7848–7857.\narXiv:1907.05418.\nHuang,J.;andHuang,G.2022. Bevdet4d:Exploittemporal\nChen,L.;Wu,P.;Chitta,K.;Jaeger,B.;Geiger,A.;andLi, cues in multi-camera 3d object detection. arXiv preprint\nH. 2024. End-to-end autonomous driving: Challenges and arXiv:2203.17054.\nfrontiers. IEEE Transactions on Pattern Analysis and Ma-\nHuang, J.; Huang, G.; Zhu, Z.; Ye, Y.; and Du, D. 2021.\nchineIntelligence.\nBevdet:High-performancemulti-camera3dobjectdetection\nChen,X.;Ma,H.;Wan,J.;Li,B.;andXia,T.2017. Multi- inbird-eye-view. arXivpreprintarXiv:2112.11790.\nview 3d object detection network for autonomous driving. Jin, Z.; Ji, X.; Cheng, Y.; Yang, B.; Yan, C.; and Xu, W.\nInProceedingsoftheIEEEConferenceonComputerVision 2023. Pla-lidar:Physicallaserattacksagainstlidar-based3d\nandPatternRecognition,1907–1915. objectdetectioninautonomousvehicle.InIEEESymposium\nCheng, Z.; Choi, H.; Liang, J.; Feng, S.; Tao, G.; Liu, D.; onSecurityandPrivacy,1822–1839.IEEE.\nZuzak,M.;andZhang,X.2023. Fusionisnotenough:Sin- Lee, M.; and Kolter, Z. 2019. On physical adver-\nglemodalattacksonfusionmodelsfor3Dobjectdetection. sarial patches for object detection. arXiv preprint\narXivpreprintarXiv:2304.14614. arXiv:1906.11897.\nGeiger, A.; Lenz, P.; and Urtasun, R. 2012. Are we ready Li,L.;Qing,L.;andChen,Y.-C.2023. Adv3d:Generating\nforautonomousdriving?thekittivisionbenchmarksuite. In 3dadversarialexamplesindrivingscenarioswithnerf.\nIEEEConferenceonComputerVisionandPatternRecogni- Li, Z.; Wang, W.; Li, H.; Xie, E.; Sima, C.; Lu, T.; Yu, Q.;\ntion,3354–3361.IEEE. andDai,J.2024. Bevformer:learningbird’s-eye-viewrep-\nGoodfellow,I.J.;Shlens,J.;andSzegedy,C.2014.Explain- resentationfromlidar-cameraviaspatiotemporaltransform-\ning and harnessing adversarial examples. arXiv preprint ers. IEEE Transactions on Pattern Analysis and Machine\narXiv:1412.6572. Intelligence."
      },
      {
        "page": 9,
        "content": "Lin, C.; Ji, X.; Yang, Y.; Li, Q.; Zhao, Z.; Peng, Z.; Wang, Zhang, J.; Lou, Y.; Wang, J.; Wu, K.; Lu, K.; and Jia, X.\nR.;Fang,L.;andShen,C.2024. HardAdversarialExample 2021. Evaluating adversarial attacks on driving safety in\nMiningforImprovingRobustFairness. IEEETransactions vision-basedautonomousvehicles. IEEEInternetofThings\nonInformationForensicsandSecurity. Journal,9(5):3443–3456.\nLiu, Z.; Lin, Y.; Cao, Y.; Hu, H.; Wei, Y.; Zhang, Z.; Lin, Zhang,R.;Isola,P.;Efros,A.A.;Shechtman,E.;andWang,\nS.; and Guo, B. 2021. Swin transformer: Hierarchical vi- O.2018. Theunreasonableeffectivenessofdeepfeaturesas\nsiontransformerusingshiftedwindows. InProceedingsof aperceptualmetric. InProceedingsoftheIEEEConference\nthe IEEE/CVF International Conference on Computer Vi- onComputerVisionandPatternRecognition,586–595.\nsion,10012–10022. Zhang, T.; Wang, L.; Zhang, X.; Zhang, Y.; Jia, B.; Liang,\nMa, Y.; Wang, T.; Bai, X.; Yang, H.; Hou, Y.; Wang, Y.; S.;Hu,S.;Fu,Q.;Liu,A.;andLiu,X.2024. VisualAdver-\nQiao, Y.; Yang, R.; and Zhu, X. 2024. Vision-centric bev sarial Attack on Vision-Language Models for Autonomous\nperception:Asurvey. IEEETransactionsonPatternAnaly- Driving. arXivpreprintarXiv:2411.18275.\nsisandMachineIntelligence. Zhang, Y.; Hou, J.; and Yuan, Y. 2024. A comprehensive\nMao,J.;Shi,S.;Wang,X.;andLi,H.2023.3Dobjectdetec- study of the robustness for lidar-based 3d object detectors\ntion for autonomous driving: A comprehensive survey. In- against adversarial attacks. International Journal of Com-\nternationalJournalofComputerVision,131(8):1909–1963. puterVision,132(5):1592–1624.\nSato,T.;Shen,J.;Wang,N.;Jia,Y.;Lin,X.;andChen,Q.A. Zhu, Z.; Zhang, Y.; Chen, H.; Dong, Y.; Zhao, S.; Ding,\n2021. Dirtyroadcanattack:Securityofdeeplearningbased W.; Zhong, J.; and Zheng, S. 2023. Understanding the ro-\nautomated lane centering under Physical-World attack. In bustness of 3D object detection with bird’s-eye-view rep-\nUSENIXsecuritysymposium,3309–3326. resentations in autonomous driving. In Proceedings of\ntheIEEE/CVFConferenceonComputerVisionandPattern\nSun, J.; Cao, Y.; Chen, Q. A.; and Mao, Z. M. 2020. To-\nRecognition,21600–21610.\nwardsrobustLiDAR-basedperceptioninautonomousdriv-\ning: General black-box adversarial sensor attack and coun-\ntermeasures. InUSENIXSecuritySymposium,877–894.\nThys,S.;VanRanst,W.;andGoedeme´,T.2019.Foolingau-\ntomated surveillancecameras: adversarialpatches to attack\nperson detection. In Proceedings of the IEEE/CVF Con-\nferenceonComputerVisionandPatternRecognitionWork-\nshops,0–0.\nTu,J.;Ren,M.;Manivasagam,S.;Liang,M.;Yang,B.;Du,\nR.; Cheng, F.; and Urtasun, R. 2020. Physically realizable\nadversarialexamplesforlidarobjectdetection. InProceed-\ningsoftheIEEE/CVFConferenceonComputerVisionand\nPatternRecognition,13716–13725.\nWang,J.;Li,F.;andHe,L.2025. AUnifiedFrameworkfor\nAdversarialPatchAttacksagainstVisual3DObjectDetec-\ntioninAutonomousDriving.IEEETransactionsonCircuits\nandSystemsforVideoTechnology.\nWang, J.; Li, F.; Lv, S.; He, L.; and Shen, C. 2025. Physi-\ncallyRealizableAdversarialCreatingAttackagainstVision-\nbasedBEVSpace3DObjectDetection. IEEETransactions\nonImageProcessing.\nWang,J.;Li,F.;Zhang,X.;andSun,H.2023a. Adversarial\nobstacle generation against lidar-based 3d object detection.\nIEEETransactionsonMultimedia,26:2686–2699.\nWang, Z.; Yang, H.; Feng, Y.; Sun, P.; Guo, H.; Zhang, Z.;\nandRen,K.2023b. Towardstransferabletargetedadversar-\nialexamples. InProceedingsoftheIEEE/CVFConference\nonComputerVisionandPatternRecognition,20534–20543.\nXie, S.; Li, Z.; Wang, Z.; and Xie, C. 2023. On the adver-\nsarialrobustnessofcamera-based3dobjectdetection. arXiv\npreprintarXiv:2301.10766.\nYang,B.;Zhang,H.;Wang,J.;Yang,Y.;Lin,C.;Shen,C.;\nandZhao,Z.2025. AdversarialExampleSoups:Improving\nTransferabilityandStealthinessforFree.IEEETransactions\nonInformationForensicsandSecurity."
      },
      {
        "page": 10,
        "content": "Supplementary Materials for Invisible Triggers, Visible Threats! Road-Style\nAdversarial Creation Attack for Visual 3D Detection in Autonomous Driving\nJianWang,LijunHe,YixingYong,HaixiaBi,FanLi*\nSchoolofInformationandCommunicationsEngineering,Xi’anJiaotongUniversity\nwj851329121@stu.xjtu.edu.cn,lijunhe@mail.xjtu.edu.cn,yongyx@stu.xjtu.edu.cn,haixia.bi@mail.xjtu.edu.cn,\nlifan@mail.xjtu.edu.cn\nA.DetailsofImage-3DRendering\nInthissection,wepresentthedetailsoftheImage-3Dren-\ndering algorithm that differentiably render the 3D space\nposterontotheimage.Ingeneral,thecoreofthealgorithm Adversarial poster Place on 3D\nliesinfindingtherelativepositionofeachpixelintheadver- road surface\nsarial image region on the predefined poster, enabling per-\npixelinterpolation.\nSpecifically, we first calculate the projection matrix\nM3D→img ∈ R4×4 according to the camera’s intrinsic and Poster on Project the poster to Image\nextrinsicparameters.M3D→img canprojectpointsfromthe captured Image ia nc tc rio nrd sii cn ,g\na\nt no\nd\nc ra om ae dr ha\ne\ne igx htr ti n prs ii oc,\nr\n3D LiDAR coordinate system to the image plane. Then,\ngiven four poster corners {p3d ∈ R3|i = 1,2,3,4} in Figure1:IllustrationofImage-3Drendering.\ni\n3D coordinate system, we get four projected corner points\n{pimg ∈R2|i=1,2,3,4}inimageplane:\ni Model Backbone InputResolution mAP NDS\nResNet50 256×704 31.7 39.4\n[u i,v i,d i,1]T =M3D→img[x i,y i,z i,1]T BEVDet Swin-Tiny 256×704 33.4 41.8\n(1)\npimg =(u /d ,v /d ) BEVDet4D ResNet50 256×704 34.6 48.0\ni i i i i (8Frames) Swin-Tiny 256×704 36.3 48.9\nTheadversarialimageregionistheintersectionbetweenthe BEVFormer ResNet50 480×800 26.7 36.9\nquadrangle region defined by the projected corner points -Tiny Swin-Tiny 480×800 27.1 37.8\nand the image. For each pixel in this region, we need to\ncompute its position in the 3D space. However, we cannot Table1:Detectionperformanceofallvictimdetectorsonthe\ncompute it directly due to the lack of per-pixel depth in- nuScenesvalidationset.\nformation d . Nevertheless, we can indirectly calculate the\ni\n3D position of each point by leveraging the known height\ninformation z of the poster. Formally, for an adver-\nheight set with a batchsize of 40 (we accumulate the gradients of\nsarial point pi img = (u i,v i), the corresponding 3D point mini-batch multiple times to achieve a larger batchsize to\np3 id =(x i,y i,z i)canbesolved: stabilize training). The weight factor λ = 0.1. Stage 2 up-\ndatestherandomlyinitializedlatentvector30iterationsfor\n[x ,y ,z ,1]T =M−1 [u d ,v d ,d ,1]T\ni i i 3D→img i i i i i\n(2)\neachinputframe.\nz =z\ni height\nFinally, the color pixel of pimg is interpolated across the B.1DetectionPerformanceofVictimModels\ni\nneighborvaluesaroundp3dontheposter.\ni We present the detection performance of all six victim 3D\nB.AdditionalExperimentalResults detectors in Table 1. For the BEVDet and BEVDet4D, we\ntrain the model on 4 NVIDIA GeForce RTX 3090 GPUs\nTrainingDetail.Instage1,wetrainthegeneratoranddis-\nwithlearningrate2e-4for20epochs(withCBGS)anddrop\ncriminator alternately with an iteration ratio 1 : 10, using\nthe learning rate at epoch 17 by a factor of 0.1. The BEV\nAdamoptimizerwithalearningrateof0.0001.Thegenera-\ngrid size is 0.6m × 0.6m and 0.8m × 0.8m for BEVDet\ntoristotallyupdatedfor16epochsonthenuScenestraining\nand BEVDet4D respectively. For the BEVFormer, we train\nthemodelfor24epochswiththeCosineAnnealingstrategy\n*Correspondingauthors.\nCopyright©2026,AssociationfortheAdvancementofArtificial (initiallearningrateis2e-4).TheBEVgridsizeis0.512m×\nIntelligence(www.aaai.org).Allrightsreserved. 0.512m."
      },
      {
        "page": 11,
        "content": "B.4Discussion\nTransferability.WeevaluatethetransferabilityofAdvRoad\nacross different detectors through the black-box settings,\nwhere attackers have no access to the details of the target\nmodel. Since the latent vector search in Stage 2 requires\ninteraction between the adversary input and the model, we\nonlyusepostersgeneratedinStage1fortheattack.Specifi-\ncally,wefirstusethegeneratortrainedonthesourcemodel\nto randomly generate 500 posters, then select the 10 most\neffectiveones(withthehighestconfidence)toattackthetar-\nget models. This process does not require any information\naboutthetargetmodels.\n\u00007\u0000D\u0000U\u0000J\u0000H\u0000W\u0000\u0003\u00000\u0000R\u0000G\u0000H\u0000O\u0000V\n\u0000% \u0000( \u00009\n\u0000'\u0000H\u0000W\u0000\u0010 \u0000%\u00005 \u0000\u0018 \u0000(\u0000\u0013\n\u00009\n\u0000'\u0000H\u0000W\u0000\u0010 \u0000%\u00006 \u0000Z \u0000(\u0000L \u00009\u0000Q \u0000'\u00007 \u0000H\u0000W\u0000\u0017 \u0000%\u0000' \u0000(\u0000\u0010\u00005 \u00009\u0000\u0018 \u0000'\u0000\u0013 \u0000H\u0000W\u0000\u0017 \u0000%\u0000' \u0000(\u0000\u0010\u00006 \u00009\u0000Z \u0000)\u0000L \u0000R\u0000Q \u0000U\u00007 \u0000P \u0000%\u0000H\u0000U \u0000(\u0000\u0010 \u00009\u00005 \u0000)\u0000\u0018 \u0000R\u0000\u0013 \u0000U\u0000P\u0000H\u0000U\u0000\u0010\u00006 \u0000Z\u0000L\u0000Q \u00007\n\u0000%\u0000(\u00009\u0000'\u0000H\u0000W\u0000\u0010\u00005\u0000\u0018\u0000\u0013\n\u0000%\u0000(\u00009\u0000'\u0000H\u0000W\u0000\u0010\u00006\u0000Z\u0000L\u0000Q\u00007\n\u0000%\u0000(\u00009\u0000'\u0000H\u0000W\u0000\u0017\u0000'\u0000\u0010\u00005\u0000\u0018\u0000\u0013\n\u0000%\u0000(\u00009\u0000'\u0000H\u0000W\u0000\u0017\u0000'\u0000\u0010\u00006\u0000Z\u0000L\u0000Q\u00007\nFigure 2: Quantitative visual comparison in terms of the\nLPIPS(↓)withotherattackposters. \u0000%\u0000(\u00009\u0000)\u0000R\u0000U\u0000P\u0000H\u0000U\u0000\u0010\u00005\u0000\u0018\u0000\u0013\n\u0000%\u0000(\u00009\u0000)\u0000R\u0000U\u0000P\u0000H\u0000U\u0000\u0010\u00006\u0000Z\u0000L\u0000Q\u00007\nASR(%,↑)\nAttack\n2.0m 1.5m 1.0m 0.5m\nAdvPoster 19.7% 14.6% 10.4% 3.9%\nAdvRoad 32.4% 25.5% 14.8% 7.1%\nTable2:Attackresultsafterapplyingadversarialsegmenta-\ntionasdefense.\nB.2VisualizationofDifferentAttackPosters\nWe provide more visual comparisons with other attack\nposters in Fig. 2. The LPIPS score (↓) evaluates the per-\nceptual similarity by utilizing neural networks to compare\nmulti-layer features between benign and attacked images.\nThe results show that AdvRoad exhibits the best conceal-\nmentandenvironmentalconsistency.\nB.3AdversarialSegmentationasDefense\nWetrainalightweightadversarialsegmentationnetworkto\npredict the poster areas in the image. During evaluation,\nthe poster region in the input image is first segmented and\nmaskedoutbeforeperformingdetection.TheresultingASR\nonBEVDet-R50afterapplyingthisdefenseisshowninTa-\nble2.AlthoughAdvRoadhasalowerASRthanAdvPoster\nwithout defense, it shows stronger resistance to the fine-\ntuned detector and adversarial segmentation. This robust-\nness comes from: 1) its similarity to the road background,\nand2)diversepostercontent.\n\u0000V\u0000O\u0000H\u0000G\u0000R\u00000\u0000\u0003\u0000H\u0000F\u0000U\u0000X\u0000R\u00006\n\u0000\u0017\u0000\u0018\n\u0000\u0016\u0000\u0015\u0000\u0011\u0000\u0014 \u0000\u001b\u0000\u0011\u0000\u0018 \u0000\u0015\u0000\u0015\u0000\u0011\u0000\u0017 \u0000\u0014\u0000\u001a\u0000\u0011\u0000\u0019 \u0000\u0014\u0000\u0016\u0000\u0011\u0000\u0017 \u0000\u001b\u0000\u0011\u0000\u0013\n\u0000\u0017\u0000\u0013\n\u0000\u0014\u0000\u0013\u0000\u0011\u0000\u001b \u0000\u0017\u0000\u0015\u0000\u0011\u0000\u0019 \u0000\u0014\u0000\u0013\u0000\u0011\u0000\u0018 \u0000\u0015\u0000\u0018\u0000\u0011\u0000\u0018 \u0000\u001c\u0000\u0011\u0000\u0018 \u0000\u001c\u0000\u0011\u0000\u0014 \u0000\u0016\u0000\u0018\n\u0000\u0016\u0000\u0013\n\u0000\u0014\u0000\u0015\u0000\u0011\u0000\u001b \u0000\u001c\u0000\u0011\u0000\u0013 \u0000\u0015\u0000\u0018\u0000\u0011\u0000\u0014 \u0000\u001b\u0000\u0011\u0000\u001a \u0000\u0019\u0000\u0011\u0000\u0017 \u0000\u0015\u0000\u0011\u0000\u001c\n\u0000\u0015\u0000\u0018\n\u0000\u001c\u0000\u0011\u0000\u0015 \u0000\u0014\u0000\u0014\u0000\u0011\u0000\u0018 \u0000\u0014\u0000\u0015\u0000\u0011\u0000\u0016 \u0000\u0017\u0000\u0018\u0000\u0011\u0000\u0015 \u0000\u0018\u0000\u0011\u0000\u001c \u0000\u001a\u0000\u0011\u0000\u001a \u0000\u0015\u0000\u0013\n\u0000\u0014\u0000\u0018\n\u0000\u0018\u0000\u0011\u0000\u0016 \u0000\u0015\u0000\u0011\u0000\u0017 \u0000\u0014\u0000\u0016\u0000\u0011\u0000\u001c \u0000\u0016\u0000\u0011\u0000\u0018 \u0000\u0017\u0000\u0014\u0000\u0011\u0000\u0015 \u0000\u001b\u0000\u0011\u0000\u001a\n\u0000\u0014\u0000\u0013\n\u0000\u0018\u0000\u0011\u0000\u0018 \u0000\u0015\u0000\u0011\u0000\u0018 \u0000\u001a\u0000\u0011\u0000\u0016 \u0000\u0016\u0000\u0011\u0000\u0016 \u0000\u0014\u0000\u0017\u0000\u0011\u0000\u0019 \u0000\u0015\u0000\u0014\u0000\u0011\u0000\u001b\n\u0000\u0018\nFigure3:Transferresultsacrosssixdetectors.TheASR(%)\nunderCD2.0maregiven.\nThe transfer results are provided in Fig. 3. We make the\nfollowingobservations.First,detectorsthatadoptthesame\nPV2BEV transformation exhibit better transferability. For\nexample,thefourmodelswithintheBEVDetseriesachieve\na minimum ASR of 8.5%, while the posters generated on\nBEVFormer showed a lower limit on BEVDet. Such as a\nminimum of 2.4%, which almost fails in this case. Since\ntheBEVDetseriesrequiresexplicitper-pixeldepthestima-\ntion for feature projection, whereas BEVFormer does not,\nthis may lead to differences in the semantic focus of the\nlearned posters. Second, detectors with the same backbone\nexhibitbettertransferability.Forexample,posterslearnedon\nBEVDet-SwinTachieve25.5%ASRonBEVDet4D-SwinT,\ncompared with 10.5% on BEVDet4D-R50. These results\nmayprovideinsightsfordesigningmoretransferableadver-\nsarialattacks.\nDiversityandEffectiveness.Toexploretheupperbound\noftheattackcapabilityoftheimplicitrepresentationofthe\nadversarial poster, we supervise the generator using only\nL , without considering gradients from L . The results\nobj cls\nare given in Table 3. It can be observed that AdvRoad†\nachievesasignificantimprovementinASRcomparedtothe\nAdvRoad, at the cost of natural appearance. Some of the\nposteroutputfromthegeneratorisvisualizedinFig.4.We\nfind that no matter what the latent vector input is, the gen-"
      },
      {
        "page": 12,
        "content": "ASR(%,↑)\nModel Attack Diversity Natural-looking LPIPS↓\n2.0m 1.5m 1.0m 0.5m\nAdvPoster × × 0.1929 91.0 83.4 64.8 33.2\nBEVDet-R50 AdvRoad ✓ ✓ 0.1472 62.6 55.6 42.7 23.3\nAdvRoad† × × 0.2100 80.3 69.4 49.4 22.1\nAdvPoster × × 0.1737 91.8 84.7 66.5 38.3\nBEVDet-SwinT AdvRoad ✓ ✓ 0.1337 60.2 56.3 47.6 28.8\nAdvRoad† × × 0.2172 86.7 81.5 69.2 41.9\nAdvPoster × × 0.1758 86.9 78.6 58.7 30.8\nBEVDet4D-R50 AdvRoad ✓ ✓ 0.1331 49.1 42.9 32.7 17.7\nAdvRoad† × × 0.2223 79.0 71.8 55.6 29.6\nAdvPoster × × 0.1748 92.7 87.9 73.4 40.8\nBEVDet4D-SwinT AdvRoad ✓ ✓ 0.1370 39.1 35.1 27.8 15.7\nAdvRoad† × × 0.1966 86.8 80.5 64.9 36.6\nAdvPoster × × 0.1104 82.6 73.3 57.0 29.7\nBEVFormer-R50 AdvRoad ✓ ✓ 0.0822 44.5 32.7 20.7 8.2\nAdvRoad† × × 0.1082 70.1 58.0 41.2 19.8\nAdvPoster × × 0.1026 83.9 74.8 58.0 31.0\nBEVFormer-SwinT AdvRoad ✓ ✓ 0.0818 37.3 30.6 21.0 8.9\nAdvRoad† × × 0.1196 74.9 65.4 48.5 24.3\nTable3:DigitalattackresultsofdifferentcreationpostersinthenuScenesdataset.†denotestrainingthegeneratorunderthe\nsupervisionofadversarialobjectiveL only.\nobj\nB.5FurtherAnalysisofthePhysicalAttack\nInpractice,ourphysicalexperimentsyieldthefollowingin-\n(a) BEVDet-R50\nsights: 1. Factors affecting overall color—such as lighting,\nprintcolordeviation,andreflectivity—arekeytoattacksuc-\ncess. Due to AdvRoad’s similarity to road surfaces, its de-\n(b) BEVDet-SwinT ceptivepatternsrequirehighcolorfidelity.Incontrast,Adv-\nPoster’svividpatternsshowgreaterrobustnesstosuchfac-\ntors.2.Localdistortions(e.g.,wrinkles,occlusions)usually\n(c) BEVDet4D-R50 cause only positional shifts in detection results and do not\ninvalidatetheattack.Thissuggeststhattheadversarialinfor-\nmationisdistributedacrossthewholeposterandisinsensi-\ntive to local damage. 3. Although we didn’t test under rain\n(d) BEVDet4D-SwinT\nornightconditions,wesuspectbothmethodswouldperform\npoorly,asmuchinformationwouldbelostafterimagecap-\nture. For example, 3D detectors already struggle to detect\n(e) BEVFormer-R50 real vehicles at night. A potential solution is to use projec-\ntorstodisplaytheposter,whichweplantoexploreinfuture\nwork.\n(f) BEVFormer-SwinT\nFigure 4: Visualization of the posters for AdvRoad†. The\nposters from the same model (randomly generating 6 sam-\nplesforeachmodel)sharesimilarcontentandhaveunnatu-\nralpatterns.\neratoroutputssimilarcontentandlosesthediversity.More-\nover,theexplicitrepresentationoftheadversary,AdvPoster,\ndemonstratesstrongerattackcapabilityandhigheroptimiza-\ntionefficiency.Similarly,atthecostofdiversityandvisual\nnaturalness."
      }
    ]
  },
  "pdf_url": "/uploads/de76f55cf4e8c26fd836caa3e30086d1.pdf"
}